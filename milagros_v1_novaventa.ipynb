{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009b755e-8fa6-454a-a1b2-408eb481f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones Generales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "# Funciones de Calendario y Tiempo\n",
    "import holidays\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Funciones de Modelos de Series de Tiempo\n",
    "from statsmodels.tsa.seasonal import MSTL\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Funciones de Scikit Learn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Funciones de Feature Engine\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import (\n",
    "     LagFeatures,WindowFeatures)\n",
    "\n",
    "# Algoritmos de Machine Learning\n",
    "import xgboost as xgb \n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Otras Funciones\n",
    "from tqdm import tqdm #Barras de Progreso\n",
    "import warnings # Eliminar de advertencias\n",
    "import sys \n",
    "from IPython.display import clear_output # Complemento barra de progreso\n",
    "import math\n",
    "\n",
    "from scipy.stats import norm\n",
    "import streamlit as st\n",
    "\n",
    "# Funcion para exportar a excel\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9848e54-0d6e-40bb-90f4-b95facc141b6",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos Historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a0f164-6010-4fe6-8e21-d01ced54d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de carga y listado de hojas\n",
    "def cargar_data_nv(ruta):\n",
    "    # Leer el archivo y listar las hojas\n",
    "    excel_file = pd.ExcelFile(ruta)\n",
    "    print(\"Hojas disponibles en el archivo:\")\n",
    "    for hoja in excel_file.sheet_names:\n",
    "        print(f\"- {hoja}\")    \n",
    "    # Cargar la hoja seleccionada\n",
    "    df = excel_file.parse('Historial campañas Novaventa')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8723412-902d-4b89-96ce-7aaba5d57e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_datos_1_nv(df):\n",
    "    df['Periodo_Campaña'] = df['Año'].astype(str) + '-' + df['Campaña'].astype(str).str.zfill(2)\n",
    "    df_orig = df[['Periodo_Campaña','Referencia Novaventa',\t'Unds Brutas']].copy()\n",
    "    df_orig = df_orig.rename(columns={'Referencia Novaventa':'CODIGO','Unds Brutas':'DEMANDA','Periodo_Campaña':'FECHA'})\n",
    "    \n",
    "    return df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85f1604-4b6c-4217-a3b6-625350ca1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llenar_nan(df_orig):\n",
    "    df_horiz = df_orig.pivot_table(index='CODIGO', columns='FECHA', values='DEMANDA', fill_value=0, observed=True)\n",
    "    # Reset the index of the pivot table so 'CODIGO' becomes a column again\n",
    "    df_reset = df_horiz.reset_index()\n",
    "        # Melt the DataFrame to convert it back to a vertical format\n",
    "    df_vertical = df_reset.melt(id_vars=['CODIGO'], var_name='FECHA', value_name='DEMANDA')\n",
    "    df_vertical['CODIGO'] = df_vertical['CODIGO'].astype('str')\n",
    "    return df_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566e88ec-0687-44e9-81cd-5401030ae8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ceros_iniciales_nv(df):\n",
    "    # Lista para almacenar DataFrames válidos\n",
    "    lista_df = []\n",
    "\n",
    "    # Obtener códigos únicos (SKU-cliente)\n",
    "    codigos_unicos = df['CODIGO'].unique()\n",
    "    #clientes_unicos = df['CLIENTE'].unique()\n",
    "    \n",
    "    for codigo in codigos_unicos:\n",
    "       \n",
    "        # Filtrar los datos para cada código y cliente\n",
    "        df_codigo = df[df['CODIGO'] == codigo]\n",
    "            # Verificar si el DataFrame no está vacío\n",
    "        if not df_codigo.empty:\n",
    "            # Verificar si hay valores no cero en DEMANDA\n",
    "            if df_codigo['DEMANDA'].ne(0).any():\n",
    "                # Encontrar la primera fila donde la demanda no es cero\n",
    "                indice_primer_no_cero = df_codigo['DEMANDA'].ne(0).idxmax()\n",
    "\n",
    "                # Recortar la serie temporal desde el primer valor no cero\n",
    "                df_codigo_recortado = df_codigo.loc[indice_primer_no_cero:]\n",
    "                \n",
    "                # Agregar a la lista si no está vacío\n",
    "                if not df_codigo_recortado.empty:\n",
    "                    lista_df.append(df_codigo_recortado)\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos de una vez\n",
    "    if lista_df:\n",
    "        df_resultado = pd.concat(lista_df)\n",
    "    else:\n",
    "        df_resultado = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a6a7fa-8eda-4bf3-b8ca-cea76eab4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_ceros_nv(df_mes_orig):\n",
    "    \n",
    "    # Generar copia de trabajo\n",
    "    df_mes_ceros = df_mes_orig.copy()\n",
    "    # Reemplazar los valores de demanda iguales a 0 por la mediana correspondiente\n",
    "    # df_mes_ceros['DEMANDA'] = df_mes_orig.groupby('CODIGO')['DEMANDA'].transform(\n",
    "    #     lambda x: x.replace(0, x.median())\n",
    "    #     )\n",
    "    df_mes_ceros['DEMANDA'] = df_mes_orig.groupby('CODIGO')['DEMANDA'].transform(\n",
    "        lambda x: x.where(x >= 70, x.median())\n",
    "    )\n",
    "    df_mes_ceros['CONSECUTIVO'] = df_mes_ceros.groupby('CODIGO').cumcount() + 1\n",
    "    df_mes_ceros = df_mes_ceros.set_index('FECHA')\n",
    "    \n",
    "    return df_mes_ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eedaf90-a323-4a29-ae17-fdf66510e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_demanda_codigo_nv(df_mes_orig):\n",
    "    # Obtener los códigos únicos\n",
    "    codigos_unicos = df_mes_orig['CODIGO'].unique()\n",
    "    \n",
    "    # Crear la figura de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=(len(codigos_unicos) + 2) // 3,  # Distribuir en 3 columnas\n",
    "        cols=3,\n",
    "        shared_yaxes=False,  # No compartir el eje Y\n",
    "        subplot_titles=[f\"Código: {codigo}\" for codigo in codigos_unicos],\n",
    "        vertical_spacing=0.06,  # Reducir el espaciado entre subplots\n",
    "    )\n",
    "    \n",
    "    # Iterar sobre cada código para agregar subplots\n",
    "    for i, codigo in enumerate(codigos_unicos, start=1):\n",
    "        # Filtrar los datos para el código actual\n",
    "        df_codigo = df_mes_orig[df_mes_orig['CODIGO'] == codigo].copy()\n",
    "        # Asegurar que el índice es tratado como string\n",
    "        if 'FECHA' in df_codigo.columns:\n",
    "            df_codigo = df_codigo.set_index('FECHA')\n",
    "        df_codigo['FECHA'] = df_codigo.index.astype('str')\n",
    "        # Agregar una traza al subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_codigo.index,  # Usar el índice de fecha\n",
    "                y=df_codigo['DEMANDA'],\n",
    "                mode='lines',\n",
    "                name=codigo,\n",
    "                line=dict(width=2, color = \"#4682B4\"),  # Personalizar el ancho de la línea\n",
    "            ),\n",
    "            row=(i - 1) // 3 + 1,  # Fila en la que estará el subplot\n",
    "            col=(i - 1) % 3 + 1,   # Columna en la que estará el subplot\n",
    "        )\n",
    "    \n",
    "    # Ajustar el diseño general\n",
    "    fig.update_layout(\n",
    "        height=220 * ((len(codigos_unicos) + 2) // 3),  # Altura ajustada según el número de subplots        \n",
    "        title_text=\"Demanda por Código\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        showlegend=False,  # Eliminar la leyenda global\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "    )\n",
    "    # Ajustar los títulos de los subplots\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "        \n",
    "     # Ajustar los títulos de los subplots y ejes\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_font=dict(size=9),  # Tamaño de fuente para los títulos del eje X\n",
    "        type='category',  # Especificar que el eje X es categórico\n",
    "        tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "    )\n",
    "    fig.update_yaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje Y\n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44edcd09-cc83-4d72-b0c5-ff05fc95b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_outliers(df_outliers, sup, inf, n):\n",
    "    \n",
    "    # Generar un pronostico Ingenuo\n",
    "    df_outliers['FORECAST'] = df_outliers['DEMANDA'].rolling(window=n, min_periods=1).mean().shift(1)\n",
    "    \n",
    "    # Calcular la mediana de la columna DEMANDA\n",
    "    mediana_demanda = df_outliers['DEMANDA'].median()\n",
    "    \n",
    "    # Reemplazar los valores NaN en la columna FORECAST con la mediana de DEMANDA\n",
    "    df_outliers['FORECAST'] = df_outliers['FORECAST'].fillna(mediana_demanda)\n",
    "\n",
    "    # Calular error\n",
    "    df_outliers['ERROR'] = df_outliers['DEMANDA'] - df_outliers['FORECAST']\n",
    "\n",
    "    # Calcular Promedio y desviacion\n",
    "    m = df_outliers['ERROR'].mean()\n",
    "    s = df_outliers['ERROR'].std()\n",
    "\n",
    "    # Aplicar Percentil sup e inf\n",
    "    prob = norm.cdf(df_outliers['ERROR'],m,s)\n",
    "\n",
    "    # Marcar principales Outliers\n",
    "    outliers = (prob > sup) | (prob < inf)\n",
    "\n",
    "    # Recalcular promedio y desviacion SIN principales outliers\n",
    "    m2 = df_outliers.loc[~outliers,'ERROR'].mean()\n",
    "    s2 = df_outliers.loc[~outliers,'ERROR'].std()\n",
    "\n",
    "    # Calcular limite superior e inferior\n",
    "    df_outliers['LIM_SUP'] = norm.ppf(sup,m2,s2) + df_outliers['FORECAST']\n",
    "    df_outliers['LIM_INF'] = norm.ppf(inf,m2,s2) + df_outliers['FORECAST']\n",
    "\n",
    "    # Usar .clip para imputar los valores por fuera de los limites\n",
    "    df_outliers['NUEVA_DEM'] = df_outliers['DEMANDA'].clip(lower = df_outliers['LIM_INF'], upper= df_outliers['LIM_SUP'])\n",
    "\n",
    "    # Señalar los valores imputados\n",
    "    df_outliers['IS_OUTLIER'] = (df_outliers['DEMANDA'] != df_outliers['NUEVA_DEM'])\n",
    "    \n",
    "    return df_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05cde775-65b3-4d30-b2c3-6c9664fab2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_outliers(df_mes_ceros, sup, inf, n):\n",
    "    \n",
    "    # Inicializar el DataFrame acumulado vacío\n",
    "    df_acumulado = pd.DataFrame()\n",
    "    \n",
    "    # Aplicar la función imputar_outliers a cada grupo (SKU)\n",
    "    for sku, df_sku in df_mes_ceros.groupby('CODIGO'):\n",
    "        # Asegurarse de que 'FECHA' sea el índice\n",
    "        \n",
    "        # Imputar outliers para cada SKU\n",
    "        df_imputado = imputar_outliers(df_sku.copy(), sup, inf, n)\n",
    "        \n",
    "        # Agregar el resultado al DataFrame acumulado\n",
    "        df_acumulado = pd.concat([df_acumulado, df_imputado])\n",
    "\n",
    "    # Crear copia de trabajo\n",
    "    df_outliers = df_acumulado.copy()\n",
    "\n",
    "    if 'CONSECUTIVO' in df_acumulado.columns: \n",
    "        df_acumulado = df_acumulado[['CODIGO',\t\n",
    "                             'CONSECUTIVO', \n",
    "                             'NUEVA_DEM']]\n",
    "    else:\n",
    "        df_acumulado = df_acumulado[['CODIGO',\t\n",
    "                               'NUEVA_DEM']]\n",
    "        \n",
    "    df_mes = df_acumulado.rename(columns={'NUEVA_DEM':'DEMANDA'})\n",
    "    \n",
    "    # Mostrar el DataFrame acumulado\n",
    "    reporte_outliers = df_outliers[df_outliers['IS_OUTLIER'] == True].reset_index()\n",
    "    \n",
    "    return df_mes, df_outliers, reporte_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d166d012-9617-42a3-a348-886564d8ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_outliers_subplots(df_mes_ceros, df_outliers, sup, inf, n):\n",
    "    # Lista de SKUs únicos\n",
    "    lista_skus = df_mes_ceros['CODIGO'].unique()\n",
    "    \n",
    "    # Calcular número de filas necesarias para 3 columnas\n",
    "    n_cols = 3\n",
    "    n_rows = -(-len(lista_skus) // n_cols)  # Redondeo hacia arriba\n",
    "\n",
    "    # Crear los subplots\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=[f\"SKU: {sku}\" for sku in lista_skus],\n",
    "        horizontal_spacing=0.05,\n",
    "        vertical_spacing=0.06\n",
    "    )\n",
    "    \n",
    "    # Definir colores\n",
    "    color_demanda = \"#FF6347\"  # Rojo tomate\n",
    "    color_forecast = \"#FFA500\"  # Naranja\n",
    "    color_nueva_dem = \"#4682B4\" # Azul Acero\n",
    "    \n",
    "    # Iterar por cada SKU\n",
    "    for idx, sku in enumerate(lista_skus):\n",
    "        # Filtrar por SKU\n",
    "        df_outliers = df_mes_ceros[df_mes_ceros['CODIGO'] == sku][['DEMANDA']].copy()\n",
    "\n",
    "        # Aplicar función imputar_outliers\n",
    "        df_outliers = imputar_outliers(df_outliers, sup, inf, n)\n",
    "\n",
    "        # Calcular la posición en la cuadrícula\n",
    "        row = (idx // n_cols) + 1\n",
    "        col = (idx % n_cols) + 1\n",
    "\n",
    "        # Agregar trazas al subplot\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"DEMANDA\"],\n",
    "            name=f\"Demanda - {sku}\",\n",
    "            mode='lines',\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2, color=color_demanda)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"FORECAST\"],\n",
    "            mode='lines',\n",
    "            name=f\"Forecast - {sku}\",\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2.2, dash='solid', color=color_forecast)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"NUEVA_DEM\"],\n",
    "            mode='lines',\n",
    "            name=f\"Nueva Demanda - {sku}\",\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2, dash='solid', color=color_nueva_dem)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        # Límites superior e inferior\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"LIM_SUP\"],\n",
    "            mode='lines',\n",
    "            name=f\"Límite Superior - {sku}\",\n",
    "            line=dict(color='black', width=1, dash='dot'),\n",
    "            opacity=0.5\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"LIM_INF\"],\n",
    "            mode='lines',\n",
    "            name=f\"Límite Inferior - {sku}\",\n",
    "            line=dict(color='black', width=1, dash='dot'),\n",
    "            opacity=0.5\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        # Outliers\n",
    "        if df_outliers[\"IS_OUTLIER\"].any():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_outliers.index[df_outliers[\"IS_OUTLIER\"]],\n",
    "                y=df_outliers[\"DEMANDA\"].loc[df_outliers[\"IS_OUTLIER\"]],\n",
    "                mode='markers',\n",
    "                name=f\"Outliers - {sku}\",\n",
    "                marker=dict(color=color_demanda, size=8, symbol='circle')\n",
    "            ), row=row, col=col)\n",
    "\n",
    "    # Actualizar diseño global\n",
    "    fig.update_layout(\n",
    "        title=\"Outliers vs Ventas por SKU\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "        height=200 * n_rows,  # Ajustar altura según filas\n",
    "        #width=900,  # Ancho fijo\n",
    "        showlegend=False  # Ocultar leyenda global\n",
    "    )\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "    if 'CONSECUTIVO' in df_mes_ceros.columns:\n",
    "        fig.update_xaxes(\n",
    "            title_font=dict(size=9),  # Tamaño de fuente para los títulos del eje X\n",
    "            type='category',  # Especificar que el eje X es categórico\n",
    "            tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "        )         \n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561ba067-9ad6-4365-887d-883685e44221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_lista_skus(df_mes):\n",
    "    lista_skus = df_mes['CODIGO'].unique()\n",
    "    return lista_skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6259ddfe-b6ef-48b3-baa9-8d74b45725f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_meses_a_evaluar(df_sku, periodo_max_evaluacion, porc_eval):\n",
    "       \n",
    "    #Calculo del largo de cada serie de tiempo\n",
    "    largo_serie_tiempo = len(df_sku)\n",
    "    \n",
    "    # Calculo del numero de meses a usar como testeo de acuerdo con porc_eval\n",
    "    meses_evaluar = min(periodo_max_evaluacion, math.ceil(largo_serie_tiempo * porc_eval))\n",
    "\n",
    "    return meses_evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59a45b29-4fc3-44a0-84bb-f86d67d19c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_rango_fechas(df_sku, meses_evaluar):\n",
    "\n",
    "    if 'CONSECUTIVO' in df_sku.columns:\n",
    "        # Seleccionar la fecha mas reciente de los datos originales\n",
    "        ultima_fecha = df_sku['CONSECUTIVO'].max()\n",
    "        # Definimos la fecha inicial de corte - meses_evaluar -1 \n",
    "        inicio = ultima_fecha - meses_evaluar\n",
    "        # Creamos un rango de fechas comenzando en inicio y terminando en ultina_fecha, con frecuencia mensual inicio MS\n",
    "        rango_fechas = range(inicio, ultima_fecha+1)\n",
    "\n",
    "    else:\n",
    "        # Seleccionar la fecha mas reciente de los datos originales\n",
    "        ultima_fecha = df_sku.index.max()\n",
    "    \n",
    "        # Definimos la fecha inicial de corte - meses_evaluar -1 \n",
    "        inicio = ultima_fecha - pd.DateOffset(months=meses_evaluar)\n",
    "  \n",
    "        # Creamos un rango de fechas comenzando en inicio y terminando en ultina_fecha, con frecuencia mensual inicio MS\n",
    "        rango_fechas = pd.date_range(start=inicio, end=ultima_fecha, freq='MS')\n",
    "\n",
    "    return rango_fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023af2ff-a517-47b6-b934-933dde3e1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_columnas_error(df):\n",
    "    \n",
    "    df['ERROR'] = df['DEMANDA'] - df['FORECAST'] # Error\n",
    "    df['ABS_ERROR'] = df['ERROR'].abs() # Error Absoluto\n",
    "    df['ERROR_PORC'] = np.where(df['DEMANDA'] == 0, 2, df['ABS_ERROR'] / df['DEMANDA']) # Error porcentual, devuelve 200% si la demanda es 0\n",
    "    df['ERROR_CUADRADO'] = df['ERROR'] ** 2 # Error al cuadrado\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d84cbff-5ac2-4d77-886f-ee23394edf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_error(df, imprimir):\n",
    "     \n",
    "    # Verificar si el total de la demanda es 0\n",
    "    if df['DEMANDA'].sum() == 0:\n",
    "        sesgo_porc = 2\n",
    "        mae_porc = 2\n",
    "        score = 2\n",
    "    else:\n",
    "        sesgo_porc = df['ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        mae_porc = df['ABS_ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        score = mae_porc + abs(sesgo_porc)\n",
    "    \n",
    "    rmse = np.sqrt(df['ERROR_CUADRADO'].mean())\n",
    "        # Muestra los resultados formateados\n",
    "    if imprimir == 1:\n",
    "        print('MAE% modelo: {:.2%}'.format(mae_porc))\n",
    "        print('Sesgo% modelo: {:.2%}'.format(sesgo_porc))\n",
    "        print('Score modelo: {:.2%}'.format(score))\n",
    "        print('RMSE modelo: {:.1f}'.format(rmse))\n",
    "   \n",
    "    return sesgo_porc, mae_porc, rmse, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fa5f9db-588c-485c-9f7e-cc95decaa27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_sku(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None, None\n",
    "        \n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df.index.max()\n",
    "        fecha_inicio_testeo = df.index.min()\n",
    "\n",
    "    # Crear columnas de error para cada pronostico generado\n",
    "    df_test = crear_columnas_error(df)\n",
    "\n",
    "    # Imprimir informacion de los periodos evaluados\n",
    "    print('Periodo de Evaluacion desde:')\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test.index.min().strftime('%Y-%m')} hasta {df_test.index.max().strftime('%Y-%m')}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    \n",
    "    # Calcular metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por sku\n",
    "    grupo_sku_error = df_test.groupby(['CODIGO'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_error.columns = ['CODIGO', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    \n",
    "    # Ordenar el DataFrame por 'SCORE%' en orden ascendente\n",
    "    grupo_sku_error = grupo_sku_error.sort_values(by='SCORE%')\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_sku_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"Codigo\" sin formatear con las columnas formateadas\n",
    "    grupo_sku_error_formato = pd.concat([grupo_sku_error[['CODIGO']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    #display(grupo_sku_error_formato)\n",
    "\n",
    "    # Agrupar por codigo y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['CODIGO','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Calcular error rmse por lag\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['CODIGO','LAG','RMSE']]\n",
    "    \n",
    "    # Agrupar por codigo para almacenar RMSE\n",
    "    #df_test['Mes'] = df_test.index.month\n",
    "    grupo_sku_mes_error = df_test.groupby(['CODIGO', \n",
    "                                           #'Mes'\n",
    "                                          ], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    # Renombrar columnas\n",
    "    grupo_sku_mes_error.columns = ['CODIGO',\n",
    "                                   #'Mes', \n",
    "                                   'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular error rmse por codigo\n",
    "    grupo_sku_mes_error = calcular_error(grupo_sku_mes_error)\n",
    "\n",
    "    # Filtrar las columnas para mejor visualizacion\n",
    "    rmse_sku_mes = grupo_sku_mes_error[['CODIGO',\n",
    "                                        #'Mes',\n",
    "                                        'RMSE']]\n",
    "    \n",
    "    return grupo_sku_error_formato, rmse_sku_lag, rmse_sku_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b844302-ca8a-42f6-95d2-83623aeec42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error(df):\n",
    "    df['MAE%'] = df['ABS_ERROR']/df['DEMANDA']\n",
    "    df['SESGO%'] = df['ERROR']/df['DEMANDA']\n",
    "    df['SCORE%'] = df['MAE%'] + df['SESGO%'].abs()\n",
    "    if 'ERROR_CUADRADO_suma' in df.columns:\n",
    "        df['RMSE'] = np.sqrt(df['ERROR_CUADRADO_suma'] / df['ERROR_CUADRADO_cuenta'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c368c1bd-91a7-4ef2-8370-194a30f13649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_lags(df):\n",
    "    # Calcular los scores por lag\n",
    "    df_lags = df.groupby('LAG')[['ERROR', 'ABS_ERROR', 'DEMANDA']].sum()\n",
    "        \n",
    "    # Calcular los scores por lag evitando la división cuando DEMANDA es cero                  \n",
    "    df_lags['SCORE%'] = np.where(df_lags['DEMANDA'] == 0, 2,\n",
    "                            (df_lags['ABS_ERROR'] / df_lags['DEMANDA']) + abs(df_lags['ERROR'] / df_lags['DEMANDA'])\n",
    "                            )\n",
    "    return df_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2654fbe9-d18e-4b74-a555-05eef67a47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_lag(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None\n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df.index.max()\n",
    "        fecha_inicio_testeo = df.index.min()\n",
    "    \n",
    "    # Crear columnas de error  \n",
    "    df_test = crear_columnas_error(df)\n",
    "    print('Periodo de Evaluacion desde:')   \n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test.index.min().strftime('%Y-%m')} hasta {df_test.index.max().strftime('%Y-%m')}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "\n",
    "    # Calcular loas metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por mes\n",
    "    grupo_mes_error = df_test.groupby(['LAG']).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_mes_error.columns = ['LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por mes\n",
    "    grupo_mes_error = calcular_error(grupo_mes_error)\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_mes_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"Lag\" sin formatear con las columnas formateadas\n",
    "    grupo_mes_error_formato = pd.concat([grupo_mes_error[['LAG']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    #display(grupo_mes_error_formato)\n",
    "\n",
    "    # Agrupar por codigo y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['CODIGO', 'LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular columnas de error por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Filtrar columnas para mejor visualizacion\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['CODIGO', 'LAG','RMSE']]\n",
    "    \n",
    "    return grupo_mes_error_formato, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c329e493-3c2a-4e36-bce0-cc73d6c3696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar df por sku\n",
    "def agrupar_por_codigo(df):\n",
    "    grupo_sku_error = df.groupby(['CODIGO'], observed=True).agg({\n",
    "                                                                'DEMANDA': 'sum',\n",
    "                                                                'ERROR': 'sum',\n",
    "                                                                'ABS_ERROR': 'sum',\n",
    "                                                                'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                                }).reset_index()\n",
    "    grupo_sku_error.columns = ['CODIGO', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                                 'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    grupo_sku_error = grupo_sku_error[['CODIGO','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "    \n",
    "    # Agrupar por codigo y por Lag \n",
    "    grupo_sku_lag_error = df.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    grupo_sku_lag_error.columns = ['CODIGO','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "    grupo_sku_lag_error = grupo_sku_lag_error[['CODIGO','LAG','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "\n",
    "    # Pivotear el DataFrame de lag\n",
    "    pivoted_lags = grupo_sku_lag_error.pivot(index='CODIGO', columns='LAG', values='SCORE%')\n",
    "    pivoted_lags.columns = [f\"score_{col}\" for col in pivoted_lags.columns]\n",
    "    \n",
    "    # Unir con el DataFrame principal\n",
    "    tabla_final = grupo_sku_error.merge(pivoted_lags, on='CODIGO', how='left')\n",
    "    \n",
    "    # Renombrar columnas para cumplir con el formato\n",
    "    tabla_final = tabla_final.rename(columns={'MAE%': 'mae_porc', 'SESGO%': 'sesgo_porc', 'SCORE%': 'score', 'RMSE': 'rmse'})\n",
    "    \n",
    "    return tabla_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ace28225-b744-4b05-846b-2a6dd39c5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_pronostico_pms_nv(df_mejor, df_mes, meses_a_pronosticar_produccion, nombre_modelo):\n",
    "\n",
    "    # Crear un nuevo DataFrame para almacenar los resultados\n",
    "    data = []\n",
    "    \n",
    "    # Iterar por cada fila de df_mejor\n",
    "    for _, row in df_mejor.iterrows():\n",
    "        codigo = row[\"CODIGO\"]\n",
    "        ultimo_forecast = row[\"ultimo_forecast\"]\n",
    "        # Generar las fechas para los meses pronosticados\n",
    "        fechas = [df_mes['CONSECUTIVO'].max() + i for i in range(1, meses_a_pronosticar_produccion + 1)]\n",
    "    \n",
    "        # Generar las filas para los meses pronosticados\n",
    "        for i, fecha in enumerate(fechas, start=1):\n",
    "            data.append({\n",
    "                \"CONSECUTIVO\": fecha,\n",
    "                \"CODIGO\": codigo,\n",
    "                \"FORECAST\": ultimo_forecast,\n",
    "                \"LAG\": f\"Lag_{i}\"\n",
    "            })\n",
    "    \n",
    "    # Crear el nuevo DataFrame\n",
    "    df_forecast = pd.DataFrame(data)\n",
    "    #df_forecast = df_forecast.set_index('FECHA')\n",
    "    df_forecast['MODELO'] = nombre_modelo\n",
    "    \n",
    "    # Visualizar el resultado\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2888684c-86a3-4ddc-b3bc-94859e74b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_nombre_modelo_serie_tiempo(df, nombre_modelo):\n",
    "    if df is None:\n",
    "        return None\n",
    "    df['MODELO'] = nombre_modelo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        df = df[['CODIGO','CONSECUTIVO','FORECAST','LAG','MODELO']]\n",
    "    else:\n",
    "        df = df[['CODIGO','FORECAST','LAG','MODELO']]\n",
    "    df.index.name = 'FECHA'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c143c25f-3bbf-4c5e-9f89-ddf5b594a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_y_generar_pms_nv(df_mes, df_mes_ceros, lista_skus, \n",
    "                          periodo_max_evaluacion, \n",
    "                          porc_eval, \n",
    "                          meses_a_pronosticar_evaluacion,\n",
    "                         barra_progreso,\n",
    "                         status_text):\n",
    "    \n",
    "    mejor_n = [] # Bolsa para guardar resultados por cada sku\n",
    "    acumulado_forecast = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando PMS para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        resultados_n = [] # Bolsa para guardar resultados evalaudos por cada n\n",
    "        resultados_datos_evaluacion = [] # Bolsa para guardar datos sin evaluar por cada n\n",
    "        \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_mes por cada Sku\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku\n",
    "\n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar aper cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        #print('meses_evaluar:',meses_evaluar)\n",
    "        # Crear el rango de fechas para cortar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        #print('rango_fechas:',rango_fechas)  \n",
    "        # Tamaño de histórico n maximo y rango   \n",
    "        n_max = max(2, len(df_sku_fecha) - meses_evaluar)        \n",
    "        rango_n = range(1, n_max)\n",
    "        #print('n, rango_n:',n_max, rango_n) \n",
    "        # Iterar por cada posible tamaño de n\n",
    "        for n in rango_n: \n",
    "            \n",
    "            datos_evaluacion = []  # Bolsa para guardar resultados evaluados\n",
    "            ultimo_forecast_n = None  # Variable para almacenar el último forecast de cada n\n",
    "        \n",
    "            for fecha_corte in rango_fechas:\n",
    "                # Filtrar datos hasta la fecha de corte\n",
    "                df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()\n",
    "                \n",
    "                if len(df_sku_fecha_temp['DEMANDA']) > 1:\n",
    "                    # Calcular el forecast usando una media móvil con ventana n\n",
    "                    #print(len(df_sku_fecha_temp['DEMANDA']))\n",
    "                    df_sku_fecha_temp['FORECAST'] = df_sku_fecha_temp['DEMANDA'].rolling(window=n, min_periods=1).mean()\n",
    " \n",
    "                    forecast = [df_sku_fecha_temp['FORECAST'].iloc[-1]]\n",
    "                    \n",
    "                else:\n",
    "                    forecast = df_sku_fecha_temp['DEMANDA'].iloc[-1]\n",
    "                \n",
    "                # Generar los próximos lags para el forecast actual            \n",
    "                datos_forecast = pd.DataFrame({                \n",
    "                    'fecha':fecha_corte,\n",
    "                    'n':n,\n",
    "                    'CODIGO': sku,\n",
    "                    'FORECAST': forecast,\n",
    "                    'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]}, \n",
    "                    index=[df_sku_fecha_temp['CONSECUTIVO'].iloc[-1] \n",
    "                                      + i for i in range(1, meses_a_pronosticar_evaluacion + 1)]) # Genera titulo Lags dinamicamente\n",
    "                datos_forecast = datos_forecast.reset_index()\n",
    "\n",
    "                # Step 2: Rename the index column to match the key in df_sku_fecha_ceros\n",
    "                datos_forecast = datos_forecast.rename(columns={'index': 'CONSECUTIVO'})\n",
    "                           \n",
    "                datos_forecast_demanda = datos_forecast.merge(\n",
    "                    df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']],\n",
    "                    how='left',\n",
    "                    on='CONSECUTIVO'\n",
    "                )\n",
    "  \n",
    "                # Eliminar NaN si se esta pronosticando\n",
    "                if porc_eval != 0:\n",
    "                    datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                    \n",
    "                # Acumular data frames por cada fecha\n",
    "                datos_evaluacion.append(datos_forecast_demanda)\n",
    "                \n",
    "                # Guardar el último forecast de esta iteración de fecha_corte\n",
    "                ultimo_forecast_n = datos_forecast  # Se actualiza en cada fecha_corte               \n",
    "                       \n",
    "            # Concatenar todos los DataFrames de la evaluación\n",
    "            df_evaluacion_final = pd.concat(datos_evaluacion)#.dropna()\n",
    "                     \n",
    "            # Calcular columnas de error\n",
    "            df_columnas_error = crear_columnas_error(df_evaluacion_final)\n",
    "            \n",
    "            # Calcular métricas de error\n",
    "            sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "              \n",
    "            # Calcular los scores por lag\n",
    "            df_lags = evaluar_lags(df_columnas_error)\n",
    "            \n",
    "            # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "            resultados_n.append({\n",
    "                'CODIGO':sku,\n",
    "                'parametro': n,         \n",
    "                'sesgo_porc': sesgo_porc,        \n",
    "                'mae_porc': mae_porc,        \n",
    "                'rmse': rmse,\n",
    "                'score': score,\n",
    "                **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag\n",
    "                'ultimo_forecast': forecast[0],  # Guarda el último forecast de n                \n",
    "            })                  \n",
    "\n",
    "            # Acumula los datos de pronostico para evaluacion aparte\n",
    "            resultados_datos_evaluacion.append({                \n",
    "                'score': score,\n",
    "                'datos_evaluacion': datos_evaluacion\n",
    "            })\n",
    "           \n",
    "        # Crear el DataFrame final \n",
    "        df_kpi = pd.DataFrame(resultados_n)\n",
    "        #display(df_kpi) \n",
    "        # Crear df con info del n con menor score\n",
    "        df_min_score = df_kpi[df_kpi['score'] == df_kpi['score'].min()]\n",
    "        # Seleccionar el forecast correspondiente al mejor score de df_min_score\n",
    "        forecast_optimo = df_min_score['ultimo_forecast'].iloc[0]\n",
    "        #Acumular df con resultados por sku\n",
    "        mejor_n.append(df_min_score)\n",
    "        \n",
    "        # Crear un data frame con los datos de evaluacion \n",
    "        df_kpi_datos_evaluacion = pd.DataFrame(resultados_datos_evaluacion) \n",
    "        # Seleccionar el n con menor score\n",
    "        mejor_n_row = df_kpi_datos_evaluacion[df_kpi_datos_evaluacion['score'] == df_kpi_datos_evaluacion['score'].min()].iloc[0]\n",
    "        # Recuperar los datos del mejor n\n",
    "        mejor_n_datos = mejor_n_row['datos_evaluacion']  \n",
    "       # Almacenar los datos del mejor n para este SKU\n",
    "        acumulado_forecast.extend(mejor_n_datos)     \n",
    "       \n",
    "    # Concatenar mejor_n para obtener un solo df\n",
    "    df_mejor_n = pd.concat(mejor_n)\n",
    "    # Eliminar duplicados conservando solo el primer codigo\n",
    "    df_mejor_n = df_mejor_n.drop_duplicates(subset='CODIGO', keep='first')\n",
    "    # Mover ultimo_forecast a la ultima columna\n",
    "    columnas = [col for col in df_mejor_n.columns if col != 'ultimo_forecast'] + ['ultimo_forecast']\n",
    "    df_mejor_n = df_mejor_n[columnas]\n",
    "    \n",
    "    df_forecast_pms = pd.concat(acumulado_forecast, ignore_index=False)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()  \n",
    "    return df_mejor_n, df_forecast_pms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ecc75dc-2b92-4f49-a7a2-61cdf8820f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_se_nv(df_mes, df_mes_ceros, lista_skus, periodo_max_evaluacion, porc_eval, \n",
    "                        meses_a_pronosticar_evaluacion,\n",
    "                        barra_progreso,\n",
    "                        status_text):\n",
    "    \n",
    "    mejor_se = [] # Bolsa para guardar resultados por cada sku\n",
    "    resultados_se = []  # Bolsa para guardar resultados por cada n\n",
    "    acumulado_df_evaluacion_final = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando SE para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        datos_evaluacion_se = []  # Bolsa para guardar resultados de evaluación por fecha\n",
    "                \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        #meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        # Crear el rango de fechas para corar el set de datos de acuerdo con meses a evaluar\n",
    "        #rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            \n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()                 \n",
    "    \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "\n",
    "            # Chequeo de la longitud de cada serie de tiempo\n",
    "            if len(demanda) < 2:\n",
    "                print(f'El sku {sku} no tiene suficientes datos para la fecha de corte {fecha_corte}') # Ver SKUs con datos insuficientes y su fecha de corte\n",
    "                forecast = np.NaN\n",
    "            else:                            \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    model = SimpleExpSmoothing(demanda).fit(smoothing_level=None, optimized=True)\n",
    "   \n",
    "                    # Calcular pronostico para los proximos periodos\n",
    "                    forecast = model.forecast(steps=meses_a_pronosticar_evaluacion)\n",
    "                           \n",
    "                    # Generar los próximos lags para el forecast actual            \n",
    "                    datos_forecast = pd.DataFrame({\n",
    "                        'FECHA':fecha_corte,\n",
    "                        'CODIGO': sku,\n",
    "                        'FORECAST': forecast,\n",
    "                        'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]\n",
    "                                }, \n",
    "                        index=[df_sku_fecha_temp['CONSECUTIVO'].iloc[-1]\n",
    "                                          + i for i in range(1,  meses_a_pronosticar_evaluacion + 1)])\n",
    "                    datos_forecast = datos_forecast.reset_index()\n",
    "                    datos_forecast = datos_forecast.rename(columns={'index': 'CONSECUTIVO'})\n",
    "                    # Unir forecast con la demanda real para evaluar\n",
    "                    datos_forecast_demanda = datos_forecast.merge(\n",
    "                                        df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']],\n",
    "                                        how='left',\n",
    "                                        on='CONSECUTIVO'\n",
    "                                    )\n",
    "\n",
    "                    if porc_eval != 0:\n",
    "                        datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                                        \n",
    "                    # Acumular datos para evaluar el pronostico\n",
    "                    datos_evaluacion_se.append(datos_forecast_demanda)\n",
    "                    \n",
    "                    # Guardar el último alfa de esta iteración de fecha_corte\n",
    "                    ultimo_forecast_alfa = model.params['smoothing_level']  # Se actualiza en cada fecha_corte\n",
    "\n",
    "       # Concatenar df_evaluacion para obtener un solo df\n",
    "        df_evaluacion = pd.concat(datos_evaluacion_se)\n",
    "\n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        df_evaluacion_final = df_evaluacion.copy()\n",
    "\n",
    "        # Acumular los datos de evaluacion por fecha\n",
    "        acumulado_df_evaluacion_final.append(df_evaluacion_final)\n",
    "                     \n",
    "        # Calcular columnas de error sobre df inicial de evaluacion\n",
    "        df_columnas_error = crear_columnas_error(df_evaluacion)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags = evaluar_lags(df_columnas_error)\n",
    "       \n",
    "        # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "        resultados_se.append({\n",
    "            'CODIGO' : sku,\n",
    "            'parametro': ultimo_forecast_alfa,            \n",
    "            'sesgo_porc': sesgo_porc,            \n",
    "            'mae_porc': mae_porc,            \n",
    "            'rmse': rmse,\n",
    "            'score': score,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag               \n",
    "            'ultimo_forecast': forecast[0]  # Guarda el último forecast            \n",
    "        })\n",
    "           \n",
    "    # Crear el DataFrame con los resultados\n",
    "    df_kpi = pd.DataFrame(resultados_se)\n",
    "\n",
    "    # Acumular por cada sku\n",
    "    mejor_se.append(df_kpi)\n",
    "\n",
    "    # Concatenar para obtener un solo df\n",
    "    df_mejor_se = pd.concat(mejor_se)\n",
    "\n",
    "    # Concatener acumulado de matriz de datos de evaluacion para obtener un solo df\n",
    "    df_forecast_se = pd.concat(acumulado_df_evaluacion_final)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return df_mejor_se,  df_forecast_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbe41759-8a68-45ac-b11b-2ee87d3341f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_regresion_lineal_simple_nv(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text):\n",
    "   \n",
    "    resultados_datos_forecast_demanda_lineal = []\n",
    "    resultados_datos_forecast_demanda_estacional = []\n",
    "    resultados_rl_lineal = []\n",
    "    resultados_rl_estacional = []\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando RL para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        resultados_regresion_lineal = []  \n",
    "        resultados_regresion_estacional = []  \n",
    "                    \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        #meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    " \n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()                 \n",
    "            \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            \n",
    "            if len(demanda) >= 4:\n",
    "                # Generar y adecuar la variable independiente tiempo\n",
    "                X = np.arange(1, len(demanda)+1).reshape(-1, 1)\n",
    "                y = demanda\n",
    "                # Modelo de Regresión Lineal\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Pronóstico para los próximos periodos\n",
    "                limite_sup_pronost = len(demanda)+1 + meses_a_pronosticar_evaluacion\n",
    "                X_futuro = np.arange(len(demanda)+1, limite_sup_pronost).reshape(-1, 1)\n",
    "                y_futuro_lineal = model.predict(X_futuro)\n",
    "\n",
    "                if len(demanda) >= 19:\n",
    "                    factores_estacionales_mes = demanda[-19:] / demanda[-19:].mean() \n",
    "                    y_futuro_estacional =  y_futuro_lineal * factores_estacionales_mes[:len(y_futuro_lineal)]\n",
    "                else:    \n",
    "                    y_futuro_estacional = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            else:\n",
    "                print(f\"Sin datos: SKU={sku}, Fecha={fecha_corte}, Datos disponibles={len(demanda)}\") \n",
    "                y_futuro_lineal = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            # Almacenar los resultados lineales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_lineal):\n",
    "                fecha_pronostico = df_sku_fecha_temp['CONSECUTIVO'].max() + periodo-len(demanda)\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_lineal.append({'CODIGO': sku, \n",
    "                                                    'CONSECUTIVO': periodo, \n",
    "                                                    'FECHA': fecha_corte, \n",
    "                                                    'FORECAST': prediccion, \n",
    "                                                    'LAG': lag})\n",
    "                #display(resultados_regresion_lineal)\n",
    "            # Almacenar los resultados estacionales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_estacional):\n",
    "                fecha_pronostico = df_sku_fecha_temp['CONSECUTIVO'].max() + periodo-len(demanda)\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_estacional.append({'CODIGO': sku, \n",
    "                                                        'CONSECUTIVO': periodo, \n",
    "                                                        'FECHA': fecha_corte, \n",
    "                                                        'FORECAST': prediccion, \n",
    "                                                        'LAG': lag})\n",
    "        \n",
    "        df_forecast_regresion_lineal = pd.DataFrame(resultados_regresion_lineal)#.set_index('FECHA')\n",
    "        #df_forecast_regresion_lineal = df_forecast_regresion_lineal.set_index('FECHA')\n",
    "        #display( df_forecast_regresion_lineal)\n",
    "        df_forecast_regresion_estacional = pd.DataFrame(resultados_regresion_estacional)#.set_index('FECHA')\n",
    "        \n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_lineal = df_forecast_regresion_lineal.merge(\n",
    "            df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']], \n",
    "            how='left', \n",
    "            on='CONSECUTIVO', \n",
    "            \n",
    "        )\n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_estacional = df_forecast_regresion_estacional.merge(\n",
    "            df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']], \n",
    "            how='left', \n",
    "            on='CONSECUTIVO', \n",
    "        )\n",
    "        # Condicionar eliminacion de NaN a si es evaluacion o generacion de pronostico\n",
    "        if porc_eval != 0:\n",
    "            datos_forecast_demanda_lineal = datos_forecast_demanda_lineal.dropna()\n",
    "            datos_forecast_demanda_estacional = datos_forecast_demanda_estacional.dropna()           \n",
    "    \n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        datos_forecast_demanda_lineal_final = datos_forecast_demanda_lineal.copy() \n",
    "        datos_forecast_demanda_estacional_final = datos_forecast_demanda_estacional.copy() \n",
    "        \n",
    "        resultados_datos_forecast_demanda_lineal.append(datos_forecast_demanda_lineal_final)\n",
    "        resultados_datos_forecast_demanda_estacional.append(datos_forecast_demanda_estacional_final)\n",
    "        \n",
    "        # Calcular columnas de error sobre df inicial de evaluación\n",
    "        df_columnas_error_lineal = crear_columnas_error(datos_forecast_demanda_lineal)\n",
    "        df_columnas_error_estacional = crear_columnas_error(datos_forecast_demanda_estacional)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc_lineal, mae_porc_lineal, rmse_lineal, score_lineal = metricas_error(df_columnas_error_lineal, imprimir=0)\n",
    "        sesgo_porc_estacional, mae_porc_estacional, rmse_estacional, score_estacional = metricas_error(df_columnas_error_estacional, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags_lineal = evaluar_lags(df_columnas_error_lineal)\n",
    "        df_lags_estacional = evaluar_lags(df_columnas_error_estacional)\n",
    "        \n",
    "        # Guardar KPIs lineales\n",
    "        resultados_rl_lineal.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_lineal,\n",
    "            'mae_porc': mae_porc_lineal,\n",
    "            'rmse': rmse_lineal,\n",
    "            'score': score_lineal,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_lineal.index, df_lags_lineal['SCORE%'])},              \n",
    "        })\n",
    "        \n",
    "        # Guardar KPIs estacionales\n",
    "        resultados_rl_estacional.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_estacional,\n",
    "            'mae_porc': mae_porc_estacional,\n",
    "            'rmse': rmse_estacional,\n",
    "            'score': score_estacional,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_estacional.index, df_lags_estacional['SCORE%'])},              \n",
    "        })\n",
    "    # Concatenar resultados acumulados\n",
    "    df_forecast_rl_lineal = pd.concat(resultados_datos_forecast_demanda_lineal, ignore_index=False)\n",
    "    df_forecast_rl_estacional = pd.concat(resultados_datos_forecast_demanda_estacional, ignore_index=False) \n",
    "    \n",
    "    # Crear el DataFrame con los resultados de KPIs\n",
    "    df_mejor_rl_lineal = pd.DataFrame(resultados_rl_lineal)\n",
    "    df_mejor_rl_estacional = pd.DataFrame(resultados_rl_estacional)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()                                     \n",
    "    # Visualizar resultados\n",
    "    return df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ead2e85d-7cee-4f28-acb5-ca893eb0ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_mstl_nv(lista_skus, df_mes, df_mes_ceros, \n",
    "                 periodo_max_evaluacion, porc_eval, \n",
    "                 meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                 barra_progreso, status_text):\n",
    "\n",
    "    # Listas para acumular resultados\n",
    "    df_lag_forecasts = []\n",
    "    total_series = len(lista_skus)\n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando MSTL para SKU N° {i + 1} de {total_series}...\")\n",
    "    \n",
    "        # Filtrar datos por SKU\n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy()\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy()\n",
    "\n",
    "        # Calcular campañas a evaluar y rango de fechas\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "\n",
    "        forecasts = []\n",
    "\n",
    "        for fecha_corte in rango_fechas:\n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()\n",
    "            date = df_sku_fecha_temp['CONSECUTIVO']\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            demand_series = pd.Series(demanda, index=date)\n",
    "            #print(sku, 'largo demanda:',len(demand_series))\n",
    "            if len(demand_series) > 38:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    try:\n",
    "                        # Aplicar descomposición MSTL\n",
    "                        mstl_model = MSTL(demand_series, periods=19, stl_kwargs={'seasonal_deg': 0})\n",
    "                        descomposicion = mstl_model.fit()\n",
    "\n",
    "                        # Componentes de descomposición\n",
    "                        tendencia = descomposicion.trend\n",
    "                        seasonal = descomposicion.seasonal\n",
    "                        indice_tiempo = pd.to_numeric(demand_series.index)\n",
    "                        \n",
    "                        # Pesos exponenciales para regresión\n",
    "                        pesos = np.exp(peso_ult_data * np.arange(len(tendencia)))\n",
    "                        \n",
    "                        # Regresión polinómica\n",
    "                        poly = PolynomialFeatures(degree=2)\n",
    "                        X_poly = poly.fit_transform(indice_tiempo.values.reshape(-1, 1))\n",
    "                        model = LinearRegression()\n",
    "                        model.fit(X_poly, tendencia, sample_weight=pesos)\n",
    "                        \n",
    "                        # Proyección de tendencia\n",
    "                        fechas_futuras = [demand_series.index[-1] + i + 1 for i in range(meses_a_pronosticar_evaluacion)]\n",
    "                        indice_fechas_futuras = pd.to_numeric(pd.Index(fechas_futuras))\n",
    "                        X_poly_futura = poly.transform(indice_fechas_futuras.values.reshape(-1, 1))\n",
    "                        pronostico_tendencia = model.predict(X_poly_futura)\n",
    "                        \n",
    "                        # Proyección de estacionalidad\n",
    "                        estacionalidad_promedio = seasonal.groupby(seasonal.index).mean()\n",
    "                        mes_inicial = fechas_futuras[0]\n",
    "                        pronostico_estacional = [\n",
    "                            estacionalidad_promedio[(mes_inicial + i - 1) % 12 + 1] for i in range(meses_a_pronosticar_evaluacion)\n",
    "                        ]\n",
    "                        \n",
    "                        # Pronóstico final\n",
    "                        pronostico_final = pronostico_tendencia + pronostico_estacional\n",
    "                        pronostico_final_series = pd.Series(pronostico_final, index=fechas_futuras)\n",
    "                        \n",
    "                        forecasts.append((sku, date, pronostico_final_series))\n",
    "                       \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al ajustar MSTL para {sku}: {e}\")\n",
    "                        continue\n",
    "\n",
    "        # Procesar resultados de los pronósticos\n",
    "        for sku, fechas_originales, forecast_series in forecasts:\n",
    "            ultima_fecha = fechas_originales[-1]\n",
    "            fechas_pronosticos = [ultima_fecha + i + 1 for i in range(len(forecast_series))]\n",
    "            lags = [f\"Lag_{i}\" for i in range(1, len(forecast_series) + 1)]\n",
    "            temp_df = pd.DataFrame({\n",
    "                'FECHA': fechas_pronosticos,\n",
    "                'LAG': lags,\n",
    "                'CODIGO': [sku] * len(forecast_series),\n",
    "                'FORECAST': forecast_series.values,\n",
    "            })\n",
    "            df_lag_forecasts.append(temp_df)\n",
    "    \n",
    "    if df_lag_forecasts:\n",
    "        df_forecasts_mstl = pd.concat(df_lag_forecasts, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No hay SKUs con suficientes campañas para un análisis estacional\")\n",
    "        return None, None\n",
    "\n",
    "    # Unir forecast con la demanda real para evaluar\n",
    "    datos_forecast_mstl = df_forecasts_mstl.merge(\n",
    "        df_mes_ceros[['CODIGO', 'DEMANDA']], \n",
    "        how='left', \n",
    "        left_on=['CODIGO', 'FECHA'], \n",
    "        right_on=['CODIGO', df_mes_ceros.index]\n",
    "    )\n",
    "    if porc_eval != 0:\n",
    "        datos_forecast_mstl = datos_forecast_mstl.dropna()\n",
    "\n",
    "    df_forecast_mstl = datos_forecast_mstl.rename(columns={'key_1': 'FECHA'}).set_index('FECHA').copy()\n",
    "    df_columnas_error_mstl = crear_columnas_error(datos_forecast_mstl)\n",
    "    df_mejor_mstl = agrupar_por_codigo(df_columnas_error_mstl)\n",
    "\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return df_mejor_mstl, df_forecast_mstl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b465c9-b9f9-47d6-a321-eb69bdcb00f0",
   "metadata": {},
   "source": [
    "## 5. Comparacion Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f4e7728-3d58-4218-a12d-273197df1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_reporte_error_skus(modelos):\n",
    "    return {modelo: globals()[f'grupo_sku_error_formato_{modelo}'] for modelo in modelos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae4cdcbe-9217-4077-ae20-1f5d92c31c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_rmse(modelos):\n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs_error = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        # Obtener el DataFrame para cada modelo\n",
    "        df = globals().get(f'rmse_sku_mes_{modelo}')\n",
    "        \n",
    "        # Verificar si el DataFrame es None o está vacío\n",
    "        if df is None or df.empty:\n",
    "            print(f\"El modelo {modelo} fue ignorado porque no tiene datos.\")\n",
    "            continue\n",
    "        \n",
    "        # Añadir una columna 'MODELO' con el nombre del modelo\n",
    "        df['MODELO'] = modelo\n",
    "        df['RMSE'] = np.ceil(df['RMSE']).astype(int)\n",
    "        \n",
    "        # Añadir el DataFrame a la lista\n",
    "        dfs_error.append(df)\n",
    "    \n",
    "    # Verificar si hay DataFrames para concatenar\n",
    "    if not dfs_error:\n",
    "        print(\"No hay datos para concatenar.\")\n",
    "        return pd.DataFrame()  # Devuelve un DataFrame vacío\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_rmse = pd.concat(dfs_error, ignore_index=True)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_rmse['CODIGO'] = df_todos_rmse['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f583af-bd47-48cf-93c6-f508a3955b5f",
   "metadata": {},
   "source": [
    "def comparar_y_graficar_modelos_nv(reporte_error_skus):\n",
    "    # Crear el DataFrame base con la columna 'Codigo'\n",
    "    df_final = reporte_error_skus['pms'][['CODIGO']].copy()\n",
    "    \n",
    "    # Iterar sobre los modelos para combinarlos en df_final\n",
    "    for nombre_modelo, df in reporte_error_skus.items():\n",
    "        df_final = df_final.merge(\n",
    "            df[['CODIGO', 'SCORE%']].rename(columns={'SCORE%': nombre_modelo}), \n",
    "            on='CODIGO', \n",
    "            how='left'\n",
    "        )\n",
    "        df['MODELO'] = nombre_modelo\n",
    "        \n",
    "    # Remover simbolos de porcentaje y convertir columnas a valores numericos\n",
    "    modelos_cols = list(reporte_error_skus.keys())\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda col: abs(col.str.rstrip('%').astype(float)))\n",
    "    \n",
    "    # Identificar la columna con el valor minimo para cada fila\n",
    "    df_final['MEJOR_MODELO'] = df_final[modelos_cols].idxmin(axis=1)\n",
    "    #dejar una copia sin formato porcentaje\n",
    "    df_minimos = df_final.copy()\n",
    "    # Dar formato a las columnas con un decimal y agregar el simbolo %\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda x: x.map('{:.1f}%'.format))\n",
    "    \n",
    "    # Contar cuantas veces el modelo es el mejor\n",
    "    report = df_final['MEJOR_MODELO'].value_counts()\n",
    "    \n",
    "    # Preparar y crear la grafica de dona\n",
    "    fig1 = go.Figure(data=[go.Pie(\n",
    "        labels=report.index, \n",
    "        values=report.values, \n",
    "        hole=0.4,  \n",
    "        textinfo='percent+label',  \n",
    "        marker=dict(colors=px.colors.qualitative.Plotly)  \n",
    "    )])\n",
    "    \n",
    "    # Actualizar Layout de la grafica\n",
    "    fig1.update_layout(\n",
    "        title='Distribucion de Mejor Modelo por SKUs',\n",
    "        title_x=0.5,  \n",
    "        template='plotly_white'  \n",
    "    )\n",
    "   \n",
    "\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_errores_totales = pd.concat(reporte_error_skus.values(), ignore_index=True) \n",
    "    \n",
    "    return df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91ffaae0-fd55-43cb-9c15-1c74090eae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_y_graficar_modelos_nv(reporte_error_skus):\n",
    "    # Crear el DataFrame base con la columna 'CODIGO'\n",
    "    df_final = None\n",
    "\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    reporte_error_skus_validos = {nombre: df for nombre, df in reporte_error_skus.items() if df is not None and not df.empty}\n",
    "\n",
    "    if not reporte_error_skus_validos:\n",
    "        print(\"No hay modelos válidos para procesar.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Usar el primer DataFrame válido como base para 'CODIGO'\n",
    "    for nombre_modelo, df in reporte_error_skus_validos.items():\n",
    "        if df_final is None:\n",
    "            df_final = df[['CODIGO']].copy()\n",
    "        break\n",
    "\n",
    "    # Iterar sobre los modelos válidos para combinarlos en df_final\n",
    "    for nombre_modelo, df in reporte_error_skus_validos.items():\n",
    "        df_final = df_final.merge(\n",
    "            df[['CODIGO', 'SCORE%']].rename(columns={'SCORE%': nombre_modelo}),\n",
    "            on='CODIGO',\n",
    "            how='left'\n",
    "        )\n",
    "        df['MODELO'] = nombre_modelo\n",
    "\n",
    "    # Remover símbolos de porcentaje y convertir columnas a valores numéricos\n",
    "    modelos_cols = list(reporte_error_skus_validos.keys())\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda col: abs(col.str.rstrip('%').astype(float)))\n",
    "\n",
    "    # Identificar la columna con el valor mínimo para cada fila\n",
    "    df_final['MEJOR_MODELO'] = df_final[modelos_cols].idxmin(axis=1)\n",
    "    # Dejar una copia sin formato porcentaje\n",
    "    df_minimos = df_final.copy()\n",
    "    # Dar formato a las columnas con un decimal y agregar el símbolo %\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda x: x.map('{:.1f}%'.format))\n",
    "\n",
    "    # Contar cuántas veces el modelo es el mejor\n",
    "    report = df_final['MEJOR_MODELO'].value_counts()\n",
    "\n",
    "    # Preparar y crear la gráfica de dona\n",
    "    fig1 = go.Figure(data=[go.Pie(\n",
    "        labels=report.index,\n",
    "        values=report.values,\n",
    "        hole=0.4,\n",
    "        textinfo='percent+label',\n",
    "        marker=dict(colors=px.colors.qualitative.Plotly)\n",
    "    )])\n",
    "\n",
    "    # Actualizar Layout de la gráfica\n",
    "    fig1.update_layout(\n",
    "        title='Distribución de Mejor Modelo por SKUs',\n",
    "        title_x=0.5,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_errores_totales = pd.concat(reporte_error_skus_validos.values(), ignore_index=True)\n",
    "\n",
    "    return df_minimos, df_final, reporte_error_skus_validos, fig1, df_errores_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "161e66b8-6c4c-4dc0-b101-cd4a079ef7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_periodos_futuros(df_periodo, n):\n",
    "    # Separar los elementos en año y número de campaña\n",
    "    periodos  = df_periodo.index.unique()\n",
    "    periodos_split = [p.split('-') for p in periodos]\n",
    "    periodos_df = pd.DataFrame(periodos_split, columns=['AÑO', 'CAMPAÑA']).astype(int)\n",
    "    \n",
    "    # Identificar el año máximo\n",
    "    max_año = periodos_df['AÑO'].max()\n",
    "    \n",
    "    # Filtrar los elementos del año máximo\n",
    "    periodos_año_max = periodos_df[periodos_df['AÑO'] == max_año]\n",
    "    \n",
    "    # Identificar la campaña máxima dentro del año máximo\n",
    "    max_campaña = periodos_año_max['CAMPAÑA'].max()\n",
    "    \n",
    "    # Generar el período máximo\n",
    "    periodo_max = f\"{max_año:04d}-{max_campaña:02d}\"\n",
    "    \n",
    "    # Generar los períodos futuros\n",
    "    futuros = []\n",
    "    año_actual = max_año\n",
    "    campaña_actual = max_campaña\n",
    "    \n",
    "    for _ in range(n):\n",
    "        campaña_actual += 1\n",
    "        if campaña_actual > 19:  # Reiniciar campañas después de la 19\n",
    "            campaña_actual = 1\n",
    "            año_actual += 1\n",
    "        futuros.append(f\"{año_actual:04d}-{campaña_actual:02d}\")\n",
    "    \n",
    "    return periodo_max, futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6bcf437e-77c8-4ed3-93ed-8b8655fef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_fecha_a_grupo(df_todos_pronosticos, futuros):\n",
    "    # Agrupar por CODIGO y MODELO\n",
    "    grouped = df_todos_pronosticos.groupby(['CODIGO', 'MODELO'])\n",
    "    \n",
    "    # Crear una lista para almacenar los DataFrames con la columna FECHA añadida\n",
    "    dfs_con_fecha = []\n",
    "    \n",
    "    # Iterar sobre los grupos\n",
    "    for (codigo, modelo), group in grouped:\n",
    "        # Asegurar que la longitud de futuros sea la misma que la del grupo\n",
    "        if len(futuros) == len(group):\n",
    "            # Crear la nueva columna FECHA\n",
    "            group['FECHA'] = futuros\n",
    "        else:\n",
    "            raise ValueError(f\"La longitud de 'futuros' no coincide con la longitud del grupo para CODIGO: {codigo} y MODELO: {modelo}\")\n",
    "        \n",
    "        # Añadir el grupo modificado a la lista\n",
    "        dfs_con_fecha.append(group)\n",
    "    \n",
    "    # Concatenar todos los DataFrames de nuevo en uno solo\n",
    "    df_todos_pronosticos_fecha = pd.concat(dfs_con_fecha, ignore_index=True)\n",
    "    \n",
    "    return df_todos_pronosticos_fecha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed5d281-e723-43ea-b90f-96660aa2989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_forecasts_pronosticos(modelos):\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    dfs_validos = [\n",
    "        globals()[f'df_forecast_final_{modelo}']\n",
    "        for modelo in modelos\n",
    "        if globals()[f'df_forecast_final_{modelo}'] is not None and not globals()[f'df_forecast_final_{modelo}'].empty\n",
    "    ]\n",
    "    \n",
    "    # Verificar si hay DataFrames válidos\n",
    "    if not dfs_validos:\n",
    "        print(\"No hay pronósticos válidos para concatenar.\")\n",
    "        return None\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_todos_pronosticos = pd.concat(dfs_validos)\n",
    "\n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_pronosticos['CODIGO'] = df_todos_pronosticos['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_pronosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ab1bb76-9f42-479b-a9db-b867b2a271f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_mejor_pronostico_nv(df_minimos, df_todos_pronosticos_fecha):\n",
    "    # Crear una lista para almacenar los DataFrames filtrados\n",
    "    lista_filtrados = [\n",
    "        df_todos_pronosticos_fecha[\n",
    "            (df_todos_pronosticos_fecha['CODIGO'] == row['CODIGO']) & \n",
    "            (df_todos_pronosticos_fecha['MODELO'] == row['MEJOR_MODELO'])\n",
    "        ]\n",
    "        for _, row in df_minimos.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Concatenar todos los DataFrames filtrados\n",
    "    df_pronosticos_mejor_modelo = pd.concat(lista_filtrados)\n",
    "    \n",
    "    # Pivotear el resultado para mostrar el forecast por Código, Modelo y Fecha\n",
    "    df_pronosticos_12_meses = df_pronosticos_mejor_modelo.pivot_table(index=[\"CODIGO\", \"MODELO\"], columns=\"FECHA\", values=\"FORECAST\")\n",
    "    \n",
    "    return df_pronosticos_mejor_modelo, df_pronosticos_12_meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9762c7b-6519-4e0e-83d9-5f934d12a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_grafica_pronostico_nv(df_mes, df_todos_pronosticos, df_pronosticos_mejor_modelo):\n",
    "    # Obtener modelos únicos\n",
    "    modelos_unicos = df_todos_pronosticos['MODELO'].unique()\n",
    "    \n",
    "    # Generar una paleta de colores en seaborn\n",
    "    dark_colors = sns.color_palette(\"muted\", n_colors=len(modelos_unicos)).as_hex()\n",
    "    \n",
    "    # Crear un diccionario para asignar colores a cada modelo\n",
    "    color_mapping = {modelo: dark_colors[i] for i, modelo in enumerate(modelos_unicos)}\n",
    "\n",
    "    # Lista de códigos únicos\n",
    "    codigos_unicos = df_mes[\"CODIGO\"].unique()\n",
    "\n",
    "    # Crear una figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Crear todas las trazas (una por cada Código y Modelo) y agregar al gráfico\n",
    "    for codigo in codigos_unicos:\n",
    "        # Filtrar df_mes por Codigo (para graficar la demanda)\n",
    "        df_mes_filtrado = df_mes[df_mes[\"CODIGO\"] == codigo]\n",
    "        \n",
    "        # Filtrar df_todos_pronosticos por Codigo (para graficar todos los pronósticos de modelos)\n",
    "        df_todos_pronosticos_filtrado = df_todos_pronosticos[df_todos_pronosticos[\"CODIGO\"] == codigo]\n",
    "\n",
    "        # Filtrar df_pronosticos_mejor_modelo para obtener el mejor modelo de ese código\n",
    "        df_pronosticos_filtrado = df_pronosticos_mejor_modelo[df_pronosticos_mejor_modelo[\"CODIGO\"] == codigo]\n",
    "        mejor_modelo = df_pronosticos_filtrado[\"MODELO\"].values[0]  # Extraer el mejor modelo para ese código\n",
    "\n",
    "        # Agregar la traza de DEMANDA para este código (inicialmente invisible)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_mes_filtrado.index, \n",
    "            y=df_mes_filtrado[\"DEMANDA\"], \n",
    "            mode='lines',\n",
    "            name=f'{codigo}',\n",
    "            line=dict(color='navy'),\n",
    "            visible=False  # Inicialmente invisible\n",
    "        ))\n",
    "\n",
    "        # Agregar una traza para cada modelo en df_todos_pronosticos_filtrado\n",
    "        for modelo in modelos_unicos:\n",
    "            # Filtrar por el modelo específico dentro del código seleccionado\n",
    "            df_modelo_filtrado = df_todos_pronosticos_filtrado[df_todos_pronosticos_filtrado[\"MODELO\"] == modelo]\n",
    "\n",
    "            # Determinar el estilo de la línea\n",
    "            if modelo == mejor_modelo:\n",
    "                line_style = dict(dash='solid', color='#FF4500', width=2.5)  # Continua para el mejor modelo\n",
    "            else:\n",
    "                line_style = dict(dash='dot', color=color_mapping[modelo])  # Punteada para los demás modelos\n",
    "\n",
    "            # Agregar la traza de FORECAST de este modelo (inicialmente invisible)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_modelo_filtrado['FECHA'], \n",
    "                y=df_modelo_filtrado[\"FORECAST\"], \n",
    "                mode='lines',\n",
    "                name=f'{modelo}',\n",
    "                line=line_style,\n",
    "                visible=False  # Inicialmente invisible\n",
    "            ))\n",
    "\n",
    "    # Crear botones para el dropdown del primer menú (Códigos)\n",
    "    dropdown_buttons_codigo = []\n",
    "    for i, codigo in enumerate(codigos_unicos):\n",
    "        # Visibilidad de DEMANDA y todas las trazas de pronósticos para este código\n",
    "        visibility = [False] * len(fig.data)  # Inicializar todas las trazas como invisibles\n",
    "\n",
    "        # Mostrar DEMANDA\n",
    "        visibility[i * (len(modelos_unicos) + 1)] = True  \n",
    "\n",
    "        # Mostrar todas las trazas de los modelos para el código seleccionado\n",
    "        for j in range(len(modelos_unicos)):\n",
    "            visibility[i * (len(modelos_unicos) + 1) + j + 1] = True\n",
    "\n",
    "        # Botón para seleccionar el código\n",
    "        dropdown_buttons_codigo.append(\n",
    "            dict(\n",
    "                args=[{\"visible\": visibility}],  # Cambiar la visibilidad de las trazas\n",
    "                label=str(codigo),  # Etiqueta del código\n",
    "                method=\"update\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Mostrar la primera DEMANDA y todos los modelos del primer código por defecto\n",
    "    fig.data[0].visible = True\n",
    "    for j in range(len(modelos_unicos)):\n",
    "        fig.data[j + 1].visible = True\n",
    "\n",
    "    # Configurar el layout con el menú dropdown\n",
    "    fig.update_layout(\n",
    "        template=\"ggplot2\",\n",
    "        updatemenus=[\n",
    "            # Menú desplegable para seleccionar el Código\n",
    "            dict(\n",
    "                buttons=dropdown_buttons_codigo,\n",
    "                direction=\"down\",\n",
    "                showactive=True,\n",
    "                x=-0.05, y=1.2,  # Posición del dropdown\n",
    "                xanchor=\"left\",\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        ],\n",
    "        title=\"Demanda vs Pronóstico por Código\",\n",
    "        xaxis_title=\"Campaña\",\n",
    "        yaxis_title=\"Demanda\",\n",
    "        showlegend=True,\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            y=0.5\n",
    "        ),\n",
    "        height=400,\n",
    "        plot_bgcolor='#F0F0F0',  # Set the plot background color to a light gray\n",
    "    )\n",
    "    fig.update_xaxes(        \n",
    "        type='category',  # Especificar que el eje X es categórico\n",
    "        tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "        tickangle=-45,  # Rotar las etiquetas del eje X a 45 grados\n",
    "        tickfont=dict(size=9)  # Reducir el tamaño de la fuente en un 25%\n",
    "    ) \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c51db79e-8633-43d7-8874-0f0314e723d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_pronosticos(sku, modelo, df_todos_pronosticos):\n",
    "    \n",
    "    # Filtrar DataFrame basado en selección\n",
    "    df_filtrado = df_todos_pronosticos[\n",
    "                (df_todos_pronosticos['CODIGO'] == sku) & \n",
    "                (df_todos_pronosticos['MODELO'] == modelo)\n",
    "            ]     \n",
    "    df_filtrado['FORECAST'] = np.ceil(df_filtrado['FORECAST']).astype(int)  \n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fede4-f4cc-469e-a4fc-8767e0f2e9d6",
   "metadata": {},
   "source": [
    "## Script de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676aad48-4b8e-4666-bda4-2bb932ef7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta ubicacion de archivo fuente\n",
    "ruta_demanda = r'dataset/Consolidado_datos_5.xlsx'\n",
    "df = cargar_data_nv(ruta_demanda)\n",
    "df_orig = preprocesar_datos_1_nv(df)\n",
    "df_vertical = llenar_nan(df_orig)\n",
    "df_resultado = eliminar_ceros_iniciales_nv(df_vertical)\n",
    "df_ceros = reemplazar_ceros_nv(df_resultado)\n",
    "graficar_demanda_codigo_nv(df_resultado)\n",
    "sup = 0.98\n",
    "inf = 0.02\n",
    "n = 6\n",
    "df_periodo, df_outliers, reporte_outliers = eliminar_outliers(df_ceros, sup, inf, n)\n",
    "graficar_outliers_subplots(df_ceros, df_outliers, sup, inf, n)\n",
    "lista_skus = crear_lista_skus(df_periodo) # Crear lista de skus\n",
    "meses_a_pronosticar_evaluacion = 6 # Numero de meses a pronosticar para evaluar y seleccionar el modelo\n",
    "periodo_max_evaluacion = 12 # Numero de periodos maximos de evaluacion de cada serie de tiempo\n",
    "porc_eval = 0.35 # Porcentaje de meses para evaluar el modelo\n",
    "barra_progreso = st.progress(0)\n",
    "status_text = st.text(\"Iniciando Evaluación...\")\n",
    "\n",
    "df_mejor_n, df_forecast_pms = evaluar_y_generar_pms_nv(df_periodo, df_ceros, lista_skus, \n",
    "                                                    periodo_max_evaluacion, \n",
    "                                                    porc_eval, \n",
    "                                                    meses_a_pronosticar_evaluacion,\n",
    "                                                   barra_progreso,\n",
    "                                                   status_text)\n",
    "grupo_mes_error_formato_pms, df_test_pms = kpi_error_lag(df_forecast_pms) # Reporte global\n",
    "grupo_sku_error_formato_pms, rmse_sku_lag_pms, rmse_sku_mes_pms = kpi_error_sku(df_forecast_pms) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con PMS\n",
    "meses_a_pronosticar_produccion = 12 # Numero de meses finales a pronosticar\n",
    "df_forecast_final_pms = construir_pronostico_pms_nv(df_mejor_n, df_periodo, meses_a_pronosticar_produccion, 'pms')\n",
    "\n",
    "df_mejor_se,  df_forecast_se = encontrar_mejor_se_nv(df_periodo, df_ceros, lista_skus, periodo_max_evaluacion, porc_eval, \n",
    "                        meses_a_pronosticar_evaluacion,\n",
    "                        barra_progreso,\n",
    "                        status_text)\n",
    "grupo_mes_error_formato_se, df_test_se = kpi_error_lag(df_forecast_se) # Reporte global\n",
    "grupo_sku_error_formato_se, rmse_sku_lag_se, rmse_sku_mes_se = kpi_error_sku(df_forecast_se)\n",
    "\n",
    "porc_eval_pronost = 0\n",
    "meses_a_pronosticar_produccion = 12\n",
    "df_mejor_se_final,  df_forecast_final_se = encontrar_mejor_se_nv(df_periodo, df_ceros, lista_skus, periodo_max_evaluacion, porc_eval_pronost, \n",
    "                        meses_a_pronosticar_produccion,\n",
    "                        barra_progreso,\n",
    "                        status_text)\n",
    "# Adicionar nombre a los pronosticos de SE\n",
    "df_forecast_final_se = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se, 'se')\n",
    "\n",
    "porc_eval = 0.35\n",
    "df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "\n",
    "grupo_mes_error_formato_rl_lineal, df_test_rl_lineal = kpi_error_lag(df_forecast_rl_lineal) # Reporte global\n",
    "grupo_sku_error_formato_rl_lineal, rmse_sku_lag_rl_lineal, rmse_sku_mes_rl_lineal = kpi_error_sku(df_forecast_rl_lineal)\n",
    "\n",
    "grupo_mes_error_formato_rl_estacional, df_test_rl_estacional = kpi_error_lag(df_forecast_rl_estacional) # Reporte global\n",
    "grupo_sku_error_formato_rl_estacional, rmse_sku_lag_rl_estacional, rmse_sku_mes_rl_estacional = kpi_error_sku(df_forecast_rl_estacional)\n",
    "\n",
    "\n",
    "df_final_mejor_rl_lineal, df_final_mejor_rl_estacional, df_forecast_final_rl_lineal, df_forecast_final_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "\n",
    "# Adicionar nombre a los pronosticos de RL\n",
    "df_forecast_final_rl_lineal = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal, 'rl_lineal')\n",
    "df_forecast_final_rl_estacional = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional, 'rl_estacional')\n",
    "\n",
    "# Modelo de descomposicion MSTL\n",
    "peso_ult_data = 0.08\n",
    "df_mejor_mstl, df_forecast_mstl = aplicar_mstl_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    " # Reportes de error MSTL\n",
    "grupo_mes_error_formato_mstl, df_test_mstl = kpi_error_lag(df_forecast_mstl) # Reporte golbal\n",
    "grupo_sku_error_formato_mstl, rmse_sku_lag_mstl, rmse_sku_mes_mstl = kpi_error_sku(df_forecast_mstl) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con MSTL\n",
    "tabla_final_pronost, df_forecast_final_mstl = aplicar_mstl_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion, \n",
    "                                    peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)                      \n",
    "\n",
    "# Adicionar nombre a los pronosticos de MSTL                                                         \n",
    "df_forecast_final_mstl = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl, 'mstl')\n",
    "modelos = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "reporte_error_skus = generar_reporte_error_skus(modelos)\n",
    "df_todos_rmse = concatenar_rmse(modelos)\n",
    "df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales = comparar_y_graficar_modelos_nv(reporte_error_skus)\n",
    "fig1.show()\n",
    "n = 12\n",
    "periodo_max, futuros = generar_periodos_futuros(df_periodo, n)\n",
    "df_todos_pronosticos = concatenar_forecasts_pronosticos(modelos)\n",
    "df_todos_pronosticos_fecha = agregar_fecha_a_grupo(df_todos_pronosticos, futuros)\n",
    "df_pronosticos_mejor_modelo, df_pronosticos_12_meses = obtener_mejor_pronostico_nv(df_minimos, df_todos_pronosticos_fecha )\n",
    "fig = crear_grafica_pronostico_nv(df_periodo, df_todos_pronosticos_fecha, df_pronosticos_mejor_modelo)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649883e-2810-456d-bfec-79d345825e27",
   "metadata": {},
   "source": [
    "# Front end streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c33a816-a8ef-4306-87c7-ed86700a7c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 13:51:07.182 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# Configurar el layout de Streamlit\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Título de la aplicación\n",
    "st.title(\"Pronósticos por campaña MILAGROS para NOVAVENTA\")\n",
    "\n",
    "# Variables globales\n",
    "session_vars = ['df_', 'df_vertical', 'df_mes_cliente', 'df_mes_orig', \n",
    "                'sup', 'inf', 'n',\n",
    "                'meses_a_pronosticar_evaluacion', 'meses_a_pronosticar_produccion', 'periodo_max_evaluacion',\n",
    "                'porc_eval', 'porc_eval_pronost', 'df_resultado',\n",
    "                'df_ceros', 'df_periodo', 'df_outliers', 'df_todos_pronosticos', 'df_todos_pronosticos_fecha',\n",
    "                'codigo_seleccionado', 'modelo_seleccionado', 'mostrar_grafica', \n",
    "                'df_pronosticos_12_meses', 'reporte_outliers', 'fig', 'mostrar_grafica_outliers'\n",
    "               ]\n",
    "# Inicializar session_state si no existe\n",
    "for var in session_vars:\n",
    "    if var not in st.session_state:\n",
    "        st.session_state[var] = None\n",
    "\n",
    "tabs = st.tabs(['📂 Cargar datos Novaventa', \n",
    "                '📊 Outliers Novaventa',  \n",
    "                '🔮 Evaluar y generar pronósticos Novaventa',\n",
    "                '🛠️ Herramientas de Análisis Novaventa'\n",
    "               ])\n",
    "\n",
    "with tabs[0]:\n",
    "    # Estado inicial de la variable de gráfica\n",
    "    if st.session_state.mostrar_grafica is None:\n",
    "        st.session_state.mostrar_grafica = \"ninguna\"\n",
    "    \n",
    "    # Subida y procesamiento de datos\n",
    "    st.header(\"Cargar Datos\")\n",
    "    \n",
    "    if st.session_state.df is not None:\n",
    "        st.success('Datos ya cargados previamente')\n",
    "        st.write(\"Datos cargados:\")\n",
    "        st.write(st.session_state.df.head())\n",
    "        if st.button('Cargar Nuevos Datos'):\n",
    "            for var in session_vars:\n",
    "                st.session_state[var] = None\n",
    "            st.experimental_rerun()\n",
    "    else:\n",
    "        ruta_demanda = st.file_uploader(\"Sube el archivo de demanda en formato Excel\", type=['xlsx'])\n",
    "        if ruta_demanda is not None:        \n",
    "            df = cargar_data_nv(ruta_demanda)\n",
    "            st.success(\"Archivo histórico cargado correctamente.\")\n",
    "            st.session_state.df = df\n",
    "            st.write(\"Datos cargados:\")\n",
    "            st.write(st.session_state.df.head())\n",
    "            df_orig_nv = preprocesar_datos_1_nv(df)\n",
    "            df_vertical_nv = llenar_nan(df_orig_nv)\n",
    "            st.session_state.df_resultado = eliminar_ceros_iniciales_nv(df_vertical_nv)\n",
    "            st.session_state.df_ceros = reemplazar_ceros_nv(st.session_state.df_resultado)\n",
    "            st.success(\"Datos preprocesados correctamente.\")\n",
    "    \n",
    "    # Opciones de gráficas\n",
    "    if st.session_state.df_ceros is not None:\n",
    "        st.header(\"Ver Gráficas de Demanda por Campaña\")\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        \n",
    "        with col1:\n",
    "           if st.button(\"Graficar demanda original con ceros\"):\n",
    "                st.session_state.mostrar_grafica = \"con_ceros\"\n",
    "        with col2:        \n",
    "            if st.button(\"Graficar demanda sin ceros\"):            \n",
    "                st.session_state.mostrar_grafica = \"sin_ceros\"\n",
    "        with col3:\n",
    "            if st.button(\"Cerrar gráfica\"):\n",
    "                st.session_state.mostrar_grafica = \"ninguna\"\n",
    "                \n",
    "        # Mostrar las gráficas según la selección\n",
    "        if st.session_state.mostrar_grafica == \"con_ceros\":\n",
    "            st.subheader(\"Gráfica: Demanda Original con Ceros\")\n",
    "            graficar_demanda_codigo_nv(st.session_state.df_resultado)\n",
    "        elif st.session_state.mostrar_grafica == \"sin_ceros\":\n",
    "            st.subheader(\"Gráfica: Demanda Sin Ceros\")\n",
    "            graficar_demanda_codigo_nv(st.session_state.df_ceros)\n",
    "\n",
    "        with tabs[1]:\n",
    "            # Parámetros de configuración\n",
    "            if \"df_ceros\" in st.session_state and st.session_state.df_ceros is not None:\n",
    "                st.header(\"Manejo de Outliers\")\n",
    "                sup = st.number_input(\"Límite Superior\", min_value=0.0, max_value=1.0, value=0.98, step=0.01)\n",
    "                inf = st.number_input(\"Límite Inferior\", min_value=0.0, max_value=1.0, value=0.02, step=0.01)\n",
    "                n = st.number_input(\"Número de Periodos para Pronóstico Ingenuo\", min_value=1, max_value=12, value=6, step=1)\n",
    "                df_periodo, df_outliers, reporte_outliers = eliminar_outliers(st.session_state.df_ceros, sup, inf, n)\n",
    "                st.session_state.df_periodo = df_periodo\n",
    "                st.session_state.df_outliers = df_outliers\n",
    "                st.session_state.reporte_outliers = reporte_outliers\n",
    "                st.session_state.sup = sup\n",
    "                st.session_state.inf = inf\n",
    "                st.session_state.n = n  \n",
    "                st.success(\"Outliers Imputados correctamente.\")\n",
    "                    \n",
    "            if \"df_periodo\" in st.session_state and \"df_outliers\" in st.session_state:\n",
    "            \n",
    "                # Exportar a excel outliers\n",
    "                if df_outliers is not None:\n",
    "                    output = io.BytesIO()\n",
    "                    with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
    "                        st.session_state.reporte_outliers.to_excel(writer, index=False, sheet_name='Outliers')\n",
    "                        \n",
    "                    excel_data = output.getvalue()\n",
    "                else:\n",
    "                    st.warning(\"No hay datos procesados aun para exportar.\")\n",
    "                # Boton de descarga a excel\n",
    "                st.download_button(\n",
    "                    label=\"📥 Descargar Outliers (Excel)\",\n",
    "                    data=excel_data,\n",
    "                    file_name=\"df_outliers.xlsx\",\n",
    "                    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "                )\n",
    "                \n",
    "                st.header(\"Generar Gráfica Manejo Ouliers\")\n",
    "                col1, col2 = st.columns(2)\n",
    "                \n",
    "                with col1:\n",
    "                    if st.button(\"Mostrar gráfica de outliers\"):\n",
    "                        st.session_state.mostrar_grafica_outliers = \"mostrar\"\n",
    "                with col2:\n",
    "                    if st.button(\"Cerrar gráfica de outliers\"):\n",
    "                        st.session_state.mostrar_grafica_outliers = \"cerrar\"\n",
    "            \n",
    "                # Mostrar o cerrar gráfica\n",
    "                if st.session_state.mostrar_grafica_outliers == \"mostrar\":\n",
    "                    st.subheader(\"Gráfica: Imputación de Outliers\")\n",
    "                    graficar_outliers_subplots(st.session_state.df_ceros, \n",
    "                                               st.session_state.df_outliers, \n",
    "                                               sup=st.session_state.sup, \n",
    "                                               inf=st.session_state.inf, \n",
    "                                               n=st.session_state.n)\n",
    "        with tabs[2]:\n",
    "             # Chequear si los pronosticos ya han sido generados\n",
    "            if st.session_state.df_pronosticos_12_meses is not None and st.session_state.fig is not None and st.session_state.df_todos_pronosticos is not None:\n",
    "                st.success(\"Pronósticos ya generados previamente.\")\n",
    "                # Boton para regenerar pronosticos\n",
    "                if st.button('Regenerar Pronósticos'):\n",
    "                    # Limpiar los pronosticos previos y volver a correr script de la seccion\n",
    "                    st.session_state.df_pronosticos_12_meses = None\n",
    "                    st.session_state.fig = None\n",
    "                    st.session_state.df_todos_pronosticos = None\n",
    "                    st.experimental_rerun()  # Volver a correr el script\n",
    "                else: \n",
    "                    st.dataframe(st.session_state.df_pronosticos_12_meses)\n",
    "                    st.plotly_chart(st.session_state.fig)\n",
    "            \n",
    "            else:    \n",
    "                if \"df_periodo\" in st.session_state and \"df_ceros\" in st.session_state:\n",
    "                    st.header(\"Parámetros de evaluación de los modelos\")\n",
    "                    meses_a_pronosticar_evaluacion = st.number_input(\"Meses a Pronosticar para Evaluación\", \n",
    "                                                                     min_value=1, max_value=24, value=6, step=1)\n",
    "                    meses_a_pronosticar_produccion = st.number_input(\"Meses a Pronosticar para Produccion\", \n",
    "                                                                     min_value=1, max_value=24, value=12, step=1)\n",
    "                    periodo_max_evaluacion = 12\n",
    "                    porc_eval = st.number_input(\"Porcentaje de Evaluación\", min_value=0.0, max_value=1.0, value=0.35, step=0.01)\n",
    "                    porc_eval_pronost = 0\n",
    "                \n",
    "                    st.session_state.meses_a_pronosticar_evaluacion = meses_a_pronosticar_evaluacion\n",
    "                    st.session_state.meses_a_pronosticar_produccion = meses_a_pronosticar_produccion\n",
    "                    st.session_state.periodo_max_evaluacion = periodo_max_evaluacion\n",
    "                    st.session_state.porc_eval = porc_eval\n",
    "                    st.session_state.porc_eval_pronost = porc_eval_pronost\n",
    "            \n",
    "                # Evaluar y generar pronósticos\n",
    "                if \"df_periodo\" in st.session_state and \"df_ceros\" in st.session_state:\n",
    "                    st.header(\"Evaluar y Generar Pronósticos\")\n",
    "                    \n",
    "                    if st.button(\"Evaluar y Generar\"):\n",
    "                              \n",
    "                        st.session_state.pronosticos_generados = True\n",
    "                        lista_skus = crear_lista_skus(st.session_state.df_periodo)\n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Iniciando Evaluación PMS...\")\n",
    "                        with st.spinner('Evaluando Promedio Móvil Simple:'):\n",
    "                            df_mejor_n, df_forecast_pms = evaluar_y_generar_pms_nv(st.session_state.df_periodo,\n",
    "                                                                                st.session_state.df_ceros, \n",
    "                                                                                lista_skus, \n",
    "                                                                                st.session_state.periodo_max_evaluacion, \n",
    "                                                                                st.session_state.porc_eval, \n",
    "                                                                                st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                               barra_progreso,\n",
    "                                                                               status_text)\n",
    "                            \n",
    "                            grupo_mes_error_formato_pms, df_test_pms = kpi_error_lag(df_forecast_pms) # Reporte global\n",
    "                            grupo_sku_error_formato_pms, rmse_sku_lag_pms, rmse_sku_mes_pms = kpi_error_sku(df_forecast_pms) \n",
    "                            \n",
    "                        # Generar pronósticos finales\n",
    "                        with st.spinner('Generando Promedio Móvil Simple:'):\n",
    "                            df_forecast_final_pms = construir_pronostico_pms_nv(df_mejor_n, \n",
    "                                                                             st.session_state.df_periodo,\n",
    "                                                                             st.session_state.meses_a_pronosticar_produccion, \n",
    "                                                                             'pms')\n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty()\n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Iniciando Evaluación SE...\") \n",
    "                        with st.spinner('Evaluando Suavizacion Exponencial Simple:'):\n",
    "                            df_mejor_se,  df_forecast_se = encontrar_mejor_se_nv(st.session_state.df_periodo,\n",
    "                                                                              st.session_state.df_ceros, \n",
    "                                                                              lista_skus, \n",
    "                                                                              st.session_state.periodo_max_evaluacion, \n",
    "                                                                              st.session_state.porc_eval, \n",
    "                                                                              st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                               barra_progreso,\n",
    "                                                                               status_text)\n",
    "                            \n",
    "                            grupo_mes_error_formato_se, df_test_se = kpi_error_lag(df_forecast_se) \n",
    "                            grupo_sku_error_formato_se, rmse_sku_lag_se, rmse_sku_mes_se = kpi_error_sku(df_forecast_se)\n",
    "                        \n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty()                \n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Pronosticando con SE...\")     \n",
    "                        with st.spinner('Generando Suavización Exponencial:'):\n",
    "                            \n",
    "                            df_mejor_se_final,  df_forecast_final_se = encontrar_mejor_se_nv(st.session_state.df_periodo, \n",
    "                                                                                          st.session_state.df_ceros, \n",
    "                                                                                          lista_skus, \n",
    "                                                                                          st.session_state.periodo_max_evaluacion,\n",
    "                                                                                          st.session_state.porc_eval_pronost,                                                                           \n",
    "                                                                                          st.session_state.meses_a_pronosticar_produccion,\n",
    "                                                                                          barra_progreso,\n",
    "                                                                                          status_text)\n",
    "                            \n",
    "                            df_forecast_final_se = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se, 'se')\n",
    "                        \n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty()   \n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Iniciando Evaluación RL...\") \n",
    "                        with st.spinner('Evaluando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                            df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, \n",
    "                                                                                                                                                           st.session_state.df_periodo, \n",
    "                                                                                                                                                           st.session_state.df_ceros,\n",
    "                                                                                                                                                           st.session_state.periodo_max_evaluacion,\n",
    "                                                                                                                                                           st.session_state.porc_eval, \n",
    "                                                                                                                                                           st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                                                                                                            barra_progreso,\n",
    "                                                                                                                                                           status_text)\n",
    "            \n",
    "                            grupo_mes_error_formato_rl_lineal, df_test_rl_lineal= kpi_error_lag(df_forecast_rl_lineal) # Reporte global RL simple\n",
    "                            grupo_sku_error_formato_rl_lineal, rmse_sku_lag_rl_lineal, rmse_sku_mes_rl_lineal = kpi_error_sku(df_forecast_rl_lineal) # Reporte por sku RL simple\n",
    "                            grupo_mes_error_formato_rl_estacional, df_test_rl_estacional= kpi_error_lag(df_forecast_rl_estacional) # Reporte global RL estacional\n",
    "                            grupo_sku_error_formato_rl_estacional, rmse_sku_lag_rl_estacional, rmse_sku_mes_rl_estacional = kpi_error_sku(df_forecast_rl_estacional) # Reporte por sku RL estaciona\n",
    "            \n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty() \n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Pronosticando con RL...\") \n",
    "                        with st.spinner('Generando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                            df_final_mejor_rl_lineal, df_final_mejor_rl_estacional, df_forecast_final_rl_lineal, df_forecast_final_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, \n",
    "                                                                                                                                                                                    st.session_state.df_periodo, \n",
    "                                                                                                                                                                                    st.session_state.df_ceros,\n",
    "                                                                                                                                                                                    st.session_state.periodo_max_evaluacion, \n",
    "                                                                                                                                                                                    st.session_state.porc_eval_pronost, \n",
    "                                                                                                                                                                                    st.session_state.meses_a_pronosticar_produccion,\n",
    "                                                                                                                                                                                    barra_progreso,\n",
    "                                                                                                                                                                                    status_text)\n",
    "                            \n",
    "                            df_forecast_final_rl_lineal = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal, 'rl_lineal')\n",
    "                            df_forecast_final_rl_estacional = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional, 'rl_estacional')\n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty() \n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Iniciando Evaluación MSTL...\") \n",
    "                        with st.spinner('Evaluando MSTL:'):\n",
    "                            peso_ult_data = 0.08 \n",
    "                            df_mejor_mstl, df_forecast_mstl = aplicar_mstl_nv(lista_skus, st.session_state.df_periodo, \n",
    "                                                                           st.session_state.df_ceros, \n",
    "                                                                           st.session_state.periodo_max_evaluacion, \n",
    "                                                                           st.session_state.porc_eval, \n",
    "                                                                           st.session_state.meses_a_pronosticar_evaluacion, \n",
    "                                                                           peso_ult_data, \n",
    "                                                                           barra_progreso, \n",
    "                                                                           status_text)\n",
    "                            \n",
    "                            grupo_mes_error_formato_mstl, df_test_mstl = kpi_error_lag(df_forecast_mstl) # Reporte golbal\n",
    "                            grupo_sku_error_formato_mstl, rmse_sku_lag_mstl, rmse_sku_mes_mstl = kpi_error_sku(df_forecast_mstl) # Reporte por sku\n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty() \n",
    "                        barra_progreso = st.progress(0)\n",
    "                        status_text = st.text(\"Pronosticando con MSTL...\") \n",
    "                        with st.spinner('Generando MSTL:'):\n",
    "            \n",
    "                            tabla_final_pronost, df_forecast_final_mstl = aplicar_mstl_nv(lista_skus, \n",
    "                                                                                       st.session_state.df_periodo, \n",
    "                                                                                       st.session_state.df_ceros, \n",
    "                                                                                       st.session_state.periodo_max_evaluacion, \n",
    "                                                                                       st.session_state.porc_eval_pronost, \n",
    "                                                                                       st.session_state.meses_a_pronosticar_produccion, \n",
    "                                                                                       peso_ult_data, \n",
    "                                                                                       barra_progreso, \n",
    "                                                                                       status_text)\n",
    "                            \n",
    "                            df_forecast_final_mstl = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl, 'mstl')\n",
    "                        \n",
    "                        barra_progreso = st.empty()\n",
    "                        status_text = st.empty()  \n",
    "            \n",
    "                        st.success(\"✅✨ ¡Modelos Calculados Correctamente! 🎯🚀\")\n",
    "                        st.balloons()\n",
    "                        \n",
    "                        modelos = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "                        \n",
    "                        reporte_error_skus = generar_reporte_error_skus(modelos)\n",
    "                        df_todos_rmse = concatenar_rmse(modelos)\n",
    "                        df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales = comparar_y_graficar_modelos_nv(reporte_error_skus)\n",
    "                        with st.expander(\"Mostrar Estadisticas de Modelos de Pronosticos\"):\n",
    "                            st.plotly_chart(fig1)\n",
    "                        periodo_max, futuros = generar_periodos_futuros(df_periodo, st.session_state.meses_a_pronosticar_produccion)            \n",
    "                        df_todos_pronosticos = concatenar_forecasts_pronosticos(modelos)\n",
    "                        df_todos_pronosticos_fecha = agregar_fecha_a_grupo(df_todos_pronosticos, futuros)\n",
    "                        st.session_state.df_todos_pronosticos = df_todos_pronosticos\n",
    "                        st.session_state.df_todos_pronosticos_fecha  = df_todos_pronosticos_fecha \n",
    "                        \n",
    "                        df_pronosticos_mejor_modelo, df_pronosticos_12_meses = obtener_mejor_pronostico_nv(df_minimos, \n",
    "                                                                                                        st.session_state.df_todos_pronosticos_fecha, \n",
    "                                                                                                        #df_errores_totales, \n",
    "                                                                                                        #df_todos_rmse\n",
    "                                                                                                       )\n",
    "                                                                                                       \n",
    "                        st.session_state.df_pronosticos_12_meses = df_pronosticos_12_meses\n",
    "                        # Mostrar resultados\n",
    "                        st.subheader(\"Pronósticos proximas campañas\")\n",
    "                        st.write(df_pronosticos_12_meses)\n",
    "                \n",
    "                        # Mostrar gráfica final\n",
    "                        fig = crear_grafica_pronostico_nv(st.session_state.df_periodo, st.session_state.df_todos_pronosticos_fecha, df_pronosticos_mejor_modelo)\n",
    "                        st.session_state.fig = fig\n",
    "                        st.plotly_chart(fig)\n",
    "\n",
    "        with tabs[3]:\n",
    "            # Sección de filtrado (solo se muestra si df_todos_pronosticos existe)\n",
    "            if 'df_todos_pronosticos_fecha' in st.session_state and st.session_state.df_todos_pronosticos_fecha is not None:\n",
    "                st.header(\"Filtrar Pronósticos\")\n",
    "                st.text('Desea usar otro pronóstico diferente al sugerido estadísticamente?')\n",
    "                \n",
    "                # Menú desplegable para seleccionar el código\n",
    "                codigo_seleccionado = st.selectbox(\n",
    "                    \"Seleccione el Código:\",\n",
    "                    options=st.session_state.df_todos_pronosticos_fecha['CODIGO'].unique()\n",
    "                )\n",
    "                \n",
    "                # Menú desplegable para seleccionar el modelo\n",
    "                modelo_seleccionado = st.selectbox(\n",
    "                    \"Seleccione el Modelo:\",\n",
    "                    options=st.session_state.df_todos_pronosticos_fecha['MODELO'].unique()\n",
    "                )\n",
    "                if st.button('Validar Series de Tiempo'):\n",
    "                    df_filtrado = validar_pronosticos(codigo_seleccionado, \n",
    "                                                  modelo_seleccionado, \n",
    "                                                  st.session_state.df_todos_pronosticos_fecha)\n",
    "                    \n",
    "                    st.write('Datos de pronostico para codigo y modelo seleccionado:')\n",
    "                    st.dataframe(df_filtrado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
