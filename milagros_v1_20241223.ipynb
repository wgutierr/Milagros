{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7ad7e1-77a7-4b58-806a-3cd4a16c5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones Generales de Analisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funciones para graficas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Funciones estadisticas y matematicas\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "# Libreria Statsmodels\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from statsmodels.tsa.seasonal import MSTL\n",
    "\n",
    "# Libreria de Scikitlearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Funciones de Calendario y Tiempo\n",
    "import holidays\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Barra de progreso\n",
    "from tqdm import tqdm \n",
    "#from IPython.display import clear_output # Complemento barra de progreso\n",
    "\n",
    "# Manejo de advertencias\n",
    "import warnings\n",
    "\n",
    "# Libreria de Streamlit para front-end\n",
    "import streamlit as st\n",
    "\n",
    "# Funcion para exportar a excel\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd6400-bf3a-43d6-8199-b99fa6829e0e",
   "metadata": {},
   "source": [
    "# Cargar Datos Historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22baff1f-c635-443f-9272-b1b5d6429b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de carga pronosticos por mes\n",
    "def cargar_data(ruta):\n",
    "    df = pd.read_excel(ruta)\n",
    "    return df\n",
    "\n",
    "# Función de carga y listado de hojas\n",
    "def cargar_data_nv(ruta):\n",
    "    # Leer el archivo y listar las hojas\n",
    "    excel_file = pd.ExcelFile(ruta)\n",
    "    print(\"Hojas disponibles en el archivo:\")\n",
    "    for hoja in excel_file.sheet_names:\n",
    "        print(f\"- {hoja}\")    \n",
    "    # Cargar la hoja seleccionada\n",
    "    df = excel_file.parse('Historial campañas Novaventa')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fca6cb-fbe2-4514-88cf-a48f4eaf1efe",
   "metadata": {},
   "source": [
    "# Preprocesar Datos Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad55638-5dff-42d9-a0a0-212c0e6f51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los datos originales a una matriz vertical pronostico en meses\n",
    "def convertir_a_df_vertical(df):\n",
    "    # Cambiar nombres de columnas\n",
    "    df = df.rename(columns={'CÓDIGO': 'CODIGO', 'REFERENCIA':'CLIENTE'})\n",
    "    columnas_fechas = df.columns[2:]    \n",
    "    # Realizar el melt para transformar el DataFrame en formato largo\n",
    "    df_vertical = df.melt(\n",
    "        id_vars=['CODIGO', 'CLIENTE'], \n",
    "        value_vars=columnas_fechas,\n",
    "        var_name='FECHA', \n",
    "        value_name='DEMANDA'\n",
    "    )\n",
    "    return df_vertical\n",
    "    \n",
    "# Solo para Novaventa\n",
    "def preprocesar_datos_1_nv(df):\n",
    "    df['Periodo_Campaña'] = df['Año'].astype(str) + '-' + df['Campaña'].astype(str).str.zfill(2)\n",
    "    df_orig = df[['Periodo_Campaña','Referencia Novaventa',\t'Unds Brutas']].copy()\n",
    "    df_orig = df_orig.rename(columns={'Referencia Novaventa':'CODIGO','Unds Brutas':'DEMANDA','Periodo_Campaña':'FECHA'})\n",
    "    \n",
    "    return df_orig\n",
    "\n",
    "# Solo para Novaventa\n",
    "def llenar_nan(df_orig):\n",
    "    df_horiz = df_orig.pivot_table(index='CODIGO', columns='FECHA', values='DEMANDA', fill_value=0, observed=True)\n",
    "    # Reset the index of the pivot table so 'CODIGO' becomes a column again\n",
    "    df_reset = df_horiz.reset_index()\n",
    "        # Melt the DataFrame to convert it back to a vertical format\n",
    "    df_vertical = df_reset.melt(id_vars=['CODIGO'], var_name='FECHA', value_name='DEMANDA')\n",
    "    df_vertical['CODIGO'] = df_vertical['CODIGO'].astype('str')\n",
    "    return df_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87cd90-7c63-49ee-98fe-9f8b4f2340b0",
   "metadata": {},
   "source": [
    "## Mapear nombre de los meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160f9be5-7ea1-4d3b-85d1-fa92a05923c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear los nombres de las columnas a fechas en formato 'YYYY-MM-DD'\n",
    "meses = {\n",
    "    \"ENE\": \"01\", \"FEB\": \"02\", \"MAR\": \"03\", \"ABR\": \"04\", \"MAY\": \"05\", \n",
    "    \"JUN\": \"06\", \"JUL\": \"07\", \"JUl\":\"07\",\"AGO\": \"08\", \"SEPT\": \"09\", \"OCT\": \"10\", \n",
    "    \"NOV\": \"11\", \"DIC\": \"12\", \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163dcdff-b5d1-4ddd-aa94-bfb04e0dfb1b",
   "metadata": {},
   "source": [
    "## Convertir Texto a Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51747af-32d7-4278-99ac-c9c4e199403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronostico por meses\n",
    "def convertir_texto_a_fecha(df_vertical, meses):\n",
    "    # Normalizar texto en la columna 'FECHA'\n",
    "    df_vertical['FECHA'] = df_vertical['FECHA'].str.upper().str.strip()\n",
    "\n",
    "    # Extraer mes y año usando regex\n",
    "    extract = df_vertical['FECHA'].str.extract(r'([A-Z]+) (\\d{4})')\n",
    "    extract.columns = ['mes', 'año']  # Renombrar columnas para claridad\n",
    "\n",
    "    # Manejar valores no coincidentes\n",
    "    if extract.isnull().any().any():\n",
    "        no_validos = df_vertical.loc[extract.isnull().any(axis=1), 'FECHA'].unique()\n",
    "        raise ValueError(f\"Valores no coincidentes en 'FECHA': {no_validos}\")\n",
    "\n",
    "    # Formatear y convertir a fecha\n",
    "    df_vertical['FECHA'] = pd.to_datetime(\n",
    "        extract.apply(lambda x: f\"{x['año']}-{meses.get(x['mes'], '01')}-01\", axis=1)\n",
    "    )\n",
    "    \n",
    "    # Establecer 'FECHA' como índice\n",
    "    df_vertical_fecha = df_vertical.set_index('FECHA')\n",
    "    \n",
    "    return df_vertical_fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088ff95-7ed1-4f74-990b-382bb5fc1cd3",
   "metadata": {},
   "source": [
    "## Eliminar Ceros iniciales en las Series de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e85d8e-fb3f-4eca-8219-4a0e1df724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ceros_iniciales(df):\n",
    "    # Lista para almacenar DataFrames válidos\n",
    "    lista_df = []\n",
    "\n",
    "    # Obtener códigos únicos (SKU-cliente)\n",
    "    codigos_unicos = df['CODIGO'].unique()\n",
    "    clientes_unicos = df['CLIENTE'].unique()\n",
    "    \n",
    "    for codigo in codigos_unicos:\n",
    "        for cliente in clientes_unicos:\n",
    "            \n",
    "            # Filtrar los datos para cada código y cliente\n",
    "            df_codigo = df[(df['CODIGO'] == codigo) & (df['CLIENTE'] == cliente)]\n",
    "\n",
    "            # Verificar si el DataFrame no está vacío\n",
    "            if not df_codigo.empty:\n",
    "                \n",
    "                # Verificar si hay valores no cero en DEMANDA\n",
    "                if df_codigo['DEMANDA'].ne(0).any():\n",
    "                    \n",
    "                    # Encontrar la primera fila donde la demanda no es cero\n",
    "                    indice_primer_no_cero = df_codigo['DEMANDA'].ne(0).idxmax()\n",
    "\n",
    "                    # Recortar la serie temporal desde el primer valor no cero\n",
    "                    df_codigo_recortado = df_codigo.loc[indice_primer_no_cero:]\n",
    "                    \n",
    "                    # Agregar a la lista si no está vacío\n",
    "                    if not df_codigo_recortado.empty:\n",
    "                        lista_df.append(df_codigo_recortado)\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos de una vez\n",
    "    if lista_df:\n",
    "        df_resultado = pd.concat(lista_df)\n",
    "    else:\n",
    "        df_resultado = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    return df_resultado\n",
    "\n",
    "# Solo para novaventa\n",
    "def eliminar_ceros_iniciales_nv(df):\n",
    "    # Lista para almacenar DataFrames válidos\n",
    "    lista_df = []\n",
    "\n",
    "    # Obtener códigos únicos (SKU-cliente)\n",
    "    codigos_unicos = df['CODIGO'].unique()\n",
    "    #clientes_unicos = df['CLIENTE'].unique()\n",
    "    \n",
    "    for codigo in codigos_unicos:\n",
    "       \n",
    "        # Filtrar los datos para cada código y cliente\n",
    "        df_codigo = df[df['CODIGO'] == codigo]\n",
    "            # Verificar si el DataFrame no está vacío\n",
    "        if not df_codigo.empty:\n",
    "            # Verificar si hay valores no cero en DEMANDA\n",
    "            if df_codigo['DEMANDA'].ne(0).any():\n",
    "                # Encontrar la primera fila donde la demanda no es cero\n",
    "                indice_primer_no_cero = df_codigo['DEMANDA'].ne(0).idxmax()\n",
    "\n",
    "                # Recortar la serie temporal desde el primer valor no cero\n",
    "                df_codigo_recortado = df_codigo.loc[indice_primer_no_cero:]\n",
    "                \n",
    "                # Agregar a la lista si no está vacío\n",
    "                if not df_codigo_recortado.empty:\n",
    "                    lista_df.append(df_codigo_recortado)\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos de una vez\n",
    "    if lista_df:\n",
    "        df_resultado = pd.concat(lista_df)\n",
    "    else:\n",
    "        df_resultado = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2273af-cfa2-45a3-8762-1084ec0b25e6",
   "metadata": {},
   "source": [
    "# Preprocesar Datos Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818c2e94-a56b-4df0-b541-125502921757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_tabla_2(df_resultado):\n",
    "    \n",
    "    # Crear columna CODIGO_CLIENTE concatenado ambas columnas\n",
    "    df_resultado['CODIGO_CLIENTE'] = df_resultado['CODIGO'] + \"_\" + df_resultado['CLIENTE']\n",
    "    \n",
    "    # Seleccionar y copiar las columnas relevantes\n",
    "    df_mes_cliente = df_resultado[['CODIGO_CLIENTE', 'CODIGO', 'CLIENTE', 'DEMANDA']].copy()\n",
    "    \n",
    "    return df_mes_cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288c4e4-d594-40cc-993b-e027f7c39bc3",
   "metadata": {},
   "source": [
    "## Grafica Demanda Original por Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383fd498-2176-458d-b03c-2f8afcc07737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_demanda_codigo_cliente(df_mes_cliente):\n",
    "    \n",
    "    # Obtener los códigos únicos\n",
    "    codigos_unicos = df_mes_cliente['CODIGO'].unique()\n",
    "    \n",
    "    # Crear la figura de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=(len(codigos_unicos) + 2) // 3,  # Para distribuir los subplots en 3 columnas\n",
    "        cols=3,\n",
    "        shared_yaxes=False,  # No Compartir el eje Y\n",
    "        subplot_titles=[f\"Código: {codigo}\" for codigo in codigos_unicos],\n",
    "        vertical_spacing=0.02,  # Reducir el espaciado vertical entre los subplots\n",
    "    )\n",
    "    \n",
    "    # Colores específicos para clientes\n",
    "    cliente_colores = {\n",
    "        'NOVAVENTA': '#FFA500',  # Naranja\n",
    "        'DISTRIBUIDORES': \"#4682B4\",  # Azul Acero\n",
    "    }\n",
    "    \n",
    "    # Asignar un color único para los otros clientes, si los hay\n",
    "    clientes_unicos = df_mes_cliente['CLIENTE'].unique()\n",
    "    \n",
    "    for i, cliente in enumerate(clientes_unicos):\n",
    "        if cliente not in cliente_colores:\n",
    "            # Asignar un color diferente para los otros clientes\n",
    "            cliente_colores[cliente] = f\"rgb({(i * 50) % 256}, {(i * 100) % 256}, {(i * 150) % 256})\"\n",
    "    \n",
    "    # Iterar sobre cada código para agregar los subplots\n",
    "    for i, codigo in enumerate(codigos_unicos, start=1):\n",
    "        # Filtrar los datos para el código actual\n",
    "        df_codigo = df_mes_cliente[df_mes_cliente['CODIGO'] == codigo]\n",
    "        \n",
    "        # Iterar sobre los clientes y agregar una traza por cliente\n",
    "        for cliente in clientes_unicos:\n",
    "            df_cliente = df_codigo[df_codigo['CLIENTE'] == cliente]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df_cliente.index,  # Usar el índice de fecha\n",
    "                    y=df_cliente['DEMANDA'],\n",
    "                    mode='lines',\n",
    "                    name=cliente,\n",
    "                    line=dict(color=cliente_colores[cliente]),  # Asignar color específico por cliente\n",
    "                ),\n",
    "                row=(i - 1) // 3 + 1,  # Fila en la que estará el subplot\n",
    "                col=(i - 1) % 3 + 1,   # Columna en la que estará el subplot\n",
    "            )\n",
    "    \n",
    "    # Ajustar la altura total para todos los subplots y actualizar la disposición\n",
    "    fig.update_layout(\n",
    "        height=220 * ((len(codigos_unicos) + 2) // 3),  # Aumentar la altura total de los subplots\n",
    "        title_text=\"Demanda por Código y Cliente\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        showlegend=False,  # Eliminar la leyenda\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "    )\n",
    "    # Ajustar los títulos de los subplots\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "        \n",
    "    # Ajustar los títulos de los subplots y ejes\n",
    "    fig.update_xaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje X\n",
    "    fig.update_yaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje Y\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24241142-355d-4b6f-bc94-ca2c4fc28955",
   "metadata": {},
   "source": [
    "## Consolidar Demanda por Codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb819f1d-9dc5-4cb2-b99d-a9740de5467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_demanda(df_mes_cliente):\n",
    "    # Agrupar por FECHA y CÓDIGO, sumar DEMANDA\n",
    "    df_mes_orig = (\n",
    "        df_mes_cliente\n",
    "        .groupby(['FECHA', 'CODIGO'])\n",
    "        .agg({'DEMANDA': 'sum'})\n",
    "        .reset_index()\n",
    "        .set_index('FECHA')\n",
    "    )\n",
    "    \n",
    "    # Calcular el largo de cada serie de tiempo por CODIGO\n",
    "    series_length = df_mes_orig.groupby('CODIGO').size()\n",
    "    \n",
    "    # Filtrar los códigos con menos de 2 registros\n",
    "    codigos_cortos = series_length[series_length < 2].index.tolist()\n",
    "    \n",
    "    # Generar un reporte de estos códigos\n",
    "    reporte_codigos = df_mes_orig[df_mes_orig['CODIGO'].isin(codigos_cortos)]\n",
    "    \n",
    "    # Eliminar los códigos con menos de 2 registros del DataFrame original\n",
    "    df_mes_orig = df_mes_orig[~df_mes_orig['CODIGO'].isin(codigos_cortos)]\n",
    "\n",
    "    print('No se pronosticaran las siguientes referencias debido a que tienen muy pocos datos:')\n",
    "    print(reporte_codigos.groupby('CODIGO').size())\n",
    "    \n",
    "    return df_mes_orig, reporte_codigos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949b9a6-1400-4d33-8ec1-14cdba7e087e",
   "metadata": {},
   "source": [
    "## Grafica Consolidada por Codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47106a6b-91a9-432a-9e93-7611e7c59dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronostico por meses\n",
    "def graficar_demanda_codigo(df_mes_orig):\n",
    "    # Obtener los códigos únicos\n",
    "    codigos_unicos = df_mes_orig['CODIGO'].unique()\n",
    "    \n",
    "    # Crear la figura de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=(len(codigos_unicos) + 2) // 3,  # Distribuir en 3 columnas\n",
    "        cols=3,\n",
    "        shared_yaxes=False,  # No compartir el eje Y\n",
    "        subplot_titles=[f\"Código: {codigo}\" for codigo in codigos_unicos],\n",
    "        vertical_spacing=0.02,  # Reducir el espaciado entre subplots\n",
    "    )\n",
    "    \n",
    "    # Iterar sobre cada código para agregar subplots\n",
    "    for i, codigo in enumerate(codigos_unicos, start=1):\n",
    "        \n",
    "        # Filtrar los datos para el código actual\n",
    "        df_codigo = df_mes_orig[df_mes_orig['CODIGO'] == codigo]\n",
    "        \n",
    "        # Agregar una traza al subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_codigo.index,  # Usar el índice de fecha\n",
    "                y=df_codigo['DEMANDA'],\n",
    "                mode='lines',\n",
    "                name=codigo,\n",
    "                line=dict(width=2, color = \"#4682B4\"),  # Personalizar el ancho de la línea\n",
    "            ),\n",
    "            row=(i - 1) // 3 + 1,  # Fila en la que estará el subplot\n",
    "            col=(i - 1) % 3 + 1,   # Columna en la que estará el subplot\n",
    "        )\n",
    "    \n",
    "    # Ajustar el diseño general\n",
    "    fig.update_layout(\n",
    "        height=220 * ((len(codigos_unicos) + 2) // 3),  # Altura ajustada según el número de subplots        \n",
    "        title_text=\"Demanda por Código\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        showlegend=False,  # Eliminar la leyenda global\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "    )\n",
    "    # Ajustar los títulos de los subplots\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "        \n",
    "     # Ajustar los títulos de los subplots y ejes\n",
    "    fig.update_xaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje X\n",
    "    fig.update_yaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje Y\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "# Solo para pronosticos de novaventa\n",
    "def graficar_demanda_codigo_nv(df_mes_orig):\n",
    "    # Obtener los códigos únicos\n",
    "    codigos_unicos = df_mes_orig['CODIGO'].unique()\n",
    "    \n",
    "    # Crear la figura de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=(len(codigos_unicos) + 2) // 3,  # Distribuir en 3 columnas\n",
    "        cols=3,\n",
    "        shared_yaxes=False,  # No compartir el eje Y\n",
    "        subplot_titles=[f\"Código: {codigo}\" for codigo in codigos_unicos],\n",
    "        vertical_spacing=0.06,  # Reducir el espaciado entre subplots\n",
    "    )\n",
    "    \n",
    "    # Iterar sobre cada código para agregar subplots\n",
    "    for i, codigo in enumerate(codigos_unicos, start=1):\n",
    "        # Filtrar los datos para el código actual\n",
    "        df_codigo = df_mes_orig[df_mes_orig['CODIGO'] == codigo].copy()\n",
    "        # Asegurar que el índice es tratado como string\n",
    "        if 'FECHA' in df_codigo.columns:\n",
    "            df_codigo = df_codigo.set_index('FECHA')\n",
    "        df_codigo['FECHA'] = df_codigo.index.astype('str')\n",
    "        # Agregar una traza al subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_codigo.index,  # Usar el índice de fecha\n",
    "                y=df_codigo['DEMANDA'],\n",
    "                mode='lines',\n",
    "                name=codigo,\n",
    "                line=dict(width=2, color = \"#4682B4\"),  # Personalizar el ancho de la línea\n",
    "            ),\n",
    "            row=(i - 1) // 3 + 1,  # Fila en la que estará el subplot\n",
    "            col=(i - 1) % 3 + 1,   # Columna en la que estará el subplot\n",
    "        )\n",
    "    \n",
    "    # Ajustar el diseño general\n",
    "    fig.update_layout(\n",
    "        height=220 * ((len(codigos_unicos) + 2) // 3),  # Altura ajustada según el número de subplots        \n",
    "        title_text=\"Demanda por Código\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        showlegend=False,  # Eliminar la leyenda global\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "    )\n",
    "    # Ajustar los títulos de los subplots\n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "        \n",
    "     # Ajustar los títulos de los subplots y ejes\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_font=dict(size=9),  # Tamaño de fuente para los títulos del eje X\n",
    "        type='category',  # Especificar que el eje X es categórico\n",
    "        tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "    )\n",
    "    fig.update_yaxes(title_font=dict(size=9))  # Tamaño de fuente para los títulos del eje Y\n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ff199d-b60c-48bb-b821-8c68a5909dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_demanda_cliente(df_mes_cliente):\n",
    "    \n",
    "    # Generar copia de trabajo\n",
    "    df_mes_orig = df_mes_cliente.copy()\n",
    "\n",
    "    # Eliminar columnas codigo, cliente\n",
    "    df_mes_orig = df_mes_orig.drop(columns=['CODIGO','CLIENTE'])\n",
    "\n",
    "    # Renombrar columna codigo como codigo_cliente\n",
    "    df_mes_orig = df_mes_orig.rename(columns={'CODIGO_CLIENTE':'CODIGO'})\n",
    "    \n",
    "    # Calcular el largo de cada serie de tiempo por CODIGO\n",
    "    series_length = df_mes_orig.groupby('CODIGO').size()\n",
    "    \n",
    "    # Filtrar los códigos con menos de 2 registros\n",
    "    codigos_cortos = series_length[series_length < 2].index.tolist()\n",
    "    \n",
    "    # Generar un reporte de estos códigos\n",
    "    reporte_codigos = df_mes_orig[df_mes_orig['CODIGO'].isin(codigos_cortos)]\n",
    "    \n",
    "    # Eliminar los códigos con menos de 2 registros del DataFrame original\n",
    "    df_mes_orig = df_mes_orig[~df_mes_orig['CODIGO'].isin(codigos_cortos)]\n",
    "\n",
    "    print('No se pronosticaran las siguientes referencias debido a que tienen muy pocos datos:')\n",
    "    print(reporte_codigos.groupby('CODIGO').size())\n",
    "\n",
    "    return df_mes_orig, reporte_codigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5aef17a-19c2-4319-a8d6-ae2b1f06070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona si se quiere pronosticar por codigo consolidado (suministro) o por codigo_cliente\n",
    "def seleccionar_tipo_pronostico(opcion, df_mes_cliente):\n",
    "\n",
    "    # Conndicional para selecccionar tipo de pronostico\n",
    "    if opcion == 'POR_CODIGO_CLIENTE':\n",
    "        df_mes_orig, reporte_codigos = preprocesar_demanda_cliente(df_mes_cliente)\n",
    "    elif opcion == 'POR_CODIGO_AGREGADO':\n",
    "        df_mes_orig, reporte_codigos = agrupar_demanda(df_mes_cliente)\n",
    "    \n",
    "    return df_mes_orig, reporte_codigos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c4e70-500f-40d0-8a96-d1782f28e9ff",
   "metadata": {},
   "source": [
    "## Reemplazar los ceros por la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3ec628-2088-4ded-894e-e501cf1c1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por mes\n",
    "def reemplazar_ceros(df_mes_orig):\n",
    "    \n",
    "    # Generar copia de trabajo\n",
    "    df_mes_ceros = df_mes_orig.copy()\n",
    "\n",
    "    # Reemplaza los datos menores a 70 unidades (tambien considerados 0s) con la mediana de la serie de tiempo\n",
    "    df_mes_ceros['DEMANDA'] = df_mes_orig.groupby('CODIGO')['DEMANDA'].transform(\n",
    "        lambda x: x.where(x >= 70, x.median())\n",
    "    )\n",
    "    \n",
    "    return df_mes_ceros\n",
    "\n",
    "# Solo para pronosticos de novaventa:\n",
    "def reemplazar_ceros_nv(df_mes_orig):\n",
    "    \n",
    "    # Generar copia de trabajo\n",
    "    df_mes_ceros = df_mes_orig.copy()\n",
    "    # Reemplazar los valores de demanda iguales a 0 por la mediana correspondiente\n",
    "    # df_mes_ceros['DEMANDA'] = df_mes_orig.groupby('CODIGO')['DEMANDA'].transform(\n",
    "    #     lambda x: x.replace(0, x.median())\n",
    "    #     )\n",
    "    df_mes_ceros['DEMANDA'] = df_mes_orig.groupby('CODIGO')['DEMANDA'].transform(\n",
    "        lambda x: x.where(x >= 70, x.median())\n",
    "    )\n",
    "    df_mes_ceros['CONSECUTIVO'] = df_mes_ceros.groupby('CODIGO').cumcount() + 1\n",
    "    df_mes_ceros = df_mes_ceros.set_index('FECHA')\n",
    "    \n",
    "    return df_mes_ceros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b1b94-31be-4d5d-8801-fd3449dc1ee7",
   "metadata": {},
   "source": [
    "## Imputar Outliers con Lim Sup - Lim Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1a3be-b03c-42f0-a57f-a494cfcfe9cb",
   "metadata": {},
   "source": [
    "* Se crea un pronostico con n=6, para los primeros periodos se va promediando los datos disponibles hasta que tenga 6 datos\n",
    "* Se definen limites superior e inferior con base en la distribucion normal, 98% y 2% (ajustable)\n",
    "* Se aplica distribucion normal, lo que quede por fuera de limites se marca como outlier, se recalcula promedio y desviacion\n",
    "* Se establece lim_sup como pronostico + percentil 98% y lim_inf como pronostico - percentil 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d35d1a9-6143-444e-b14d-03005cafa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_outliers(df_outliers, sup, inf, n):\n",
    "    \n",
    "    # Generar un pronostico Ingenuo\n",
    "    df_outliers['FORECAST'] = df_outliers['DEMANDA'].rolling(window=n, min_periods=1).mean().shift(1)\n",
    "    \n",
    "    # Calcular la mediana de la columna DEMANDA\n",
    "    mediana_demanda = df_outliers['DEMANDA'].median()\n",
    "    \n",
    "    # Reemplazar los valores NaN en la columna FORECAST con la mediana de DEMANDA\n",
    "    df_outliers['FORECAST'] = df_outliers['FORECAST'].fillna(mediana_demanda)\n",
    "\n",
    "    # Calular error\n",
    "    df_outliers['ERROR'] = df_outliers['DEMANDA'] - df_outliers['FORECAST']\n",
    "\n",
    "    # Calcular Promedio y desviacion\n",
    "    m = df_outliers['ERROR'].mean()\n",
    "    s = df_outliers['ERROR'].std()\n",
    "\n",
    "    # Aplicar Percentil sup e inf\n",
    "    prob = norm.cdf(df_outliers['ERROR'],m,s)\n",
    "\n",
    "    # Marcar principales Outliers\n",
    "    outliers = (prob > sup) | (prob < inf)\n",
    "\n",
    "    # Recalcular promedio y desviacion SIN principales outliers\n",
    "    m2 = df_outliers.loc[~outliers,'ERROR'].mean()\n",
    "    s2 = df_outliers.loc[~outliers,'ERROR'].std()\n",
    "\n",
    "    # Calcular limite superior e inferior\n",
    "    df_outliers['LIM_SUP'] = norm.ppf(sup,m2,s2) + df_outliers['FORECAST']\n",
    "    df_outliers['LIM_INF'] = norm.ppf(inf,m2,s2) + df_outliers['FORECAST']\n",
    "\n",
    "    # Usar .clip para imputar los valores por fuera de los limites\n",
    "    df_outliers['NUEVA_DEM'] = df_outliers['DEMANDA'].clip(lower = df_outliers['LIM_INF'], upper= df_outliers['LIM_SUP'])\n",
    "\n",
    "    # Señalar los valores imputados\n",
    "    df_outliers['IS_OUTLIER'] = (df_outliers['DEMANDA'] != df_outliers['NUEVA_DEM'])\n",
    "    \n",
    "    return df_outliers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ae4de6-0898-4a2f-a101-6903351ede09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_outliers(df_mes_ceros, sup, inf, n):\n",
    "    \n",
    "    # Inicializar el DataFrame acumulado vacío\n",
    "    df_acumulado = pd.DataFrame()\n",
    "    \n",
    "    # Aplicar la función imputar_outliers a cada grupo (SKU)\n",
    "    for sku, df_sku in df_mes_ceros.groupby('CODIGO'):\n",
    "        # Asegurarse de que 'FECHA' sea el índice\n",
    "        \n",
    "        # Imputar outliers para cada SKU\n",
    "        df_imputado = imputar_outliers(df_sku.copy(), sup, inf, n)\n",
    "        \n",
    "        # Agregar el resultado al DataFrame acumulado\n",
    "        df_acumulado = pd.concat([df_acumulado, df_imputado])\n",
    "\n",
    "    # Crear copia de trabajo\n",
    "    df_outliers = df_acumulado.copy()\n",
    "\n",
    "    if 'CONSECUTIVO' in df_acumulado.columns: \n",
    "        df_acumulado = df_acumulado[['CODIGO',\t\n",
    "                             'CONSECUTIVO', \n",
    "                             'NUEVA_DEM']]\n",
    "    else:\n",
    "        df_acumulado = df_acumulado[['CODIGO',\t\n",
    "                               'NUEVA_DEM']]\n",
    "        \n",
    "    df_mes = df_acumulado.rename(columns={'NUEVA_DEM':'DEMANDA'})\n",
    "    \n",
    "    # Mostrar el DataFrame acumulado\n",
    "    reporte_outliers = df_outliers[df_outliers['IS_OUTLIER'] == True].reset_index()\n",
    "    \n",
    "    return df_mes, df_outliers, reporte_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77ba816-fe7b-4d8a-a5ea-ee3aa4c49ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_outliers_subplots(df_mes_ceros, df_outliers, sup, inf, n):\n",
    "    \n",
    "    # Lista de SKUs únicos\n",
    "    lista_skus = df_mes_ceros['CODIGO'].unique()\n",
    "    \n",
    "    # Calcular número de filas necesarias para 3 columnas\n",
    "    n_cols = 3\n",
    "    n_rows = -(-len(lista_skus) // n_cols)  # Redondeo hacia arriba\n",
    "\n",
    "    # Crear los subplots\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=[f\"SKU: {sku}\" for sku in lista_skus],\n",
    "        horizontal_spacing=0.05,\n",
    "        vertical_spacing=0.015\n",
    "    )\n",
    "    \n",
    "    # Definir colores\n",
    "    color_demanda = \"#FF6347\"  # Rojo tomate\n",
    "    color_forecast = \"#FFA500\"  # Naranja\n",
    "    color_nueva_dem = \"#4682B4\" # Azul Acero\n",
    "    \n",
    "    # Iterar por cada SKU\n",
    "    for idx, sku in enumerate(lista_skus):\n",
    "        \n",
    "        # Filtrar por SKU\n",
    "        df_outliers = df_mes_ceros[df_mes_ceros['CODIGO'] == sku][['DEMANDA']].copy()\n",
    "\n",
    "        # Aplicar función imputar_outliers\n",
    "        df_outliers = imputar_outliers(df_outliers, sup, inf, n)\n",
    "\n",
    "        # Calcular la posición en la cuadrícula\n",
    "        row = (idx // n_cols) + 1\n",
    "        col = (idx % n_cols) + 1\n",
    "\n",
    "        # Agregar trazas al subplot\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"DEMANDA\"],\n",
    "            name=f\"Demanda - {sku}\",\n",
    "            mode='lines',\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2, color=color_demanda)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"FORECAST\"],\n",
    "            mode='lines',\n",
    "            name=f\"Forecast - {sku}\",\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2.2, dash='solid', color=color_forecast)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"NUEVA_DEM\"],\n",
    "            mode='lines',\n",
    "            name=f\"Nueva Demanda - {sku}\",\n",
    "            marker=dict(size=6),\n",
    "            line=dict(width=2, dash='solid', color=color_nueva_dem)\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        # Límites superior e inferior\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"LIM_SUP\"],\n",
    "            mode='lines',\n",
    "            name=f\"Límite Superior - {sku}\",\n",
    "            line=dict(color='black', width=1, dash='dot'),\n",
    "            opacity=0.5\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_outliers.index,\n",
    "            y=df_outliers[\"LIM_INF\"],\n",
    "            mode='lines',\n",
    "            name=f\"Límite Inferior - {sku}\",\n",
    "            line=dict(color='black', width=1, dash='dot'),\n",
    "            opacity=0.5\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        # Outliers\n",
    "        if df_outliers[\"IS_OUTLIER\"].any():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_outliers.index[df_outliers[\"IS_OUTLIER\"]],\n",
    "                y=df_outliers[\"DEMANDA\"].loc[df_outliers[\"IS_OUTLIER\"]],\n",
    "                mode='markers',\n",
    "                name=f\"Outliers - {sku}\",\n",
    "                marker=dict(color=color_demanda, size=8, symbol='circle')\n",
    "            ), row=row, col=col)\n",
    "\n",
    "    # Actualizar diseño global\n",
    "    fig.update_layout(\n",
    "        title=\"Outliers vs Ventas por SKU\",\n",
    "        title_x=0.5,  # Centrar el título\n",
    "        title_font=dict(size=14),  # Tamaño de fuente del título principal\n",
    "        font=dict(size=10),  # Tamaño de fuente general\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Ajustar márgenes\n",
    "        template=\"ggplot2\",\n",
    "        height=200 * n_rows,  # Ajustar altura según filas\n",
    "        #width=900,  # Ancho fijo\n",
    "        showlegend=False  # Ocultar leyenda global\n",
    "    )\n",
    "    \n",
    "    for annotation in fig['layout']['annotations']:\n",
    "        annotation['font'] = dict(size=11)  # Reducir tamaño del texto de los títulos de subplots\n",
    "\n",
    "    if 'CONSECUTIVO' in df_mes_ceros.columns:\n",
    "        fig.update_xaxes(\n",
    "            title_font=dict(size=9),  # Tamaño de fuente para los títulos del eje X\n",
    "            type='category',  # Especificar que el eje X es categórico\n",
    "            tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "        )       \n",
    "    # Mostrar la figura\n",
    "    #fig.show()\n",
    "    st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485094ef-fd8c-4c9b-ba74-8ee333be7f41",
   "metadata": {},
   "source": [
    "# Funciones generales de ayuda para procesar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc862d2-1b6b-45ad-a6cc-97b0c44e4888",
   "metadata": {},
   "source": [
    "## Funcion para crear la lista de sku's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72bdc99-6a7c-4ee9-9778-f0a1d520e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_lista_skus(df_mes):\n",
    "    lista_skus = df_mes['CODIGO'].unique()\n",
    "    return lista_skus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99735e82-4fb2-4825-9f23-938cf510a735",
   "metadata": {},
   "source": [
    "## Funcion para calcular el numero de meses a evaluar por cada SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0d482e-60b2-41e1-9b10-531026174cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_meses_a_evaluar(df_sku, periodo_max_evaluacion, porc_eval):\n",
    "       \n",
    "    #Calculo del largo de cada serie de tiempo\n",
    "    largo_serie_tiempo = len(df_sku)\n",
    "    \n",
    "    # Calculo del numero de meses a usar como testeo de acuerdo con porc_eval\n",
    "    meses_evaluar = min(periodo_max_evaluacion, math.ceil(largo_serie_tiempo * porc_eval))\n",
    "\n",
    "    return meses_evaluar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4af96-6465-44b9-8e20-ed1e0de8aa01",
   "metadata": {},
   "source": [
    "## Funcion para crear el rango de fechas para iterar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf16bb9-3e61-4bc6-a945-f8ca270208ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_rango_fechas(df_sku, meses_evaluar):\n",
    "\n",
    "    if 'CONSECUTIVO' in df_sku.columns:\n",
    "        # Seleccionar la fecha mas reciente de los datos originales\n",
    "        ultima_fecha = df_sku['CONSECUTIVO'].max()\n",
    "        # Definimos la fecha inicial de corte - meses_evaluar -1 \n",
    "        inicio = ultima_fecha - meses_evaluar\n",
    "        # Creamos un rango de fechas comenzando en inicio y terminando en ultina_fecha, con frecuencia mensual inicio MS\n",
    "        rango_fechas = range(inicio, ultima_fecha+1)\n",
    "\n",
    "    else:\n",
    "        # Seleccionar la fecha mas reciente de los datos originales\n",
    "        ultima_fecha = df_sku.index.max()\n",
    "    \n",
    "        # Definimos la fecha inicial de corte - meses_evaluar -1 \n",
    "        inicio = ultima_fecha - pd.DateOffset(months=meses_evaluar)\n",
    "  \n",
    "        # Creamos un rango de fechas comenzando en inicio y terminando en ultina_fecha, con frecuencia mensual inicio MS\n",
    "        rango_fechas = pd.date_range(start=inicio, end=ultima_fecha, freq='MS')\n",
    "\n",
    "    return rango_fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7807d7a-4f8a-4adf-ae7f-4952f97a0c4e",
   "metadata": {},
   "source": [
    "## Funciones para calculo y medicion de metricas de error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f87910-f231-468c-a95f-b545a2685087",
   "metadata": {},
   "source": [
    "### Función para crear columnas de error, error absoluto, error porcentual y error cuadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404c97f1-da74-4d59-8049-68ca4d23a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_columnas_error(df):\n",
    "    \n",
    "    df['ERROR'] = df['DEMANDA'] - df['FORECAST'] # Error\n",
    "    df['ABS_ERROR'] = df['ERROR'].abs() # Error Absoluto\n",
    "    df['ERROR_PORC'] = np.where(df['DEMANDA'] == 0, 2, df['ABS_ERROR'] / df['DEMANDA']) # Error porcentual, devuelve 200% si la demanda es 0\n",
    "    df['ERROR_CUADRADO'] = df['ERROR'] ** 2 # Error al cuadrado\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840277c-76e3-46c3-9f92-2f94e796802c",
   "metadata": {},
   "source": [
    "### Funcion para calcular las metricas totales dado un df con columnas de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffdaa9c0-9f97-4d78-a4a6-a7db21d0c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_error(df, imprimir):\n",
    "     \n",
    "    # Verificar si el total de la demanda es 0\n",
    "    if df['DEMANDA'].sum() == 0:\n",
    "        sesgo_porc = 2\n",
    "        mae_porc = 2\n",
    "        score = 2\n",
    "    else:\n",
    "        sesgo_porc = df['ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        mae_porc = df['ABS_ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        score = mae_porc + abs(sesgo_porc)\n",
    "    \n",
    "    rmse = np.sqrt(df['ERROR_CUADRADO'].mean())\n",
    "        # Muestra los resultados formateados\n",
    "    if imprimir == 1:\n",
    "        print('MAE% modelo: {:.2%}'.format(mae_porc))\n",
    "        print('Sesgo% modelo: {:.2%}'.format(sesgo_porc))\n",
    "        print('Score modelo: {:.2%}'.format(score))\n",
    "        print('RMSE modelo: {:.1f}'.format(rmse))\n",
    "   \n",
    "    return sesgo_porc, mae_porc, rmse, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b450c-51b4-4cf7-bfa6-889d64c22148",
   "metadata": {},
   "source": [
    "### Funcion para evaluar el error por sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb6c963b-6fa0-421b-bcf8-3949ace07fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_sku(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None, None\n",
    "        \n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df.index.max()\n",
    "        fecha_inicio_testeo = df.index.min()\n",
    "\n",
    "    # Crear columnas de error para cada pronostico generado\n",
    "    df_test = crear_columnas_error(df)\n",
    "\n",
    "    # Imprimir informacion de los periodos evaluados\n",
    "    print('Periodo de Evaluacion desde:')\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test.index.min().strftime('%Y-%m')} hasta {df_test.index.max().strftime('%Y-%m')}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    \n",
    "    # Calcular metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por sku\n",
    "    grupo_sku_error = df_test.groupby(['CODIGO'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_error.columns = ['CODIGO', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    \n",
    "    # Ordenar el DataFrame por 'SCORE%' en orden ascendente\n",
    "    grupo_sku_error = grupo_sku_error.sort_values(by='SCORE%')\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_sku_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"Codigo\" sin formatear con las columnas formateadas\n",
    "    grupo_sku_error_formato = pd.concat([grupo_sku_error[['CODIGO']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    #display(grupo_sku_error_formato)\n",
    "\n",
    "    # Agrupar por codigo y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['CODIGO','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Calcular error rmse por lag\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['CODIGO','LAG','RMSE']]\n",
    "    \n",
    "    # Agrupar por codigo para almacenar RMSE\n",
    "    #df_test['Mes'] = df_test.index.month\n",
    "    grupo_sku_mes_error = df_test.groupby(['CODIGO', \n",
    "                                           #'Mes'\n",
    "                                          ], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    # Renombrar columnas\n",
    "    grupo_sku_mes_error.columns = ['CODIGO',\n",
    "                                   #'Mes', \n",
    "                                   'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular error rmse por codigo\n",
    "    grupo_sku_mes_error = calcular_error(grupo_sku_mes_error)\n",
    "\n",
    "    # Filtrar las columnas para mejor visualizacion\n",
    "    rmse_sku_mes = grupo_sku_mes_error[['CODIGO',\n",
    "                                        #'Mes',\n",
    "                                        'RMSE']]\n",
    "    \n",
    "    return grupo_sku_error_formato, rmse_sku_lag, rmse_sku_mes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44183d30-1075-4c6d-9212-383f8927f375",
   "metadata": {},
   "source": [
    "### Funcion para calcular metricas por una sola linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a0c488d-6497-41a5-bd4a-03fd42042648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error(df):\n",
    "    df['MAE%'] = df['ABS_ERROR']/df['DEMANDA']\n",
    "    df['SESGO%'] = df['ERROR']/df['DEMANDA']\n",
    "    df['SCORE%'] = df['MAE%'] + df['SESGO%'].abs()\n",
    "    if 'ERROR_CUADRADO_suma' in df.columns:\n",
    "        df['RMSE'] = np.sqrt(df['ERROR_CUADRADO_suma'] / df['ERROR_CUADRADO_cuenta'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f14827-567e-442c-a3ec-97e738696513",
   "metadata": {},
   "source": [
    "### Funcion para calcular errores por LAG para el promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "044cc5c6-882b-43ec-9c1a-001bf803e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_lags(df):\n",
    "    \n",
    "    # Calcular los scores por lag\n",
    "    df_lags = df.groupby('LAG')[['ERROR', 'ABS_ERROR', 'DEMANDA']].sum()\n",
    "    df_lags['MAE%'] = np.where(df_lags['DEMANDA'] == 0, 2,\n",
    "                            (df_lags['ABS_ERROR'] / df_lags['DEMANDA']))\n",
    "    df_lags['SESGO%'] =  np.where(df_lags['DEMANDA'] == 0, 2,\n",
    "                            (abs(df_lags['ERROR'] / df_lags['DEMANDA']))\n",
    "                                 )\n",
    "    # Calcular los scores por lag evitando la división cuando DEMANDA es cero                  \n",
    "    df_lags['SCORE%'] = np.where(df_lags['DEMANDA'] == 0, 2,\n",
    "                            (df_lags['ABS_ERROR'] / df_lags['DEMANDA']) + abs(df_lags['ERROR'] / df_lags['DEMANDA'])\n",
    "                            )\n",
    "    return df_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be4adbe8-8440-4194-a0a3-a9debe4d4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_lag(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None\n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df.index.max()\n",
    "        fecha_inicio_testeo = df.index.min()\n",
    "    \n",
    "    # Crear columnas de error  \n",
    "    df_test = crear_columnas_error(df)\n",
    "    print('Periodo de Evaluacion desde:')   \n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test.index.min().strftime('%Y-%m')} hasta {df_test.index.max().strftime('%Y-%m')}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "\n",
    "    # Calcular loas metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por mes\n",
    "    grupo_mes_error = df_test.groupby(['LAG']).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_mes_error.columns = ['LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por mes\n",
    "    grupo_mes_error = calcular_error(grupo_mes_error)\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_mes_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"Lag\" sin formatear con las columnas formateadas\n",
    "    grupo_mes_error_formato = pd.concat([grupo_mes_error[['LAG']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    #display(grupo_mes_error_formato)\n",
    "\n",
    "    # Agrupar por codigo y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['CODIGO', 'LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular columnas de error por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Filtrar columnas para mejor visualizacion\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['CODIGO', 'LAG','RMSE']]\n",
    "    \n",
    "    return grupo_mes_error_formato, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cee94df-35e6-4336-b076-e482b6320428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar df por sku\n",
    "def agrupar_por_codigo(df):\n",
    "    grupo_sku_error = df.groupby(['CODIGO'], observed=True).agg({\n",
    "                                                                'DEMANDA': 'sum',\n",
    "                                                                'ERROR': 'sum',\n",
    "                                                                'ABS_ERROR': 'sum',\n",
    "                                                                'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                                }).reset_index()\n",
    "    grupo_sku_error.columns = ['CODIGO', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                                 'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    grupo_sku_error = grupo_sku_error[['CODIGO','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "    \n",
    "    # Agrupar por codigo y por Lag \n",
    "    grupo_sku_lag_error = df.groupby(['CODIGO', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    grupo_sku_lag_error.columns = ['CODIGO','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "    grupo_sku_lag_error = grupo_sku_lag_error[['CODIGO','LAG','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "\n",
    "    # Pivotear el DataFrame de lag\n",
    "    pivoted_lags = grupo_sku_lag_error.pivot(index='CODIGO', columns='LAG', values='SCORE%')\n",
    "    pivoted_lags.columns = [f\"score_{col}\" for col in pivoted_lags.columns]\n",
    "    \n",
    "    # Unir con el DataFrame principal\n",
    "    tabla_final = grupo_sku_error.merge(pivoted_lags, on='CODIGO', how='left')\n",
    "    \n",
    "    # Renombrar columnas para cumplir con el formato\n",
    "    tabla_final = tabla_final.rename(columns={'MAE%': 'mae_porc', 'SESGO%': 'sesgo_porc', 'SCORE%': 'score', 'RMSE': 'rmse'})\n",
    "    \n",
    "    return tabla_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d9b2e-8380-42a7-a277-4aba2485ed38",
   "metadata": {},
   "source": [
    "## Funciones para formatear y graficar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb27d4d-a586-4339-bde5-f6509597e893",
   "metadata": {},
   "source": [
    "### Funcion para construir pronostico final para el promedio movil simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "304ada7d-bfe3-4ab7-836f-d16b1b08e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por mes\n",
    "def construir_pronostico_pms(df_mejor, df_mes, meses_a_pronosticar_produccion, nombre_modelo):\n",
    "\n",
    "    # Crear un nuevo DataFrame para almacenar los resultados\n",
    "    data = []\n",
    "    \n",
    "    # Iterar por cada fila de df_mejor\n",
    "    for _, row in df_mejor.iterrows():\n",
    "        codigo = row[\"CODIGO\"]\n",
    "        ultimo_forecast = row[\"ultimo_forecast\"]\n",
    "        # Generar las fechas para los meses pronosticados\n",
    "        fechas = [df_mes.index.max() + pd.DateOffset(months=i) for i in range(1, meses_a_pronosticar_produccion + 1)]\n",
    "    \n",
    "        # Generar las filas para los meses pronosticados\n",
    "        for i, fecha in enumerate(fechas, start=1):\n",
    "            data.append({\n",
    "                \"FECHA\": fecha,\n",
    "                \"CODIGO\": codigo,\n",
    "                \"FORECAST\": ultimo_forecast,\n",
    "                \"LAG\": f\"Lag_{i}\"\n",
    "            })\n",
    "    \n",
    "    # Crear el nuevo DataFrame\n",
    "    df_forecast = pd.DataFrame(data)\n",
    "    df_forecast = df_forecast.set_index('FECHA')\n",
    "    df_forecast['MODELO'] = nombre_modelo\n",
    "    \n",
    "    # Visualizar el resultado\n",
    "    return df_forecast\n",
    "\n",
    "# Solo para novaventa:\n",
    "def construir_pronostico_pms_nv(df_mejor, df_mes, meses_a_pronosticar_produccion, nombre_modelo):\n",
    "\n",
    "    # Crear un nuevo DataFrame para almacenar los resultados\n",
    "    data = []\n",
    "    \n",
    "    # Iterar por cada fila de df_mejor\n",
    "    for _, row in df_mejor.iterrows():\n",
    "        codigo = row[\"CODIGO\"]\n",
    "        ultimo_forecast = row[\"ultimo_forecast\"]\n",
    "        # Generar las fechas para los meses pronosticados\n",
    "        fechas = [df_mes['CONSECUTIVO'].max() + i for i in range(1, meses_a_pronosticar_produccion + 1)]\n",
    "    \n",
    "        # Generar las filas para los meses pronosticados\n",
    "        for i, fecha in enumerate(fechas, start=1):\n",
    "            data.append({\n",
    "                \"CONSECUTIVO\": fecha,\n",
    "                \"CODIGO\": codigo,\n",
    "                \"FORECAST\": ultimo_forecast,\n",
    "                \"LAG\": f\"Lag_{i}\"\n",
    "            })\n",
    "    \n",
    "    # Crear el nuevo DataFrame\n",
    "    df_forecast = pd.DataFrame(data)\n",
    "    #df_forecast = df_forecast.set_index('FECHA')\n",
    "    df_forecast['MODELO'] = nombre_modelo\n",
    "    \n",
    "    # Visualizar el resultado\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10268c-e8c5-45d4-9677-c1bd792c50e9",
   "metadata": {},
   "source": [
    "### Funcion para adicionar nombre del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b02e83-d159-446c-8bc4-35cb4344ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_nombre_modelo_serie_tiempo(df, nombre_modelo):\n",
    "    if df is None:\n",
    "        return None\n",
    "    df['MODELO'] = nombre_modelo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        df = df[['CODIGO','CONSECUTIVO','FORECAST','LAG','MODELO']]\n",
    "    else:\n",
    "        df = df[['CODIGO','FORECAST','LAG','MODELO']]\n",
    "    df.index.name = 'FECHA'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904229b5-839c-4fed-9682-bd10ad55c87a",
   "metadata": {},
   "source": [
    "# Modelos de Pronosticos de Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e8db9-9039-412f-bbc2-b2af096dd773",
   "metadata": {},
   "source": [
    "## Simulacion promedio movil simple PMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba8aec-18d7-4779-820e-d1cf475f81b3",
   "metadata": {},
   "source": [
    "Evalúa y genera pronósticos PMS para un grupo de SKUs, seleccionando el mejor n con base en el score.\n",
    "\n",
    "Args:\n",
    "* df_mes (DataFrame): DataFrame con datos de demanda imputando outliers por SKU.\n",
    "* df_mes_ceros (Data Frame): DataFrame con datos de demanda original (sin imputar outliers), pero con ceros reemplazados por la mediana\n",
    "* lista_skus (list): Lista de SKUs a evaluar.\n",
    "* periodo_max_evaluacion (int): Máximo numero de meses a evaluar - se mantendra en 12.\n",
    "* porc_eval (float): Porcentaje de datos (meses) a usar para evaluación.\n",
    "* meses_a_pronosticar_evaluacion (int): Número de meses a pronosticar para efectos de seleccion de modelo\n",
    "\n",
    "Devuelve:\n",
    "* DataFrame df_mejor_n: Información del mejor n, metricas, pronostico por SKU.\n",
    "* DataFrame df_forecast_pms: Datos de pronósticos seleccionados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfc9adc9-e213-4c92-914e-5a4758c8405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por mes:\n",
    "def evaluar_y_generar_pms(df_mes, df_mes_ceros, lista_skus, \n",
    "                          periodo_max_evaluacion, \n",
    "                          porc_eval, \n",
    "                          meses_a_pronosticar_evaluacion,\n",
    "                         barra_progreso,\n",
    "                         status_text):\n",
    "    \n",
    "    mejor_n = [] # Bolsa para guardar resultados por cada sku\n",
    "    acumulado_forecast = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando PMS para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        resultados_n = [] # Bolsa para guardar resultados evalaudos por cada n\n",
    "        resultados_datos_evaluacion = [] # Bolsa para guardar datos sin evaluar por cada n\n",
    "        \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_mes por cada Sku\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku\n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar aper cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "    \n",
    "        # Crear el rango de fechas para cortar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "       \n",
    "        # Tamaño de histórico n maximo y rango   \n",
    "        n_max = max(2, len(df_sku_fecha) - meses_evaluar)        \n",
    "        rango_n = range(1, n_max)\n",
    "        \n",
    "        # Iterar por cada posible tamaño de n\n",
    "        for n in rango_n: \n",
    "            \n",
    "            datos_evaluacion = []  # Bolsa para guardar resultados evaluados\n",
    "            ultimo_forecast_n = None  # Variable para almacenar el último forecast de cada n\n",
    "        \n",
    "            for fecha_corte in rango_fechas:\n",
    "                # Filtrar datos hasta la fecha de corte\n",
    "                df_sku_fecha_temp = df_sku_fecha[df_sku_fecha.index <= fecha_corte].copy()\n",
    "                \n",
    "                if len(df_sku_fecha_temp['DEMANDA']) > 1:\n",
    "                    # Calcular el forecast usando una media móvil con ventana n\n",
    "                    #print(len(df_sku_fecha_temp['DEMANDA']))\n",
    "                    df_sku_fecha_temp['FORECAST'] = df_sku_fecha_temp['DEMANDA'].rolling(window=n, min_periods=1).mean()\n",
    " \n",
    "                    forecast = [df_sku_fecha_temp['FORECAST'].iloc[-1]]\n",
    "\n",
    "                else:\n",
    "                    #forecast = [np.NaN]\n",
    "                    forecast = df_sku_fecha_temp['DEMANDA'].iloc[-1]\n",
    "                # Generar los próximos lags para el forecast actual            \n",
    "                datos_forecast = pd.DataFrame({                \n",
    "                    'fecha':fecha_corte,\n",
    "                    'n':n,\n",
    "                    'CODIGO': sku,\n",
    "                    'FORECAST': forecast,\n",
    "                    'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]}, index=[df_sku_fecha_temp.index[-1] \n",
    "                                      + pd.DateOffset(months=i) for i in range(1, meses_a_pronosticar_evaluacion + 1)]) # Genera titulo Lags dinamicamente\n",
    "                 \n",
    "                # Unir forecast con la demanda real para evaluar\n",
    "                datos_forecast_demanda = datos_forecast.merge(df_sku_fecha_ceros[['DEMANDA']], \n",
    "                                                how='left', left_index=True, right_index=True)            \n",
    "\n",
    "                # Eliminar NaN si se esta pronosticando\n",
    "                if porc_eval != 0:\n",
    "                    datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                    \n",
    "                # Acumular data frames por cada fecha\n",
    "                datos_evaluacion.append(datos_forecast_demanda)\n",
    "                \n",
    "                # Guardar el último forecast de esta iteración de fecha_corte\n",
    "                ultimo_forecast_n = datos_forecast  # Se actualiza en cada fecha_corte               \n",
    "                       \n",
    "            # Concatenar todos los DataFrames de la evaluación\n",
    "            df_evaluacion_final = pd.concat(datos_evaluacion)#.dropna()\n",
    "                       \n",
    "            # Calcular columnas de error\n",
    "            df_columnas_error = crear_columnas_error(df_evaluacion_final)\n",
    "            \n",
    "            # Calcular métricas de error\n",
    "            sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "              \n",
    "            # Calcular los scores por lag\n",
    "            df_lags = evaluar_lags(df_columnas_error)\n",
    "            \n",
    "            # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "            resultados_n.append({\n",
    "                'CODIGO':sku,\n",
    "                'parametro': n,         \n",
    "                'sesgo_porc': sesgo_porc,        \n",
    "                'mae_porc': mae_porc,        \n",
    "                'rmse': rmse,\n",
    "                'score': score,\n",
    "                **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag\n",
    "                'ultimo_forecast': forecast[0],  # Guarda el último forecast de n                \n",
    "            })                  \n",
    "\n",
    "            # Acumula los datos de pronostico para evaluacion aparte\n",
    "            resultados_datos_evaluacion.append({                \n",
    "                'score': score,\n",
    "                'datos_evaluacion': datos_evaluacion\n",
    "            })\n",
    "           \n",
    "        # Crear el DataFrame final \n",
    "        df_kpi = pd.DataFrame(resultados_n)\n",
    "        # Crear df con info del n con menor score\n",
    "        df_min_score = df_kpi[df_kpi['score'] == df_kpi['score'].min()]\n",
    "        # Seleccionar el forecast correspondiente al mejor score de df_min_score\n",
    "        forecast_optimo = df_min_score['ultimo_forecast'].iloc[0]\n",
    "        #Acumular df con resultados por sku\n",
    "        mejor_n.append(df_min_score)\n",
    "        \n",
    "        # Crear un data frame con los datos de evaluacion \n",
    "        df_kpi_datos_evaluacion = pd.DataFrame(resultados_datos_evaluacion) \n",
    "        # Seleccionar el n con menor score\n",
    "        mejor_n_row = df_kpi_datos_evaluacion[df_kpi_datos_evaluacion['score'] == df_kpi_datos_evaluacion['score'].min()].iloc[0]\n",
    "        # Recuperar los datos del mejor n\n",
    "        mejor_n_datos = mejor_n_row['datos_evaluacion']  \n",
    "       # Almacenar los datos del mejor n para este SKU\n",
    "        acumulado_forecast.extend(mejor_n_datos)     \n",
    "       \n",
    "    # Concatenar mejor_n para obtener un solo df\n",
    "    df_mejor_n = pd.concat(mejor_n)\n",
    "    # Eliminar duplicados conservando solo el primer codigo\n",
    "    df_mejor_n = df_mejor_n.drop_duplicates(subset='CODIGO', keep='first')\n",
    "    # Mover ultimo_forecast a la ultima columna\n",
    "    columnas = [col for col in df_mejor_n.columns if col != 'ultimo_forecast'] + ['ultimo_forecast']\n",
    "    df_mejor_n = df_mejor_n[columnas]\n",
    "    \n",
    "    df_forecast_pms = pd.concat(acumulado_forecast, ignore_index=False)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()  \n",
    "    return df_mejor_n, df_forecast_pms \n",
    "\n",
    "# Solo para novaventa:\n",
    "def evaluar_y_generar_pms_nv(df_mes, df_mes_ceros, lista_skus, \n",
    "                          periodo_max_evaluacion, \n",
    "                          porc_eval, \n",
    "                          meses_a_pronosticar_evaluacion,\n",
    "                         barra_progreso,\n",
    "                         status_text):\n",
    "    \n",
    "    mejor_n = [] # Bolsa para guardar resultados por cada sku\n",
    "    acumulado_forecast = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando PMS para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        resultados_n = [] # Bolsa para guardar resultados evalaudos por cada n\n",
    "        resultados_datos_evaluacion = [] # Bolsa para guardar datos sin evaluar por cada n\n",
    "        \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_mes por cada Sku\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku\n",
    "\n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar aper cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        #print('meses_evaluar:',meses_evaluar)\n",
    "        # Crear el rango de fechas para cortar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        #print('rango_fechas:',rango_fechas)  \n",
    "        # Tamaño de histórico n maximo y rango   \n",
    "        n_max = max(2, len(df_sku_fecha) - meses_evaluar)        \n",
    "        rango_n = range(1, n_max)\n",
    "        #print('n, rango_n:',n_max, rango_n) \n",
    "        # Iterar por cada posible tamaño de n\n",
    "        for n in rango_n: \n",
    "            \n",
    "            datos_evaluacion = []  # Bolsa para guardar resultados evaluados\n",
    "            ultimo_forecast_n = None  # Variable para almacenar el último forecast de cada n\n",
    "        \n",
    "            for fecha_corte in rango_fechas:\n",
    "                # Filtrar datos hasta la fecha de corte\n",
    "                df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()\n",
    "                \n",
    "                if len(df_sku_fecha_temp['DEMANDA']) > 1:\n",
    "                    # Calcular el forecast usando una media móvil con ventana n\n",
    "                    #print(len(df_sku_fecha_temp['DEMANDA']))\n",
    "                    df_sku_fecha_temp['FORECAST'] = df_sku_fecha_temp['DEMANDA'].rolling(window=n, min_periods=1).mean()\n",
    " \n",
    "                    forecast = [df_sku_fecha_temp['FORECAST'].iloc[-1]]\n",
    "                    \n",
    "                else:\n",
    "                    forecast = df_sku_fecha_temp['DEMANDA'].iloc[-1]\n",
    "                \n",
    "                # Generar los próximos lags para el forecast actual            \n",
    "                datos_forecast = pd.DataFrame({                \n",
    "                    'fecha':fecha_corte,\n",
    "                    'n':n,\n",
    "                    'CODIGO': sku,\n",
    "                    'FORECAST': forecast,\n",
    "                    'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]}, \n",
    "                    index=[df_sku_fecha_temp['CONSECUTIVO'].iloc[-1] \n",
    "                                      + i for i in range(1, meses_a_pronosticar_evaluacion + 1)]) # Genera titulo Lags dinamicamente\n",
    "                datos_forecast = datos_forecast.reset_index()\n",
    "\n",
    "                # Step 2: Rename the index column to match the key in df_sku_fecha_ceros\n",
    "                datos_forecast = datos_forecast.rename(columns={'index': 'CONSECUTIVO'})\n",
    "                           \n",
    "                datos_forecast_demanda = datos_forecast.merge(\n",
    "                    df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']],\n",
    "                    how='left',\n",
    "                    on='CONSECUTIVO'\n",
    "                )\n",
    "  \n",
    "                # Eliminar NaN si se esta pronosticando\n",
    "                if porc_eval != 0:\n",
    "                    datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                    \n",
    "                # Acumular data frames por cada fecha\n",
    "                datos_evaluacion.append(datos_forecast_demanda)\n",
    "                \n",
    "                # Guardar el último forecast de esta iteración de fecha_corte\n",
    "                ultimo_forecast_n = datos_forecast  # Se actualiza en cada fecha_corte               \n",
    "                       \n",
    "            # Concatenar todos los DataFrames de la evaluación\n",
    "            df_evaluacion_final = pd.concat(datos_evaluacion)#.dropna()\n",
    "                     \n",
    "            # Calcular columnas de error\n",
    "            df_columnas_error = crear_columnas_error(df_evaluacion_final)\n",
    "            \n",
    "            # Calcular métricas de error\n",
    "            sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "              \n",
    "            # Calcular los scores por lag\n",
    "            df_lags = evaluar_lags(df_columnas_error)\n",
    "            \n",
    "            # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "            resultados_n.append({\n",
    "                'CODIGO':sku,\n",
    "                'parametro': n,         \n",
    "                'sesgo_porc': sesgo_porc,        \n",
    "                'mae_porc': mae_porc,        \n",
    "                'rmse': rmse,\n",
    "                'score': score,\n",
    "                **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag\n",
    "                'ultimo_forecast': forecast[0],  # Guarda el último forecast de n                \n",
    "            })                  \n",
    "\n",
    "            # Acumula los datos de pronostico para evaluacion aparte\n",
    "            resultados_datos_evaluacion.append({                \n",
    "                'score': score,\n",
    "                'datos_evaluacion': datos_evaluacion\n",
    "            })\n",
    "           \n",
    "        # Crear el DataFrame final \n",
    "        df_kpi = pd.DataFrame(resultados_n)\n",
    "        #display(df_kpi) \n",
    "        # Crear df con info del n con menor score\n",
    "        df_min_score = df_kpi[df_kpi['score'] == df_kpi['score'].min()]\n",
    "        # Seleccionar el forecast correspondiente al mejor score de df_min_score\n",
    "        forecast_optimo = df_min_score['ultimo_forecast'].iloc[0]\n",
    "        #Acumular df con resultados por sku\n",
    "        mejor_n.append(df_min_score)\n",
    "        \n",
    "        # Crear un data frame con los datos de evaluacion \n",
    "        df_kpi_datos_evaluacion = pd.DataFrame(resultados_datos_evaluacion) \n",
    "        # Seleccionar el n con menor score\n",
    "        mejor_n_row = df_kpi_datos_evaluacion[df_kpi_datos_evaluacion['score'] == df_kpi_datos_evaluacion['score'].min()].iloc[0]\n",
    "        # Recuperar los datos del mejor n\n",
    "        mejor_n_datos = mejor_n_row['datos_evaluacion']  \n",
    "       # Almacenar los datos del mejor n para este SKU\n",
    "        acumulado_forecast.extend(mejor_n_datos)     \n",
    "       \n",
    "    # Concatenar mejor_n para obtener un solo df\n",
    "    df_mejor_n = pd.concat(mejor_n)\n",
    "    # Eliminar duplicados conservando solo el primer codigo\n",
    "    df_mejor_n = df_mejor_n.drop_duplicates(subset='CODIGO', keep='first')\n",
    "    # Mover ultimo_forecast a la ultima columna\n",
    "    columnas = [col for col in df_mejor_n.columns if col != 'ultimo_forecast'] + ['ultimo_forecast']\n",
    "    df_mejor_n = df_mejor_n[columnas]\n",
    "    \n",
    "    df_forecast_pms = pd.concat(acumulado_forecast, ignore_index=False)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()  \n",
    "    return df_mejor_n, df_forecast_pms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46513447-451e-4703-a338-1256f9900a51",
   "metadata": {},
   "source": [
    "## Suavizacion Exponencial Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "538c1cd8-01e6-404d-8e7f-1f667df10f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_se(df_mes, df_mes_ceros, lista_skus, periodo_max_evaluacion, porc_eval, \n",
    "                        meses_a_pronosticar_evaluacion,\n",
    "                        barra_progreso,\n",
    "                        status_text):\n",
    "    \n",
    "    mejor_se = [] # Bolsa para guardar resultados por cada sku\n",
    "    resultados_se = []  # Bolsa para guardar resultados por cada n\n",
    "    acumulado_df_evaluacion_final = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando SE para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        datos_evaluacion_se = []  # Bolsa para guardar resultados de evaluación por fecha\n",
    "                \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "    \n",
    "        # Crear el rango de fechas para corar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            \n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha.index <= fecha_corte].copy()                 \n",
    "    \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "\n",
    "            # Chequeo de la longitud de cada serie de tiempo\n",
    "            if len(demanda) < 2:\n",
    "                print(f'El sku {sku} no tiene suficientes datos para la fecha de corte {fecha_corte}') # Ver SKUs con datos insuficientes y su fecha de corte\n",
    "                forecast = np.NaN\n",
    "            else:                            \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    model = SimpleExpSmoothing(demanda).fit(smoothing_level=None, optimized=True)\n",
    "   \n",
    "                    # Calcular pronostico para los proximos periodos\n",
    "                    forecast = model.forecast(steps=meses_a_pronosticar_evaluacion)\n",
    "                           \n",
    "                    # Generar los próximos lags para el forecast actual            \n",
    "                    datos_forecast = pd.DataFrame({\n",
    "                        'fecha':fecha_corte,\n",
    "                        'CODIGO': sku,\n",
    "                        'FORECAST': forecast,\n",
    "                        'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]\n",
    "                                }, \n",
    "                        index=[df_sku_fecha_temp.index[-1] \n",
    "                                          + pd.DateOffset(months=i) for i in range(1,  meses_a_pronosticar_evaluacion + 1)])\n",
    "                    \n",
    "                    # Unir forecast con la demanda real para evaluar\n",
    "                    datos_forecast_demanda = datos_forecast.merge(df_sku_fecha_ceros[['DEMANDA']], \n",
    "                                                    how='left', left_index=True, right_index=True)\n",
    "\n",
    "                    if porc_eval != 0:\n",
    "                        datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                                        \n",
    "                    # Acumular datos para evaluar el pronostico\n",
    "                    datos_evaluacion_se.append(datos_forecast_demanda)\n",
    "                    \n",
    "                    # Guardar el último alfa de esta iteración de fecha_corte\n",
    "                    ultimo_forecast_alfa = model.params['smoothing_level']  # Se actualiza en cada fecha_corte\n",
    "\n",
    "       # Concatenar df_evaluacion para obtener un solo df\n",
    "        df_evaluacion = pd.concat(datos_evaluacion_se)\n",
    "\n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        df_evaluacion_final = df_evaluacion.copy()\n",
    "\n",
    "        # Acumular los datos de evaluacion por fecha\n",
    "        acumulado_df_evaluacion_final.append(df_evaluacion_final)\n",
    "                     \n",
    "        # Calcular columnas de error sobre df inicial de evaluacion\n",
    "        df_columnas_error = crear_columnas_error(df_evaluacion)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags = evaluar_lags(df_columnas_error)\n",
    "       \n",
    "        # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "        resultados_se.append({\n",
    "            'CODIGO' : sku,\n",
    "            'parametro': ultimo_forecast_alfa,            \n",
    "            'sesgo_porc': sesgo_porc,            \n",
    "            'mae_porc': mae_porc,            \n",
    "            'rmse': rmse,\n",
    "            'score': score,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag               \n",
    "            'ultimo_forecast': forecast[0]  # Guarda el último forecast            \n",
    "        })\n",
    "           \n",
    "    # Crear el DataFrame con los resultados\n",
    "    df_kpi = pd.DataFrame(resultados_se)\n",
    "\n",
    "    # Acumular por cada sku\n",
    "    mejor_se.append(df_kpi)\n",
    "\n",
    "    # Concatenar para obtener un solo df\n",
    "    df_mejor_se = pd.concat(mejor_se)\n",
    "\n",
    "    # Concatener acumulado de matriz de datos de evaluacion para obtener un solo df\n",
    "    df_forecast_se = pd.concat(acumulado_df_evaluacion_final)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return df_mejor_se,  df_forecast_se\n",
    "\n",
    "# Solo para novaventa\n",
    "def encontrar_mejor_se_nv(df_mes, df_mes_ceros, lista_skus, periodo_max_evaluacion, porc_eval, \n",
    "                        meses_a_pronosticar_evaluacion,\n",
    "                        barra_progreso,\n",
    "                        status_text):\n",
    "    \n",
    "    mejor_se = [] # Bolsa para guardar resultados por cada sku\n",
    "    resultados_se = []  # Bolsa para guardar resultados por cada n\n",
    "    acumulado_df_evaluacion_final = [] # Bolsa para guardar los resultados de todos los pronosticos\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando SE para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        datos_evaluacion_se = []  # Bolsa para guardar resultados de evaluación por fecha\n",
    "                \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        #meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        # Crear el rango de fechas para corar el set de datos de acuerdo con meses a evaluar\n",
    "        #rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            \n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()                 \n",
    "    \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "\n",
    "            # Chequeo de la longitud de cada serie de tiempo\n",
    "            if len(demanda) < 2:\n",
    "                print(f'El sku {sku} no tiene suficientes datos para la fecha de corte {fecha_corte}') # Ver SKUs con datos insuficientes y su fecha de corte\n",
    "                forecast = np.NaN\n",
    "            else:                            \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    model = SimpleExpSmoothing(demanda).fit(smoothing_level=None, optimized=True)\n",
    "   \n",
    "                    # Calcular pronostico para los proximos periodos\n",
    "                    forecast = model.forecast(steps=meses_a_pronosticar_evaluacion)\n",
    "                           \n",
    "                    # Generar los próximos lags para el forecast actual            \n",
    "                    datos_forecast = pd.DataFrame({\n",
    "                        'FECHA':fecha_corte,\n",
    "                        'CODIGO': sku,\n",
    "                        'FORECAST': forecast,\n",
    "                        'LAG': [f'Lag_{i}' for i in range(1, meses_a_pronosticar_evaluacion + 1)]\n",
    "                                }, \n",
    "                        index=[df_sku_fecha_temp['CONSECUTIVO'].iloc[-1]\n",
    "                                          + i for i in range(1,  meses_a_pronosticar_evaluacion + 1)])\n",
    "                    datos_forecast = datos_forecast.reset_index()\n",
    "                    datos_forecast = datos_forecast.rename(columns={'index': 'CONSECUTIVO'})\n",
    "                    # Unir forecast con la demanda real para evaluar\n",
    "                    datos_forecast_demanda = datos_forecast.merge(\n",
    "                                        df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']],\n",
    "                                        how='left',\n",
    "                                        on='CONSECUTIVO'\n",
    "                                    )\n",
    "\n",
    "                    if porc_eval != 0:\n",
    "                        datos_forecast_demanda = datos_forecast_demanda.dropna()\n",
    "                                        \n",
    "                    # Acumular datos para evaluar el pronostico\n",
    "                    datos_evaluacion_se.append(datos_forecast_demanda)\n",
    "                    \n",
    "                    # Guardar el último alfa de esta iteración de fecha_corte\n",
    "                    ultimo_forecast_alfa = model.params['smoothing_level']  # Se actualiza en cada fecha_corte\n",
    "\n",
    "       # Concatenar df_evaluacion para obtener un solo df\n",
    "        df_evaluacion = pd.concat(datos_evaluacion_se)\n",
    "\n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        df_evaluacion_final = df_evaluacion.copy()\n",
    "\n",
    "        # Acumular los datos de evaluacion por fecha\n",
    "        acumulado_df_evaluacion_final.append(df_evaluacion_final)\n",
    "                     \n",
    "        # Calcular columnas de error sobre df inicial de evaluacion\n",
    "        df_columnas_error = crear_columnas_error(df_evaluacion)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc, mae_porc, rmse, score = metricas_error(df_columnas_error, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags = evaluar_lags(df_columnas_error)\n",
    "       \n",
    "        # Agregar resultados y el último forecast de cada n a la lista resultados_n\n",
    "        resultados_se.append({\n",
    "            'CODIGO' : sku,\n",
    "            'parametro': ultimo_forecast_alfa,            \n",
    "            'sesgo_porc': sesgo_porc,            \n",
    "            'mae_porc': mae_porc,            \n",
    "            'rmse': rmse,\n",
    "            'score': score,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags.index, df_lags['SCORE%'])},  # Agrega dinámicamente scores por lag               \n",
    "            'ultimo_forecast': forecast[0]  # Guarda el último forecast            \n",
    "        })\n",
    "           \n",
    "    # Crear el DataFrame con los resultados\n",
    "    df_kpi = pd.DataFrame(resultados_se)\n",
    "\n",
    "    # Acumular por cada sku\n",
    "    mejor_se.append(df_kpi)\n",
    "\n",
    "    # Concatenar para obtener un solo df\n",
    "    df_mejor_se = pd.concat(mejor_se)\n",
    "\n",
    "    # Concatener acumulado de matriz de datos de evaluacion para obtener un solo df\n",
    "    df_forecast_se = pd.concat(acumulado_df_evaluacion_final)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return df_mejor_se,  df_forecast_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ceb5b5-0397-4b56-9f25-70ef99a1bed1",
   "metadata": {},
   "source": [
    "## Regresion lineal simple y estacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "564ba6ae-860f-4eb9-bb6b-0fb236766d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por mes\n",
    "def aplicar_regresion_lineal_simple(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text):\n",
    "   \n",
    "    resultados_datos_forecast_demanda_lineal = []\n",
    "    resultados_datos_forecast_demanda_estacional = []\n",
    "    resultados_rl_lineal = []\n",
    "    resultados_rl_estacional = []\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando RL para SKU N° {i + 1} de {total_series}...\")\n",
    "    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        #resultados_rl_lineal = []\n",
    "        #resultados_rl_estacional = []\n",
    "        resultados_regresion_lineal = []  \n",
    "        resultados_regresion_estacional = []  \n",
    "                    \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        \n",
    "        # Crear el rango de fechas para cortar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        \n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha.index <= fecha_corte].copy()                 \n",
    "            \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            \n",
    "            if len(demanda) >= 4:\n",
    "                # Generar y adecuar la variable independiente tiempo\n",
    "                X = np.arange(1, len(demanda)+1).reshape(-1, 1)\n",
    "                y = demanda\n",
    "                # Modelo de Regresión Lineal\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Pronóstico para los próximos 6 periodos\n",
    "                limite_sup_pronost = len(demanda)+1 + meses_a_pronosticar_evaluacion\n",
    "                X_futuro = np.arange(len(demanda)+1, limite_sup_pronost).reshape(-1, 1)\n",
    "                y_futuro_lineal = model.predict(X_futuro)\n",
    "\n",
    "                if len(demanda) >= 12:\n",
    "                    factores_estacionales_mes = demanda[-12:] / demanda[-12:].mean() \n",
    "                    y_futuro_estacional =  y_futuro_lineal * factores_estacionales_mes[:len(y_futuro_lineal)]\n",
    "                else:    \n",
    "                    y_futuro_estacional = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            else:\n",
    "                print(f\"Sin datos: SKU={sku}, Fecha={fecha_corte}, Datos disponibles={len(demanda)}\") \n",
    "                y_futuro_lineal = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            # Almacenar los resultados lineales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_lineal):\n",
    "                fecha_pronostico = df_sku_fecha_temp.index.max() + pd.DateOffset(months=(periodo-len(demanda)))\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_lineal.append({'CODIGO': sku, 'PERIODO': periodo, 'FECHA': fecha_pronostico, 'FORECAST': prediccion, 'LAG': lag})\n",
    "\n",
    "            # Almacenar los resultados estacionales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_estacional):\n",
    "                fecha_pronostico = df_sku_fecha_temp.index.max() + pd.DateOffset(months=(periodo-len(demanda)))\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_estacional.append({'CODIGO': sku, 'PERIODO': periodo, 'FECHA': fecha_pronostico, 'FORECAST': prediccion, 'LAG': lag})\n",
    "        \n",
    "        df_forecast_regresion_lineal = pd.DataFrame(resultados_regresion_lineal)#.set_index('FECHA')\n",
    "        df_forecast_regresion_lineal = df_forecast_regresion_lineal.set_index('FECHA')\n",
    "\n",
    "        df_forecast_regresion_estacional = pd.DataFrame(resultados_regresion_estacional).set_index('FECHA')\n",
    "        \n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_lineal = df_forecast_regresion_lineal.merge(\n",
    "            df_mes_ceros[['CODIGO', 'DEMANDA']], \n",
    "            how='left', \n",
    "            left_on=['CODIGO', df_forecast_regresion_lineal.index], \n",
    "            right_on=['CODIGO', df_mes_ceros.index]\n",
    "        )\n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_estacional = df_forecast_regresion_estacional.merge(\n",
    "            df_mes_ceros[['CODIGO', 'DEMANDA']], \n",
    "            how='left', \n",
    "            left_on=['CODIGO', df_forecast_regresion_estacional.index], \n",
    "            right_on=['CODIGO', df_mes_ceros.index]\n",
    "        )\n",
    "        # Condicionar eliminacion de NaN a si es evaluacion o generacion de pronostico\n",
    "        if porc_eval != 0:\n",
    "            datos_forecast_demanda_lineal = datos_forecast_demanda_lineal.dropna()\n",
    "            datos_forecast_demanda_estacional = datos_forecast_demanda_estacional.dropna()\n",
    "            \n",
    "        # Renombrar la columna 'key_1' a 'FECHA' y Establecer 'FECHA' como el índice\n",
    "        datos_forecast_demanda_lineal = datos_forecast_demanda_lineal.rename(columns={'key_1': 'FECHA'}).set_index('FECHA')\n",
    "        # Renombrar la columna 'key_1' a 'FECHA' y Establecer 'FECHA' como el índice\n",
    "        datos_forecast_demanda_estacional = datos_forecast_demanda_estacional.rename(columns={'key_1': 'FECHA'}).set_index('FECHA')\n",
    "    \n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        datos_forecast_demanda_lineal_final = datos_forecast_demanda_lineal.copy() \n",
    "        datos_forecast_demanda_estacional_final = datos_forecast_demanda_estacional.copy() \n",
    "        \n",
    "        resultados_datos_forecast_demanda_lineal.append(datos_forecast_demanda_lineal_final)\n",
    "        resultados_datos_forecast_demanda_estacional.append(datos_forecast_demanda_estacional_final)\n",
    "        \n",
    "        # Calcular columnas de error sobre df inicial de evaluación\n",
    "        df_columnas_error_lineal = crear_columnas_error(datos_forecast_demanda_lineal)\n",
    "        df_columnas_error_estacional = crear_columnas_error(datos_forecast_demanda_estacional)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc_lineal, mae_porc_lineal, rmse_lineal, score_lineal = metricas_error(df_columnas_error_lineal, imprimir=0)\n",
    "        sesgo_porc_estacional, mae_porc_estacional, rmse_estacional, score_estacional = metricas_error(df_columnas_error_estacional, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags_lineal = evaluar_lags(df_columnas_error_lineal)\n",
    "        df_lags_estacional = evaluar_lags(df_columnas_error_estacional)\n",
    "        \n",
    "        # Guardar KPIs lineales\n",
    "        resultados_rl_lineal.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_lineal,\n",
    "            'mae_porc': mae_porc_lineal,\n",
    "            'rmse': rmse_lineal,\n",
    "            'score': score_lineal,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_lineal.index, df_lags_lineal['SCORE%'])},              \n",
    "        })\n",
    "        \n",
    "        # Guardar KPIs estacionales\n",
    "        resultados_rl_estacional.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_estacional,\n",
    "            'mae_porc': mae_porc_estacional,\n",
    "            'rmse': rmse_estacional,\n",
    "            'score': score_estacional,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_estacional.index, df_lags_estacional['SCORE%'])},              \n",
    "        })\n",
    "    # Concatenar resultados acumulados\n",
    "    df_forecast_rl_lineal = pd.concat(resultados_datos_forecast_demanda_lineal, ignore_index=False)\n",
    "    df_forecast_rl_estacional = pd.concat(resultados_datos_forecast_demanda_estacional, ignore_index=False) \n",
    "    \n",
    "    # Crear el DataFrame con los resultados de KPIs\n",
    "    df_mejor_rl_lineal = pd.DataFrame(resultados_rl_lineal)\n",
    "    df_mejor_rl_estacional = pd.DataFrame(resultados_rl_estacional)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()                                     \n",
    "    # Visualizar resultados\n",
    "    return df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional\n",
    "\n",
    "# Solo para novaventa:\n",
    "def aplicar_regresion_lineal_simple_nv(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text):\n",
    "   \n",
    "    resultados_datos_forecast_demanda_lineal = []\n",
    "    resultados_datos_forecast_demanda_estacional = []\n",
    "    resultados_rl_lineal = []\n",
    "    resultados_rl_estacional = []\n",
    "    total_series = len(lista_skus)  \n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando RL para SKU N° {i + 1} de {total_series}...\")\n",
    "        \n",
    "        resultados_regresion_lineal = []  \n",
    "        resultados_regresion_estacional = []  \n",
    "                    \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_almacen_semana por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        #meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    " \n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()                 \n",
    "            \n",
    "            # Extraer la demanda como un array\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            \n",
    "            if len(demanda) >= 4:\n",
    "                # Generar y adecuar la variable independiente tiempo\n",
    "                X = np.arange(1, len(demanda)+1).reshape(-1, 1)\n",
    "                y = demanda\n",
    "                # Modelo de Regresión Lineal\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Pronóstico para los próximos periodos\n",
    "                limite_sup_pronost = len(demanda)+1 + meses_a_pronosticar_evaluacion\n",
    "                X_futuro = np.arange(len(demanda)+1, limite_sup_pronost).reshape(-1, 1)\n",
    "                y_futuro_lineal = model.predict(X_futuro)\n",
    "\n",
    "                if len(demanda) >= 19:\n",
    "                    factores_estacionales_mes = demanda[-19:] / demanda[-19:].mean() \n",
    "                    y_futuro_estacional =  y_futuro_lineal * factores_estacionales_mes[:len(y_futuro_lineal)]\n",
    "                else:    \n",
    "                    y_futuro_estacional = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            else:\n",
    "                print(f\"Sin datos: SKU={sku}, Fecha={fecha_corte}, Datos disponibles={len(demanda)}\") \n",
    "                y_futuro_lineal = [np.NaN] * meses_a_pronosticar_evaluacion \n",
    "            \n",
    "            # Almacenar los resultados lineales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_lineal):\n",
    "                fecha_pronostico = df_sku_fecha_temp['CONSECUTIVO'].max() + periodo-len(demanda)\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_lineal.append({'CODIGO': sku, \n",
    "                                                    'CONSECUTIVO': periodo, \n",
    "                                                    'FECHA': fecha_corte, \n",
    "                                                    'FORECAST': prediccion, \n",
    "                                                    'LAG': lag})\n",
    "                #display(resultados_regresion_lineal)\n",
    "            # Almacenar los resultados estacionales con código y periodo\n",
    "            for periodo, prediccion in zip(range(len(demanda)+1, limite_sup_pronost), y_futuro_estacional):\n",
    "                fecha_pronostico = df_sku_fecha_temp['CONSECUTIVO'].max() + periodo-len(demanda)\n",
    "                lag = f\"Lag_{periodo - len(demanda)}\"\n",
    "                resultados_regresion_estacional.append({'CODIGO': sku, \n",
    "                                                        'CONSECUTIVO': periodo, \n",
    "                                                        'FECHA': fecha_corte, \n",
    "                                                        'FORECAST': prediccion, \n",
    "                                                        'LAG': lag})\n",
    "        \n",
    "        df_forecast_regresion_lineal = pd.DataFrame(resultados_regresion_lineal)#.set_index('FECHA')\n",
    "        #df_forecast_regresion_lineal = df_forecast_regresion_lineal.set_index('FECHA')\n",
    "        #display( df_forecast_regresion_lineal)\n",
    "        df_forecast_regresion_estacional = pd.DataFrame(resultados_regresion_estacional)#.set_index('FECHA')\n",
    "        \n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_lineal = df_forecast_regresion_lineal.merge(\n",
    "            df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']], \n",
    "            how='left', \n",
    "            on='CONSECUTIVO', \n",
    "            \n",
    "        )\n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_demanda_estacional = df_forecast_regresion_estacional.merge(\n",
    "            df_sku_fecha_ceros[['DEMANDA', 'CONSECUTIVO']], \n",
    "            how='left', \n",
    "            on='CONSECUTIVO', \n",
    "        )\n",
    "        # Condicionar eliminacion de NaN a si es evaluacion o generacion de pronostico\n",
    "        if porc_eval != 0:\n",
    "            datos_forecast_demanda_lineal = datos_forecast_demanda_lineal.dropna()\n",
    "            datos_forecast_demanda_estacional = datos_forecast_demanda_estacional.dropna()           \n",
    "    \n",
    "        # Generar una copia de los datos de evaluacion para analizar aparte\n",
    "        datos_forecast_demanda_lineal_final = datos_forecast_demanda_lineal.copy() \n",
    "        datos_forecast_demanda_estacional_final = datos_forecast_demanda_estacional.copy() \n",
    "        \n",
    "        resultados_datos_forecast_demanda_lineal.append(datos_forecast_demanda_lineal_final)\n",
    "        resultados_datos_forecast_demanda_estacional.append(datos_forecast_demanda_estacional_final)\n",
    "        \n",
    "        # Calcular columnas de error sobre df inicial de evaluación\n",
    "        df_columnas_error_lineal = crear_columnas_error(datos_forecast_demanda_lineal)\n",
    "        df_columnas_error_estacional = crear_columnas_error(datos_forecast_demanda_estacional)\n",
    "        \n",
    "        # Calcular métricas de error\n",
    "        sesgo_porc_lineal, mae_porc_lineal, rmse_lineal, score_lineal = metricas_error(df_columnas_error_lineal, imprimir=0)\n",
    "        sesgo_porc_estacional, mae_porc_estacional, rmse_estacional, score_estacional = metricas_error(df_columnas_error_estacional, imprimir=0)\n",
    "        \n",
    "        # Calcular los scores por lag\n",
    "        df_lags_lineal = evaluar_lags(df_columnas_error_lineal)\n",
    "        df_lags_estacional = evaluar_lags(df_columnas_error_estacional)\n",
    "        \n",
    "        # Guardar KPIs lineales\n",
    "        resultados_rl_lineal.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_lineal,\n",
    "            'mae_porc': mae_porc_lineal,\n",
    "            'rmse': rmse_lineal,\n",
    "            'score': score_lineal,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_lineal.index, df_lags_lineal['SCORE%'])},              \n",
    "        })\n",
    "        \n",
    "        # Guardar KPIs estacionales\n",
    "        resultados_rl_estacional.append({\n",
    "            'CODIGO': sku,\n",
    "            'sesgo_porc': sesgo_porc_estacional,\n",
    "            'mae_porc': mae_porc_estacional,\n",
    "            'rmse': rmse_estacional,\n",
    "            'score': score_estacional,\n",
    "            **{f'score_{lag}': score_value for lag, score_value in zip(df_lags_estacional.index, df_lags_estacional['SCORE%'])},              \n",
    "        })\n",
    "    # Concatenar resultados acumulados\n",
    "    df_forecast_rl_lineal = pd.concat(resultados_datos_forecast_demanda_lineal, ignore_index=False)\n",
    "    df_forecast_rl_estacional = pd.concat(resultados_datos_forecast_demanda_estacional, ignore_index=False) \n",
    "    \n",
    "    # Crear el DataFrame con los resultados de KPIs\n",
    "    df_mejor_rl_lineal = pd.DataFrame(resultados_rl_lineal)\n",
    "    df_mejor_rl_estacional = pd.DataFrame(resultados_rl_estacional)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()                                     \n",
    "    # Visualizar resultados\n",
    "    return df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd69baf-d941-437c-898f-7cc46efc81ed",
   "metadata": {},
   "source": [
    "## MSTL con Regresion Polinomica y Mayor Peso a la Ultima Tendencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a6c912-ea43-42e5-ac6d-8f619ada0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por meses\n",
    "def aplicar_mstl(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text):\n",
    "\n",
    "    df_lag_forecasts = []\n",
    "    resultados_datos_forecast_demanda_mstl = []\n",
    "    resultados_mstl = []\n",
    "    total_series = len(lista_skus)  \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):    \n",
    "#for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando MSTL para SKU N° {i + 1} de {total_series}...\")\n",
    "    \n",
    "    #for sku in tqdm(lista_skus, desc=\"Procesando SKUs\"):           \n",
    "                       \n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy() # Filtrar df_mes por cada SKU\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy() # Filtrar df_mes_ceros por cada Sku            \n",
    "        \n",
    "        # Evaluar el largo de la serie de tiempo y calcular meses a evaluar para cada sku\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        #print(sku, 'meses_evaluar:',meses_evaluar)\n",
    "        # Crear el rango de fechas para corar el set de datos de acuerdo con meses a evaluar\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "        #print(rango_fechas)\n",
    "        \n",
    "        forecasts = []\n",
    "        # Iterar por fecha\n",
    "        for fecha_corte in rango_fechas:\n",
    "            \n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha.index <= fecha_corte].copy()                 \n",
    "    \n",
    "            # Extraer la demanda y la fecha como un array\n",
    "            date = df_sku_fecha_temp.index\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            demand_series = pd.Series(demanda, index=date)                      \n",
    "    \n",
    "            if len(demand_series) > 24:\n",
    "                #print(f\"sku: {sku}, longitud: {len(demand_series)}\")\n",
    "                  \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    try:\n",
    "                        # Aplicar descomposición MSTL\n",
    "                        mstl_model = MSTL(demand_series, periods=12, stl_kwargs={'seasonal_deg': 0})\n",
    "                        descomposicion = mstl_model.fit()\n",
    "                        \n",
    "                        # Extraer componentes\n",
    "                        tendencia = descomposicion.trend\n",
    "                        seasonal = descomposicion.seasonal\n",
    "                        # Usar el indice en formato tiempo como indice de tiempo para la regresion\n",
    "                        indice_tiempo = pd.to_numeric(demand_series.index)  # Convertir DatetimeIndex a formato numero para la regresion\n",
    "                        peso_ult_data = peso_ult_data  # Ajustar para incrementar o disminuir la importancia de los datos mas recientes\n",
    "                        pesos = np.exp(peso_ult_data * np.arange(len(tendencia)))\n",
    "                        # Aplicar regresion polinomica a los datos de tendencia\n",
    "                        poly = PolynomialFeatures(degree=2)  # Aplicar grado 2 para obtener una proyeccion no lineal\n",
    "                        X_poly = poly.fit_transform(indice_tiempo.values.reshape(-1, 1))\n",
    "                        \n",
    "                        model = LinearRegression()\n",
    "                        model.fit(X_poly, tendencia, sample_weight=pesos)\n",
    "    \n",
    "                     # Proyectar la tendencia para los proximos 7 periodos\n",
    "                        fechas_futuras = [demand_series.index[-1] + DateOffset(months=i+1) for i in range(meses_a_pronosticar_evaluacion)]\n",
    "                        indice_fechas_futuras = pd.to_numeric(pd.Index(fechas_futuras))\n",
    "                        X_poly_futura = poly.transform(indice_fechas_futuras.values.reshape(-1, 1))\n",
    "                        pronostico_tendencia = model.predict(X_poly_futura)\n",
    "    \n",
    "                         # Calcular el indice estacional para cada mes\n",
    "                        estacionalidad_promedio = seasonal.groupby(seasonal.index.month).mean()\n",
    "                        \n",
    "                        # Determinar el mes de inicio de fecha pronostico \n",
    "                        mes_inicial = fechas_futuras[0].month\n",
    "                    \n",
    "                        # Proyectar el componente estacional por los proximos  periodos\n",
    "                        pronostico_estacional = [estacionalidad_promedio[(mes_inicial + i - 1) % 12 + 1] for i in range(meses_a_pronosticar_evaluacion)]\n",
    "                    \n",
    "                        # Combinar tendencia y componente estacional en un solo pronostico\n",
    "                        pronostico_final = pronostico_tendencia + pronostico_estacional\n",
    "                    \n",
    "                        # Crear una serie de pandas para mejor manejo\n",
    "                        pronostico_final_series = pd.Series(pronostico_final, index=fechas_futuras)\n",
    "                        \n",
    "                        forecasts.append((sku, date, pronostico_final))\n",
    "                       \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al ajustar MSTL para {sku}: {e}\")\n",
    "                        continue\n",
    "\n",
    "    \n",
    "        for sku, fechas_originales, forecast_series in forecasts:\n",
    "            #print('fechas originales:', fechas_originales, 'forecast_series:', forecast_series)\n",
    "            ultima_fecha = fechas_originales[-1]\n",
    "            \n",
    "            # Crear lista de fechas, de a mes a partir de ultima fecha + 1 mes\n",
    "            fechas_pronosticos = [ultima_fecha + DateOffset(months=i+1) for i in range(len(forecast_series))]\n",
    "            \n",
    "            # Crear lista de valores de lags\n",
    "            lags = [f\"Lag_{i}\" for i in range(1, len(forecast_series) + 1)]\n",
    "            # Crear df temporal por sku\n",
    "            temp_df = pd.DataFrame({\n",
    "                'FECHA': fechas_pronosticos,\n",
    "                'LAG':lags,\n",
    "                'CODIGO': [sku] * len(forecast_series),\n",
    "                'FORECAST': forecast_series,\n",
    "                \n",
    "            })\n",
    "            \n",
    "            # Acumular el df temporal al df principal\n",
    "            df_lag_forecasts.append(temp_df)\n",
    "    \n",
    "        \n",
    "        df_forecasts_mstl = pd.concat(df_lag_forecasts, ignore_index=True)\n",
    "        df_forecasts_mstl = df_forecasts_mstl.set_index('FECHA')\n",
    "        df2 = df_forecasts_mstl.copy()\n",
    "        # Unir forecast con la demanda real para evaluar\n",
    "        datos_forecast_mstl = df_forecasts_mstl.merge(\n",
    "            df_mes_ceros[['CODIGO', 'DEMANDA']], \n",
    "            how='left', \n",
    "            left_on=['CODIGO', df_forecasts_mstl.index], \n",
    "            right_on=['CODIGO', df_mes_ceros.index]\n",
    "        )\n",
    "        if porc_eval != 0:\n",
    "            datos_forecast_mstl = datos_forecast_mstl.dropna()\n",
    "        \n",
    "         # Renombrar la columna 'key_1' a 'FECHA' y Establecer 'FECHA' como el índice\n",
    "        df_forecast_mstl = datos_forecast_mstl.rename(columns={'key_1': 'FECHA'}).set_index('FECHA').copy()\n",
    "                      \n",
    "        df_columnas_error_mstl = crear_columnas_error(datos_forecast_mstl)\n",
    "\n",
    "        df_mejor_mstl = agrupar_por_codigo(df_columnas_error_mstl)   \n",
    "    \n",
    "    #df_mejor_mstl = pd.DataFrame(resultados_mstl)\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return  df_mejor_mstl, df_forecast_mstl\n",
    "\n",
    "# Solo para pronosticos de Novaventa\n",
    "def aplicar_mstl_nv(lista_skus, df_mes, df_mes_ceros, \n",
    "                 periodo_max_evaluacion, porc_eval, \n",
    "                 meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                 barra_progreso, status_text):\n",
    "\n",
    "    # Listas para acumular resultados\n",
    "    df_lag_forecasts = []\n",
    "    total_series = len(lista_skus)\n",
    "    \n",
    "    for i, sku in enumerate(tqdm(lista_skus, desc=\"Procesando SKUs\")):\n",
    "        # Actualizar barra de progreso y mensaje de estado\n",
    "        barra_progreso.progress((i + 1) / total_series)\n",
    "        status_text.text(f\"Evaluando MSTL para SKU N° {i + 1} de {total_series}...\")\n",
    "    \n",
    "        # Filtrar datos por SKU\n",
    "        df_sku_fecha = df_mes[df_mes['CODIGO'] == sku].copy()\n",
    "        df_sku_fecha_ceros = df_mes_ceros[df_mes_ceros['CODIGO'] == sku].copy()\n",
    "\n",
    "        # Calcular campañas a evaluar y rango de fechas\n",
    "        meses_evaluar = calcular_meses_a_evaluar(df_sku_fecha, periodo_max_evaluacion, porc_eval)\n",
    "        rango_fechas = crear_rango_fechas(df_sku_fecha, meses_evaluar)\n",
    "\n",
    "        forecasts = []\n",
    "\n",
    "        for fecha_corte in rango_fechas:\n",
    "            # Filtrar datos hasta la fecha de corte\n",
    "            df_sku_fecha_temp = df_sku_fecha[df_sku_fecha['CONSECUTIVO'] <= fecha_corte].copy()\n",
    "            date = df_sku_fecha_temp['CONSECUTIVO']\n",
    "            demanda = df_sku_fecha_temp['DEMANDA'].values\n",
    "            demand_series = pd.Series(demanda, index=date)\n",
    "            #print(sku, 'largo demanda:',len(demand_series))\n",
    "            if len(demand_series) > 38:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    try:\n",
    "                        # Aplicar descomposición MSTL\n",
    "                        mstl_model = MSTL(demand_series, periods=19, stl_kwargs={'seasonal_deg': 0})\n",
    "                        descomposicion = mstl_model.fit()\n",
    "\n",
    "                        # Componentes de descomposición\n",
    "                        tendencia = descomposicion.trend\n",
    "                        seasonal = descomposicion.seasonal\n",
    "                        indice_tiempo = pd.to_numeric(demand_series.index)\n",
    "                        \n",
    "                        # Pesos exponenciales para regresión\n",
    "                        pesos = np.exp(peso_ult_data * np.arange(len(tendencia)))\n",
    "                        \n",
    "                        # Regresión polinómica\n",
    "                        poly = PolynomialFeatures(degree=2)\n",
    "                        X_poly = poly.fit_transform(indice_tiempo.values.reshape(-1, 1))\n",
    "                        model = LinearRegression()\n",
    "                        model.fit(X_poly, tendencia, sample_weight=pesos)\n",
    "                        \n",
    "                        # Proyección de tendencia\n",
    "                        fechas_futuras = [demand_series.index[-1] + i + 1 for i in range(meses_a_pronosticar_evaluacion)]\n",
    "                        indice_fechas_futuras = pd.to_numeric(pd.Index(fechas_futuras))\n",
    "                        X_poly_futura = poly.transform(indice_fechas_futuras.values.reshape(-1, 1))\n",
    "                        pronostico_tendencia = model.predict(X_poly_futura)\n",
    "                        \n",
    "                        # Proyección de estacionalidad\n",
    "                        estacionalidad_promedio = seasonal.groupby(seasonal.index).mean()\n",
    "                        mes_inicial = fechas_futuras[0]\n",
    "                        pronostico_estacional = [\n",
    "                            estacionalidad_promedio[(mes_inicial + i - 1) % 12 + 1] for i in range(meses_a_pronosticar_evaluacion)\n",
    "                        ]\n",
    "                        \n",
    "                        # Pronóstico final\n",
    "                        pronostico_final = pronostico_tendencia + pronostico_estacional\n",
    "                        pronostico_final_series = pd.Series(pronostico_final, index=fechas_futuras)\n",
    "                        \n",
    "                        forecasts.append((sku, date, pronostico_final_series))\n",
    "                       \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al ajustar MSTL para {sku}: {e}\")\n",
    "                        continue\n",
    "\n",
    "        # Procesar resultados de los pronósticos\n",
    "        for sku, fechas_originales, forecast_series in forecasts:\n",
    "            ultima_fecha = fechas_originales[-1]\n",
    "            fechas_pronosticos = [ultima_fecha + i + 1 for i in range(len(forecast_series))]\n",
    "            lags = [f\"Lag_{i}\" for i in range(1, len(forecast_series) + 1)]\n",
    "            temp_df = pd.DataFrame({\n",
    "                'FECHA': fechas_pronosticos,\n",
    "                'LAG': lags,\n",
    "                'CODIGO': [sku] * len(forecast_series),\n",
    "                'FORECAST': forecast_series.values,\n",
    "            })\n",
    "            df_lag_forecasts.append(temp_df)\n",
    "    \n",
    "    if df_lag_forecasts:\n",
    "        df_forecasts_mstl = pd.concat(df_lag_forecasts, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No hay SKUs con suficientes campañas para un análisis estacional\")\n",
    "        return None, None\n",
    "\n",
    "    # Unir forecast con la demanda real para evaluar\n",
    "    datos_forecast_mstl = df_forecasts_mstl.merge(\n",
    "        df_mes_ceros[['CODIGO', 'DEMANDA']], \n",
    "        how='left', \n",
    "        left_on=['CODIGO', 'FECHA'], \n",
    "        right_on=['CODIGO', df_mes_ceros.index]\n",
    "    )\n",
    "    if porc_eval != 0:\n",
    "        datos_forecast_mstl = datos_forecast_mstl.dropna()\n",
    "\n",
    "    df_forecast_mstl = datos_forecast_mstl.rename(columns={'key_1': 'FECHA'}).set_index('FECHA').copy()\n",
    "    df_columnas_error_mstl = crear_columnas_error(datos_forecast_mstl)\n",
    "    df_mejor_mstl = agrupar_por_codigo(df_columnas_error_mstl)\n",
    "\n",
    "    status_text.text(\"\")\n",
    "    barra_progreso.empty()\n",
    "    return df_mejor_mstl, df_forecast_mstl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684749e-f47c-42d4-9590-d80879d16b86",
   "metadata": {},
   "source": [
    "# Comparacion de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac25f2-ded7-419d-9990-4b3fcd124d41",
   "metadata": {},
   "source": [
    "## Funciones para comparar y seleccionar mejores modelos por SKU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56632b31-937e-48d9-b7ca-d2f3a15ecd6d",
   "metadata": {},
   "source": [
    "### Funcion para generar df con con los errores de la evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a061c629-58b0-4b3c-acdd-2201c206ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_reporte_error_skus(modelos):\n",
    "    return {modelo: globals()[f'grupo_sku_error_formato_{modelo}'] for modelo in modelos}\n",
    "\n",
    "def generar_reporte_error_skus_nv(modelos_nv):\n",
    "    return {modelo_nv: globals()[f'grupo_sku_error_formato_{modelo_nv}_nv'] for modelo_nv in modelos_nv}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b1601-0ec4-4a4e-ab46-64306d51f556",
   "metadata": {},
   "source": [
    "### Funcion para crear df con mejores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce677f8d-73d4-4d8b-a419-02f897a8cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por meses\n",
    "def comparar_y_graficar_modelos(reporte_error_skus):\n",
    "    # Crear el DataFrame base con la columna 'Codigo'\n",
    "    df_final = reporte_error_skus['pms'][['CODIGO']].copy()\n",
    "    \n",
    "    # Iterar sobre los modelos para combinarlos en df_final\n",
    "    for nombre_modelo, df in reporte_error_skus.items():\n",
    "        df_final = df_final.merge(\n",
    "            df[['CODIGO', 'SCORE%']].rename(columns={'SCORE%': nombre_modelo}), \n",
    "            on='CODIGO', \n",
    "            how='left'\n",
    "        )\n",
    "        df['MODELO'] = nombre_modelo\n",
    "        \n",
    "    # Remover simbolos de porcentaje y convertir columnas a valores numericos\n",
    "    modelos_cols = list(reporte_error_skus.keys())\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda col: abs(col.str.rstrip('%').astype(float)))\n",
    "    \n",
    "    # Identificar la columna con el valor minimo para cada fila\n",
    "    df_final['MEJOR_MODELO'] = df_final[modelos_cols].idxmin(axis=1)\n",
    "    #dejar una copia sin formato porcentaje\n",
    "    df_minimos = df_final.copy()\n",
    "    # Dar formato a las columnas con un decimal y agregar el simbolo %\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda x: x.map('{:.1f}%'.format))\n",
    "    \n",
    "    # Contar cuantas veces el modelo es el mejor\n",
    "    report = df_final['MEJOR_MODELO'].value_counts()\n",
    "    \n",
    "    # Preparar y crear la grafica de dona\n",
    "    fig1 = go.Figure(data=[go.Pie(\n",
    "        labels=report.index, \n",
    "        values=report.values, \n",
    "        hole=0.4,  \n",
    "        textinfo='percent+label',  \n",
    "        marker=dict(colors=px.colors.qualitative.Plotly)  \n",
    "    )])\n",
    "    \n",
    "    # Actualizar Layout de la grafica\n",
    "    fig1.update_layout(\n",
    "        title='Distribucion de Mejor Modelo por SKUs',\n",
    "        title_x=0.5,  \n",
    "        template='plotly_white'  \n",
    "    )\n",
    "   \n",
    "\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_errores_totales = pd.concat(reporte_error_skus.values(), ignore_index=True) \n",
    "    \n",
    "    return df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales\n",
    "\n",
    "# Solo para novaventa\n",
    "def comparar_y_graficar_modelos_nv(reporte_error_skus):\n",
    "    # Crear el DataFrame base con la columna 'CODIGO'\n",
    "    df_final = None\n",
    "\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    reporte_error_skus_validos = {nombre: df for nombre, df in reporte_error_skus.items() if df is not None and not df.empty}\n",
    "\n",
    "    if not reporte_error_skus_validos:\n",
    "        print(\"No hay modelos válidos para procesar.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Usar el primer DataFrame válido como base para 'CODIGO'\n",
    "    for nombre_modelo, df in reporte_error_skus_validos.items():\n",
    "        if df_final is None:\n",
    "            df_final = df[['CODIGO']].copy()\n",
    "        break\n",
    "\n",
    "    # Iterar sobre los modelos válidos para combinarlos en df_final\n",
    "    for nombre_modelo, df in reporte_error_skus_validos.items():\n",
    "        df_final = df_final.merge(\n",
    "            df[['CODIGO', 'SCORE%']].rename(columns={'SCORE%': nombre_modelo}),\n",
    "            on='CODIGO',\n",
    "            how='left'\n",
    "        )\n",
    "        df['MODELO'] = nombre_modelo\n",
    "\n",
    "    # Remover símbolos de porcentaje y convertir columnas a valores numéricos\n",
    "    modelos_cols = list(reporte_error_skus_validos.keys())\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda col: abs(col.str.rstrip('%').astype(float)))\n",
    "\n",
    "    # Identificar la columna con el valor mínimo para cada fila\n",
    "    df_final['MEJOR_MODELO'] = df_final[modelos_cols].idxmin(axis=1)\n",
    "    # Dejar una copia sin formato porcentaje\n",
    "    df_minimos = df_final.copy()\n",
    "    # Dar formato a las columnas con un decimal y agregar el símbolo %\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda x: x.map('{:.1f}%'.format))\n",
    "\n",
    "    # Contar cuántas veces el modelo es el mejor\n",
    "    report = df_final['MEJOR_MODELO'].value_counts()\n",
    "\n",
    "    # Preparar y crear la gráfica de dona\n",
    "    fig1 = go.Figure(data=[go.Pie(\n",
    "        labels=report.index,\n",
    "        values=report.values,\n",
    "        hole=0.4,\n",
    "        textinfo='percent+label',\n",
    "        marker=dict(colors=px.colors.qualitative.Plotly)\n",
    "    )])\n",
    "\n",
    "    # Actualizar Layout de la gráfica\n",
    "    fig1.update_layout(\n",
    "        title='Distribución de Mejor Modelo por SKUs',\n",
    "        title_x=0.5,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_errores_totales = pd.concat(reporte_error_skus_validos.values(), ignore_index=True)\n",
    "\n",
    "    return df_minimos, df_final, reporte_error_skus_validos, fig1, df_errores_totales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d108cb2-8d7e-421e-9908-6244b9289391",
   "metadata": {},
   "source": [
    "### Funcion para acumular todos los pronosticos generados, no solo los de menor error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542521ec-f746-4715-8276-32f2a438bad5",
   "metadata": {},
   "source": [
    "def concatenar_forecasts_pronosticos(modelos):\n",
    "    \n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs = [globals()[f'df_forecast_final_{modelo}'] for modelo in modelos]\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_pronosticos = pd.concat(dfs)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_pronosticos['CODIGO'] = df_todos_pronosticos['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_pronosticos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b682e8-d3c6-4713-8d17-5137a817de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_forecasts_pronosticos(modelos):\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    dfs_validos = [\n",
    "        globals()[f'df_forecast_final_{modelo}']\n",
    "        for modelo in modelos\n",
    "        if globals()[f'df_forecast_final_{modelo}'] is not None and not globals()[f'df_forecast_final_{modelo}'].empty\n",
    "    ]\n",
    "    \n",
    "    # Verificar si hay DataFrames válidos\n",
    "    if not dfs_validos:\n",
    "        print(\"No hay pronósticos válidos para concatenar.\")\n",
    "        return None\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_todos_pronosticos = pd.concat(dfs_validos)\n",
    "\n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_pronosticos['CODIGO'] = df_todos_pronosticos['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_pronosticos\n",
    "\n",
    "# Solo para novaventa\n",
    "def concatenar_forecasts_pronosticos_nv(modelos_nv):\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    dfs_validos_nv = [\n",
    "        globals()[f'df_forecast_final_{modelo_nv}_nv']\n",
    "        for modelo_nv in modelos_nv\n",
    "        if globals()[f'df_forecast_final_{modelo_nv}_nv'] is not None and not globals()[f'df_forecast_final_{modelo_nv}_nv'].empty\n",
    "    ]\n",
    "    \n",
    "    # Verificar si hay DataFrames válidos\n",
    "    if not dfs_validos_nv:\n",
    "        print(\"No hay pronósticos válidos para concatenar.\")\n",
    "        return None\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_todos_pronosticos_nv = pd.concat(dfs_validos_nv)\n",
    "\n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_pronosticos_nv['CODIGO'] = df_todos_pronosticos_nv['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_pronosticos_nv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbc0d8-b734-420a-9860-de1a7d5d4a8f",
   "metadata": {},
   "source": [
    "### Funcion para generar periodos futuros novaventa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f5f7048-8af5-41f6-b79d-008d5d2ed941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_periodos_futuros(df_periodo, meses_a_pronosticar_produccion):\n",
    "    # Separar los elementos en año y número de campaña\n",
    "    periodos  = df_periodo.index.unique()\n",
    "    periodos_split = [p.split('-') for p in periodos]\n",
    "    periodos_df = pd.DataFrame(periodos_split, columns=['AÑO', 'CAMPAÑA']).astype(int)\n",
    "    \n",
    "    # Identificar el año máximo\n",
    "    max_año = periodos_df['AÑO'].max()\n",
    "    \n",
    "    # Filtrar los elementos del año máximo\n",
    "    periodos_año_max = periodos_df[periodos_df['AÑO'] == max_año]\n",
    "    \n",
    "    # Identificar la campaña máxima dentro del año máximo\n",
    "    max_campaña = periodos_año_max['CAMPAÑA'].max()\n",
    "    \n",
    "    # Generar el período máximo\n",
    "    periodo_max = f\"{max_año:04d}-{max_campaña:02d}\"\n",
    "    \n",
    "    # Generar los períodos futuros\n",
    "    futuros = []\n",
    "    año_actual = max_año\n",
    "    campaña_actual = max_campaña\n",
    "    \n",
    "    for _ in range(meses_a_pronosticar_produccion):\n",
    "        campaña_actual += 1\n",
    "        if campaña_actual > 19:  # Reiniciar campañas después de la 19\n",
    "            campaña_actual = 1\n",
    "            año_actual += 1\n",
    "        futuros.append(f\"{año_actual:04d}-{campaña_actual:02d}\")\n",
    "    \n",
    "    return periodo_max, futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b64b5f46-1976-447e-ad5e-04bd42f90285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_fecha_a_grupo(df_todos_pronosticos, futuros):\n",
    "    # Agrupar por CODIGO y MODELO\n",
    "    grouped = df_todos_pronosticos.groupby(['CODIGO', 'MODELO'])\n",
    "    \n",
    "    # Crear una lista para almacenar los DataFrames con la columna FECHA añadida\n",
    "    dfs_con_fecha = []\n",
    "    \n",
    "    # Iterar sobre los grupos\n",
    "    for (codigo, modelo), group in grouped:\n",
    "        # Asegurar que la longitud de futuros sea la misma que la del grupo\n",
    "        if len(futuros) == len(group):\n",
    "            # Crear la nueva columna FECHA\n",
    "            group['FECHA'] = futuros\n",
    "        else:\n",
    "            raise ValueError(f\"La longitud de 'futuros' no coincide con la longitud del grupo para CODIGO: {codigo} y MODELO: {modelo}\")\n",
    "        \n",
    "        # Añadir el grupo modificado a la lista\n",
    "        dfs_con_fecha.append(group)\n",
    "    \n",
    "    # Concatenar todos los DataFrames de nuevo en uno solo\n",
    "    df_todos_pronosticos_fecha = pd.concat(dfs_con_fecha, ignore_index=True)\n",
    "    \n",
    "    return df_todos_pronosticos_fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86ab7d-c051-471b-b081-dfbc3d69ca2f",
   "metadata": {},
   "source": [
    "### Funcion para consolidar los RMSE de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac5ea6ae-8db0-4eed-af7d-131d9851e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_rmse(modelos):\n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs_error = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        # Obtener el DataFrame para cada modelo\n",
    "        df = globals().get(f'rmse_sku_mes_{modelo}')\n",
    "        \n",
    "        # Verificar si el DataFrame es None o está vacío\n",
    "        if df is None or df.empty:\n",
    "            print(f\"El modelo {modelo} fue ignorado porque no tiene datos.\")\n",
    "            continue\n",
    "        \n",
    "        # Añadir una columna 'MODELO' con el nombre del modelo\n",
    "        df['MODELO'] = modelo\n",
    "        df['RMSE'] = np.ceil(df['RMSE']).astype(int)\n",
    "        \n",
    "        # Añadir el DataFrame a la lista\n",
    "        dfs_error.append(df)\n",
    "    \n",
    "    # Verificar si hay DataFrames para concatenar\n",
    "    if not dfs_error:\n",
    "        print(\"No hay datos para concatenar.\")\n",
    "        return pd.DataFrame()  # Devuelve un DataFrame vacío\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_rmse = pd.concat(dfs_error, ignore_index=True)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_rmse['CODIGO'] = df_todos_rmse['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_rmse\n",
    "\n",
    "# Solo para novaventa\n",
    "def concatenar_rmse_nv(modelos_nv):\n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs_error_nv = []\n",
    "    \n",
    "    for modelo_nv in modelos_nv:\n",
    "        # Obtener el DataFrame para cada modelo\n",
    "        df = globals().get(f'rmse_sku_mes_{modelo_nv}_nv')\n",
    "        \n",
    "        # Verificar si el DataFrame es None o está vacío\n",
    "        if df is None or df.empty:\n",
    "            print(f\"El modelo {modelo_nv} fue ignorado porque no tiene datos.\")\n",
    "            continue\n",
    "        \n",
    "        # Añadir una columna 'MODELO' con el nombre del modelo\n",
    "        df['MODELO'] = modelo_nv\n",
    "        df['RMSE'] = np.ceil(df['RMSE']).astype(int)\n",
    "        \n",
    "        # Añadir el DataFrame a la lista\n",
    "        dfs_error_nv.append(df)\n",
    "    \n",
    "    # Verificar si hay DataFrames para concatenar\n",
    "    if not dfs_error_nv:\n",
    "        print(\"No hay datos para concatenar.\")\n",
    "        return pd.DataFrame()  # Devuelve un DataFrame vacío\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_rmse_nv = pd.concat(dfs_error_nv, ignore_index=True)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_rmse_nv['CODIGO'] = df_todos_rmse_nv['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_rmse_nv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f33d81-67be-4f8b-bd93-acaf7208ba0e",
   "metadata": {},
   "source": [
    "### Funcion para seleccionar el mejor modelo para cada sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ce1eb91-47bc-485d-b6e9-8f98e0c1bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_mejor_pronostico(df_minimos, df_todos_pronosticos, df_errores_totales, df_todos_rmse):\n",
    "    # Crear una lista para almacenar los DataFrames filtrados\n",
    "    lista_filtrados = [\n",
    "        df_todos_pronosticos[\n",
    "            (df_todos_pronosticos['CODIGO'] == row['CODIGO']) & \n",
    "            (df_todos_pronosticos['MODELO'] == row['MEJOR_MODELO'])\n",
    "        ]\n",
    "        for _, row in df_minimos.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Concatenar todos los DataFrames filtrados\n",
    "    df_pronosticos_mejor_modelo = pd.concat(lista_filtrados)\n",
    "    \n",
    "    # Pivotear el resultado para mostrar el forecast por Código, Modelo y Fecha\n",
    "    #df_pronosticos_12_meses = df_pronosticos_mejor_modelo.pivot_table(index=[\"CODIGO\", \"MODELO\"], columns=\"FECHA\", values=\"FORECAST\")#.reset_index()\n",
    "    df_pronosticos_finales = df_pronosticos_mejor_modelo.pivot_table(index=[\"CODIGO\", \"MODELO\"], columns=\"FECHA\", values=\"FORECAST\").reset_index()\n",
    "    # Realizamos un merge para agregar las columnas coincidiendo por CODIGO y MODELO\n",
    "    # Realiza el merge entre ambos DataFrames en las claves 'CODIGO' y 'MODELO'\n",
    "    df_merged = pd.merge(\n",
    "        df_pronosticos_finales, \n",
    "        df_errores_totales[['CODIGO', 'MODELO', 'MAE%', 'SESGO%', 'SCORE%']], \n",
    "        on=['CODIGO', 'MODELO'], \n",
    "        how='left'\n",
    "    )\n",
    "    df_merged_rmse = pd.merge(\n",
    "        df_merged, \n",
    "        df_todos_rmse[['CODIGO', 'MODELO', 'RMSE']], \n",
    "        on=['CODIGO', 'MODELO'], \n",
    "        how='left'\n",
    "    )\n",
    " \n",
    "    # Inserta las columnas en las posiciones deseadas\n",
    "    df_merged_rmse.insert(0, 'MAE%', df_merged_rmse.pop('MAE%'))\n",
    "    df_merged_rmse.insert(1, 'SESGO%', df_merged_rmse.pop('SESGO%'))\n",
    "    df_merged_rmse.insert(2, 'SCORE%', df_merged_rmse.pop('SCORE%'))\n",
    "    df_merged_rmse.insert(3, 'RMSE', df_merged_rmse.pop('RMSE'))\n",
    "    # Si deseas restaurar el índice anterior\n",
    "    df_pronosticos_12_meses = df_merged_rmse.set_index(['CODIGO', 'MODELO'])\n",
    "    \n",
    "    # Filtrar columnas que parezcan fechas en formato yyyy-mm-dd\n",
    "    columnas_tiempo = [col for col in df_pronosticos_12_meses.columns if '-' in str(col)]\n",
    "    \n",
    "    # Renombrar las columnas seleccionadas al formato yyyy-mm-dd\n",
    "    df_pronosticos_12_meses = df_pronosticos_12_meses.rename(\n",
    "        columns={col: pd.to_datetime(col).strftime('%Y-%m-%d') for col in columnas_tiempo})\n",
    "    \n",
    "    # Identificar las columnas de fechas\n",
    "    columns_to_round = [col for col in df_pronosticos_12_meses.columns if col.startswith('20')]\n",
    "    \n",
    "    # Redondear los valores de estas columnas al entero más cercano\n",
    "    df_pronosticos_12_meses[columns_to_round] = df_pronosticos_12_meses[columns_to_round].round().astype(int)\n",
    "    \n",
    "    return df_pronosticos_mejor_modelo, df_pronosticos_12_meses\n",
    "\n",
    "# Solo para novaventa\n",
    "def obtener_mejor_pronostico_nv(df_minimos, df_todos_pronosticos_fecha):\n",
    "    # Crear una lista para almacenar los DataFrames filtrados\n",
    "    lista_filtrados = [\n",
    "        df_todos_pronosticos_fecha[\n",
    "            (df_todos_pronosticos_fecha['CODIGO'] == row['CODIGO']) & \n",
    "            (df_todos_pronosticos_fecha['MODELO'] == row['MEJOR_MODELO'])\n",
    "        ]\n",
    "        for _, row in df_minimos.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Concatenar todos los DataFrames filtrados\n",
    "    df_pronosticos_mejor_modelo = pd.concat(lista_filtrados)\n",
    "    \n",
    "    # Pivotear el resultado para mostrar el forecast por Código, Modelo y Fecha\n",
    "    df_pronosticos_12_meses = df_pronosticos_mejor_modelo.pivot_table(index=[\"CODIGO\", \"MODELO\"], columns=\"FECHA\", values=\"FORECAST\")\n",
    "    \n",
    "    return df_pronosticos_mejor_modelo, df_pronosticos_12_meses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739a3b5-28d7-4549-a4d1-612e04aa375b",
   "metadata": {},
   "source": [
    "### Funcion para crear la grafica de demanda + pronostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0fe15b8-2550-4663-9fa7-c79441392e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_grafica_pronostico(df_mes_ceros, df_todos_pronosticos, df_pronosticos_mejor_modelo):\n",
    "    # Obtener modelos únicos\n",
    "    modelos_unicos = df_todos_pronosticos['MODELO'].unique()\n",
    "    \n",
    "    # Generar una paleta de colores en seaborn\n",
    "    dark_colors = sns.color_palette(\"muted\", n_colors=len(modelos_unicos)).as_hex()\n",
    "    \n",
    "    # Crear un diccionario para asignar colores a cada modelo\n",
    "    color_mapping = {modelo: dark_colors[i] for i, modelo in enumerate(modelos_unicos)}\n",
    "\n",
    "    # Lista de códigos únicos\n",
    "    codigos_unicos = df_pronosticos_12_meses.index.unique(0)\n",
    "    #codigos_unicos = df_mes_ceros[\"CODIGO\"].unique()\n",
    "\n",
    "    # Crear una figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Crear todas las trazas (una por cada Código y Modelo) y agregar al gráfico\n",
    "    for codigo in codigos_unicos:\n",
    "        # Filtrar df_mes por Codigo (para graficar la demanda)\n",
    "        df_mes_filtrado = df_mes_ceros[df_mes_ceros[\"CODIGO\"] == codigo]\n",
    "\n",
    "        # Filtrar df_todos_pronosticos por Codigo (para graficar todos los pronósticos de modelos)\n",
    "        df_todos_pronosticos_filtrado = df_todos_pronosticos[df_todos_pronosticos[\"CODIGO\"] == codigo]\n",
    "\n",
    "        # Filtrar df_pronosticos_mejor_modelo para obtener el mejor modelo de ese código\n",
    "        df_pronosticos_filtrado = df_pronosticos_mejor_modelo[df_pronosticos_mejor_modelo[\"CODIGO\"] == codigo]\n",
    "        mejor_modelo = df_pronosticos_filtrado[\"MODELO\"].values[0]  # Extraer el mejor modelo para ese código\n",
    "\n",
    "        # Agregar la traza de DEMANDA para este código (inicialmente invisible)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_mes_filtrado.index, \n",
    "            y=df_mes_filtrado[\"DEMANDA\"], \n",
    "            mode='lines',\n",
    "            name=f'{codigo}',\n",
    "            line=dict(color='navy'),\n",
    "            visible=False  # Inicialmente invisible\n",
    "        ))\n",
    "\n",
    "        # Agregar una traza para cada modelo en df_todos_pronosticos_filtrado\n",
    "        for modelo in modelos_unicos:\n",
    "            # Filtrar por el modelo específico dentro del código seleccionado\n",
    "            df_modelo_filtrado = df_todos_pronosticos_filtrado[df_todos_pronosticos_filtrado[\"MODELO\"] == modelo]\n",
    "\n",
    "            # Determinar el estilo de la línea\n",
    "            if modelo == mejor_modelo:\n",
    "                line_style = dict(dash='solid', color='#FF4500', width=2.5)  # Continua para el mejor modelo\n",
    "            else:\n",
    "                line_style = dict(dash='dot', color=color_mapping[modelo])  # Punteada para los demás modelos\n",
    "\n",
    "            # Agregar la traza de FORECAST de este modelo (inicialmente invisible)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_modelo_filtrado.index, \n",
    "                y=df_modelo_filtrado[\"FORECAST\"], \n",
    "                mode='lines',\n",
    "                name=f'{modelo}',\n",
    "                line=line_style,\n",
    "                visible=False  # Inicialmente invisible\n",
    "            ))\n",
    "\n",
    "    # Crear botones para el dropdown del primer menú (Códigos)\n",
    "    dropdown_buttons_codigo = []\n",
    "    for i, codigo in enumerate(codigos_unicos):\n",
    "        # Visibilidad de DEMANDA y todas las trazas de pronósticos para este código\n",
    "        visibility = [False] * len(fig.data)  # Inicializar todas las trazas como invisibles\n",
    "\n",
    "        # Mostrar DEMANDA\n",
    "        visibility[i * (len(modelos_unicos) + 1)] = True  \n",
    "\n",
    "        # Mostrar todas las trazas de los modelos para el código seleccionado\n",
    "        for j in range(len(modelos_unicos)):\n",
    "            visibility[i * (len(modelos_unicos) + 1) + j + 1] = True\n",
    "\n",
    "        # Botón para seleccionar el código\n",
    "        dropdown_buttons_codigo.append(\n",
    "            dict(\n",
    "                args=[{\"visible\": visibility}],  # Cambiar la visibilidad de las trazas\n",
    "                label=str(codigo),  # Etiqueta del código\n",
    "                method=\"update\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Mostrar la primera DEMANDA y todos los modelos del primer código por defecto\n",
    "    fig.data[0].visible = True\n",
    "    for j in range(len(modelos_unicos)):\n",
    "        fig.data[j + 1].visible = True\n",
    "\n",
    "    # Configurar el layout con el menú dropdown\n",
    "    fig.update_layout(\n",
    "        template=\"ggplot2\",\n",
    "        updatemenus=[\n",
    "            # Menú desplegable para seleccionar el Código\n",
    "            dict(\n",
    "                buttons=dropdown_buttons_codigo,\n",
    "                direction=\"down\",\n",
    "                showactive=True,\n",
    "                x=-0.05, y=1.0,  # Posición del dropdown\n",
    "                xanchor=\"right\",\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        ],\n",
    "        title=\"Demanda vs Pronóstico por Código\",\n",
    "        xaxis_title=\"Fecha\",\n",
    "        yaxis_title=\"Demanda\",\n",
    "        showlegend=True,\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            y=0.5\n",
    "        ),\n",
    "        height=400,\n",
    "        plot_bgcolor='#F0F0F0',  # Set the plot background color to a light gray\n",
    "    )\n",
    "    if 'CONSECUTIVO' in df_mes_ceros:\n",
    "        fig.update_xaxes(        \n",
    "            type='category',  # Especificar que el eje X es categórico\n",
    "            tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "            tickangle=-45,  # Rotar las etiquetas del eje X a 45 grados\n",
    "            tickfont=dict(size=9)  # Reducir el tamaño de la fuente en un 25%\n",
    "        ) \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Solo para novaventa\n",
    "def crear_grafica_pronostico_nv(df_mes, df_todos_pronosticos, df_pronosticos_mejor_modelo):\n",
    "    # Obtener modelos únicos\n",
    "    modelos_unicos = df_todos_pronosticos['MODELO'].unique()\n",
    "    \n",
    "    # Generar una paleta de colores en seaborn\n",
    "    dark_colors = sns.color_palette(\"muted\", n_colors=len(modelos_unicos)).as_hex()\n",
    "    \n",
    "    # Crear un diccionario para asignar colores a cada modelo\n",
    "    color_mapping = {modelo: dark_colors[i] for i, modelo in enumerate(modelos_unicos)}\n",
    "\n",
    "    # Lista de códigos únicos\n",
    "    codigos_unicos = df_mes[\"CODIGO\"].unique()\n",
    "\n",
    "    # Crear una figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Crear todas las trazas (una por cada Código y Modelo) y agregar al gráfico\n",
    "    for codigo in codigos_unicos:\n",
    "        # Filtrar df_mes por Codigo (para graficar la demanda)\n",
    "        df_mes_filtrado = df_mes[df_mes[\"CODIGO\"] == codigo]\n",
    "        \n",
    "        # Filtrar df_todos_pronosticos por Codigo (para graficar todos los pronósticos de modelos)\n",
    "        df_todos_pronosticos_filtrado = df_todos_pronosticos[df_todos_pronosticos[\"CODIGO\"] == codigo]\n",
    "\n",
    "        # Filtrar df_pronosticos_mejor_modelo para obtener el mejor modelo de ese código\n",
    "        df_pronosticos_filtrado = df_pronosticos_mejor_modelo[df_pronosticos_mejor_modelo[\"CODIGO\"] == codigo]\n",
    "        mejor_modelo = df_pronosticos_filtrado[\"MODELO\"].values[0]  # Extraer el mejor modelo para ese código\n",
    "\n",
    "        # Agregar la traza de DEMANDA para este código (inicialmente invisible)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_mes_filtrado.index, \n",
    "            y=df_mes_filtrado[\"DEMANDA\"], \n",
    "            mode='lines',\n",
    "            name=f'{codigo}',\n",
    "            line=dict(color='navy'),\n",
    "            visible=False  # Inicialmente invisible\n",
    "        ))\n",
    "\n",
    "        # Agregar una traza para cada modelo en df_todos_pronosticos_filtrado\n",
    "        for modelo in modelos_unicos:\n",
    "            # Filtrar por el modelo específico dentro del código seleccionado\n",
    "            df_modelo_filtrado = df_todos_pronosticos_filtrado[df_todos_pronosticos_filtrado[\"MODELO\"] == modelo]\n",
    "\n",
    "            # Determinar el estilo de la línea\n",
    "            if modelo == mejor_modelo:\n",
    "                line_style = dict(dash='solid', color='#FF4500', width=2.5)  # Continua para el mejor modelo\n",
    "            else:\n",
    "                line_style = dict(dash='dot', color=color_mapping[modelo])  # Punteada para los demás modelos\n",
    "\n",
    "            # Agregar la traza de FORECAST de este modelo (inicialmente invisible)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_modelo_filtrado['FECHA'], \n",
    "                y=df_modelo_filtrado[\"FORECAST\"], \n",
    "                mode='lines',\n",
    "                name=f'{modelo}',\n",
    "                line=line_style,\n",
    "                visible=False  # Inicialmente invisible\n",
    "            ))\n",
    "\n",
    "    # Crear botones para el dropdown del primer menú (Códigos)\n",
    "    dropdown_buttons_codigo = []\n",
    "    for i, codigo in enumerate(codigos_unicos):\n",
    "        # Visibilidad de DEMANDA y todas las trazas de pronósticos para este código\n",
    "        visibility = [False] * len(fig.data)  # Inicializar todas las trazas como invisibles\n",
    "\n",
    "        # Mostrar DEMANDA\n",
    "        visibility[i * (len(modelos_unicos) + 1)] = True  \n",
    "\n",
    "        # Mostrar todas las trazas de los modelos para el código seleccionado\n",
    "        for j in range(len(modelos_unicos)):\n",
    "            visibility[i * (len(modelos_unicos) + 1) + j + 1] = True\n",
    "\n",
    "        # Botón para seleccionar el código\n",
    "        dropdown_buttons_codigo.append(\n",
    "            dict(\n",
    "                args=[{\"visible\": visibility}],  # Cambiar la visibilidad de las trazas\n",
    "                label=str(codigo),  # Etiqueta del código\n",
    "                method=\"update\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Mostrar la primera DEMANDA y todos los modelos del primer código por defecto\n",
    "    fig.data[0].visible = True\n",
    "    for j in range(len(modelos_unicos)):\n",
    "        fig.data[j + 1].visible = True\n",
    "\n",
    "    # Configurar el layout con el menú dropdown\n",
    "    fig.update_layout(\n",
    "        template=\"ggplot2\",\n",
    "        updatemenus=[\n",
    "            # Menú desplegable para seleccionar el Código\n",
    "            dict(\n",
    "                buttons=dropdown_buttons_codigo,\n",
    "                direction=\"down\",\n",
    "                showactive=True,\n",
    "                x=-0.05, y=1.2,  # Posición del dropdown\n",
    "                xanchor=\"left\",\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        ],\n",
    "        title=\"Demanda vs Pronóstico por Código\",\n",
    "        xaxis_title=\"Campaña\",\n",
    "        yaxis_title=\"Demanda\",\n",
    "        showlegend=True,\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            y=0.5\n",
    "        ),\n",
    "        height=400,\n",
    "        plot_bgcolor='#F0F0F0',  # Set the plot background color to a light gray\n",
    "    )\n",
    "    fig.update_xaxes(        \n",
    "        type='category',  # Especificar que el eje X es categórico\n",
    "        tickmode='array',  # Asegurar que las etiquetas del eje X no sean interpretadas como fechas\n",
    "        tickangle=-45,  # Rotar las etiquetas del eje X a 45 grados\n",
    "        tickfont=dict(size=9)  # Reducir el tamaño de la fuente en un 25%\n",
    "    ) \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2a82b-08c4-4200-be1a-34e8a8c76a28",
   "metadata": {},
   "source": [
    "### Funcion para seleccionar un pronostico diferente al minimo estadistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8932782-c594-45cb-9064-d47006351a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_pronosticos(sku, modelo, df_todos_pronosticos):\n",
    "    \n",
    "    # Filtrar DataFrame basado en selección\n",
    "    df_filtrado = df_todos_pronosticos[\n",
    "                (df_todos_pronosticos['CODIGO'] == sku) & \n",
    "                (df_todos_pronosticos['MODELO'] == modelo)\n",
    "            ]     \n",
    "    df_filtrado['FORECAST'] = np.ceil(df_filtrado['FORECAST']).astype(int)  \n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d0550-e778-4d21-96bc-84ca799fb7b9",
   "metadata": {},
   "source": [
    "### Funcion para agrupar df_test y obtener metricas combinadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1eefeee-0d0e-4caa-ae2b-0b935b555a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_df_test(modelos):\n",
    "    \n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs = []\n",
    "    for modelo in modelos:\n",
    "        df = globals()[f'df_test_{modelo}']\n",
    "        # Añadir la columna 'modelo' con el valor del modelo\n",
    "        df['modelo'] = modelo\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_df_test = pd.concat(dfs)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_df_test['CODIGO'] = df_todos_df_test['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_df_test\n",
    "\n",
    "# Solo para Novaventa\n",
    "def concatenar_df_test_nv(modelos_nv):\n",
    "    \n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs_nv = []\n",
    "    for modelo_nv in modelos_nv:\n",
    "        df = globals()[f'df_test_{modelo_nv}']\n",
    "        # Añadir la columna 'modelo' con el valor del modelo\n",
    "        df['modelo'] = modelo_nv\n",
    "        dfs_nv.append(df)\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_df_test_nv = pd.concat(dfs_nv)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_df_test_nv['CODIGO'] = df_todos_df_test_nv['CODIGO'].astype(str)\n",
    "\n",
    "    return df_todos_df_test_nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97ab8f21-fa51-4a75-a507-c68dfc4e1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_y_concatenatar_df_test(df_minimos, df_todos_df_test):\n",
    "    # Lista para almacenar los DataFrames filtrados\n",
    "    dfs_filtrados = []\n",
    "    \n",
    "    # Iterar sobre cada fila de df_minimos\n",
    "    for _, row in df_minimos.iterrows():\n",
    "        # Obtener CODIGO y MEJOR_MODELO de cada fila\n",
    "        codigo = row['CODIGO']\n",
    "        mejor_modelo = row['MEJOR_MODELO']\n",
    "        \n",
    "        # Filtrar df_todos_df_test por la combinación de CODIGO y MEJOR_MODELO\n",
    "        df_filtrado = df_todos_df_test[(df_todos_df_test['CODIGO'] == codigo) & (df_todos_df_test['modelo'] == mejor_modelo)]\n",
    "        \n",
    "        # Añadir el DataFrame filtrado a la lista\n",
    "        dfs_filtrados.append(df_filtrado)\n",
    "    \n",
    "    # Concatenar todos los DataFrames filtrados en uno solo, manteniendo los índices originales\n",
    "    df_resultado_test = pd.concat(dfs_filtrados, ignore_index=False)\n",
    "    \n",
    "    return df_resultado_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d9ee7-fe2e-47aa-a913-9a34cef185df",
   "metadata": {},
   "source": [
    "# Script de prueba parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac164696-12cb-4278-a037-a13afafc715f",
   "metadata": {},
   "source": [
    "Esta celda es para probar el algoritmo y realizar cambios o ajsutes posteriores a la entrega, debe permancer inactivada y no debe hacer parte del codigo ejecutable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9e4c1-138a-4b75-b223-a48fce320051",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Cargar data\n",
    "ruta_demanda = r'dataset/historico_venta 2022_2024.xlsx'\n",
    "df = cargar_data(ruta_demanda)\n",
    "\n",
    "# Preprocesar data\n",
    "df_vertical = convertir_a_df_vertical(df)\n",
    "df_vertical_fecha = convertir_texto_a_fecha(df_vertical, meses)\n",
    "df_resultado = eliminar_ceros_iniciales(df_vertical_fecha)\n",
    "df_mes_cliente = preprocesar_tabla_2(df_resultado)\n",
    "\n",
    "# Grafica 1: Demanda por Codigo - Cliente\n",
    "#graficar_demanda_codigo_cliente(df_mes_cliente)\n",
    "\n",
    "# Grafica 2: Demanda por Codigo Agregado\n",
    "#df_mes_orig, reporte_codigos = agrupar_demanda(df_mes_cliente)\n",
    "#graficar_demanda_codigo(df_mes_orig)\n",
    "\n",
    "# Seleccionar tipo de Pronostico\n",
    "opciones = ['POR_CODIGO_CLIENTE','POR_CODIGO_AGREGADO']\n",
    "opcion = opciones[1]\n",
    "df_mes_orig, reporte_codigos = seleccionar_tipo_pronostico(opcion, df_mes_cliente)\n",
    "\n",
    "# Reemplazar los Ceros por la mediana\n",
    "df_mes_ceros = reemplazar_ceros(df_mes_orig)\n",
    "\n",
    "# Grafica 3: Demanda con los ceros reemplazados\n",
    "graficar_demanda_codigo(df_mes_ceros)\n",
    "\n",
    "# Definir limites sup e inf\n",
    "sup = 0.98\n",
    "inf = 0.02\n",
    "\n",
    "# Definir n para el pronostico ingenuo\n",
    "n = 6\n",
    "\n",
    "# Imputar Outliers\n",
    "df_mes, df_outliers, reporte_outliers = eliminar_outliers(df_mes_ceros, sup, inf, n)\n",
    "\n",
    "# Grafica 4: Demanda sin Outliers\n",
    "graficar_demanda_codigo(df_mes)\n",
    "\n",
    "# Grafica 5: Visualizacion de Ouliers imputados\n",
    "graficar_outliers_subplots(df_mes_ceros, df_outliers, sup=sup, inf=inf, n=n)\n",
    "\n",
    "# Evaluar Modelos de Pronosticos de Serie de Tiempo\n",
    "lista_skus = crear_lista_skus(df_mes) # Crear lista de skus\n",
    "\n",
    "# Parametros\n",
    "meses_a_pronosticar_evaluacion = 6 # Numero de meses a pronosticar para evaluar y seleccionar el modelo\n",
    "periodo_max_evaluacion = 12 # Numero de periodos maximos de evaluacion de cada serie de tiempo\n",
    "porc_eval = 0.35 # Porcentaje de meses para evaluar el modelo\n",
    "barra_progreso = st.progress(0)\n",
    "status_text = st.text(\"Iniciando Evaluación...\")\n",
    "\n",
    "# PMS\n",
    "df_mejor_n, df_forecast_pms = evaluar_y_generar_pms(df_mes, df_mes_ceros, lista_skus, \n",
    "                                                    periodo_max_evaluacion, \n",
    "                                                    porc_eval, \n",
    "                                                    meses_a_pronosticar_evaluacion,\n",
    "                                                   barra_progreso,\n",
    "                                                   status_text)\n",
    "\n",
    "# Reportes de error PMS\n",
    "grupo_mes_error_formato_pms, df_test_pms = kpi_error_lag(df_forecast_pms) # Reporte global\n",
    "grupo_sku_error_formato_pms, rmse_sku_lag_pms, rmse_sku_mes_pms = kpi_error_sku(df_forecast_pms) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con PMS\n",
    "meses_a_pronosticar_produccion = 12 # Numero de meses finales a pronosticar\n",
    "df_forecast_final_pms = construir_pronostico_pms(df_mejor_n, df_mes, meses_a_pronosticar_produccion, 'pms')\n",
    "\n",
    "# Suavizacion Exponencial\n",
    "df_mejor_se,  df_forecast_se = encontrar_mejor_se(df_mes, \n",
    "                                                  df_mes_ceros, \n",
    "                                                  lista_skus, \n",
    "                                                  periodo_max_evaluacion, \n",
    "                                                  porc_eval, \n",
    "                                                  meses_a_pronosticar_evaluacion,\n",
    "                                                  barra_progreso,\n",
    "                                                    status_text)\n",
    "\n",
    "# Reportes de error SE\n",
    "grupo_mes_error_formato_se, df_test_se = kpi_error_lag(df_forecast_se) # Reporte global\n",
    "grupo_sku_error_formato_se, rmse_sku_lag_se, rmse_sku_mes_se = kpi_error_sku(df_forecast_se) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con SE\n",
    "porc_eval_pronost = 0 # Porcentaje de Evaluacion se lleva a 0 para pronosticar\n",
    "df_mejor_se_final,  df_forecast_final_se = encontrar_mejor_se(df_mes, df_mes_ceros, \n",
    "                                                              lista_skus, \n",
    "                                                              periodo_max_evaluacion, \n",
    "                                                              porc_eval_pronost, \n",
    "                                                              meses_a_pronosticar_produccion,\n",
    "                                                              barra_progreso,\n",
    "                                                               status_text)\n",
    "\n",
    "# Adicionar nombre a los pronosticos de SE\n",
    "df_forecast_final_se = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se, 'se')\n",
    "\n",
    "# Regresion lineal simple y \"estacional\"\n",
    "df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional = aplicar_regresion_lineal_simple(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "                                                                                                                              \n",
    "\n",
    "# Reportes error RL\n",
    "grupo_mes_error_formato_rl_lineal, df_test_rl_lineal= kpi_error_lag(df_forecast_rl_lineal) # Reporte global RL simple\n",
    "grupo_sku_error_formato_rl_lineal, rmse_sku_lag_rl_lineal, rmse_sku_mes_rl_lineal = kpi_error_sku(df_forecast_rl_lineal) # Reporte por sku RL simple\n",
    "grupo_mes_error_formato_rl_estacional, df_test_rl_estacional= kpi_error_lag(df_forecast_rl_estacional) # Reporte global RL estacional\n",
    "grupo_sku_error_formato_rl_estacional, rmse_sku_lag_rl_estacional, rmse_sku_mes_rl_estacional = kpi_error_sku(df_forecast_rl_estacional) # Reporte por sku RL estacional\n",
    "\n",
    "# Generar Pronosticos finales con RL \n",
    "df_final_mejor_rl_lineal, df_final_mejor_rl_estacional, df_forecast_final_rl_lineal, df_forecast_final_rl_estacional = aplicar_regresion_lineal_simple(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "\n",
    "# Adicionar nombre a los pronosticos de RL\n",
    "df_forecast_final_rl_lineal = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal, 'rl_lineal')\n",
    "df_forecast_final_rl_estacional = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional, 'rl_estacional')\n",
    "\n",
    "# Modelo de descomposicion MSTL\n",
    "porc_eval = 0.35\n",
    "peso_ult_data = 0.08\n",
    "df_mejor_mstl, df_forecast_mstl = aplicar_mstl(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    " # Reportes de error MSTL\n",
    "grupo_mes_error_formato_mstl, df_test_mstl = kpi_error_lag(df_forecast_mstl) # Reporte golbal\n",
    "grupo_sku_error_formato_mstl, rmse_sku_lag_mstl, rmse_sku_mes_mstl = kpi_error_sku(df_forecast_mstl) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con MSTL\n",
    "tabla_final_pronost, df_forecast_final_mstl = aplicar_mstl(lista_skus, df_mes, df_mes_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion, \n",
    "                                    peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)                      \n",
    "\n",
    "# Adicionar nombre a los pronosticos de MSTL                                                         \n",
    "df_forecast_final_mstl = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl, 'mstl')\n",
    "\n",
    "# Crear reporte acumulado de errores de todos los modelos\n",
    "modelos = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "reporte_error_skus = generar_reporte_error_skus(modelos)\n",
    "df_todos_rmse = concatenar_rmse(modelos)\n",
    "\n",
    "# Grafica 6: Distribucion de merjor modelos por sku\n",
    "df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales = comparar_y_graficar_modelos(reporte_error_skus)\n",
    "fig1.show()\n",
    "\n",
    "# Concatener todos los pronosticos finales generados\n",
    "df_todos_pronosticos = concatenar_forecasts_pronosticos(modelos)\n",
    "\n",
    "# Crear tabla final con pronosticos a 12 meses\n",
    "df_pronosticos_mejor_modelo, df_pronosticos_12_meses = obtener_mejor_pronostico(df_minimos, df_todos_pronosticos, df_errores_totales, df_todos_rmse)\n",
    "\n",
    "# Grafica final demanda vs mejor pronostico\n",
    "fig = crear_grafica_pronostico(df_mes, df_todos_pronosticos, df_pronosticos_mejor_modelo)\n",
    "fig.show()\n",
    "df_todos_df_test = concatenar_df_test(modelos)\n",
    "df_resultado_test = filtrar_y_concatenatar_df_test(df_minimos, df_todos_df_test)\n",
    "sesgo_porc, mae_porc, rmse, score = metricas_error(df_resultado_test, imprimir=1)\n",
    "df_lags = evaluar_lags(df_resultado_test)[['MAE%','SESGO%','SCORE%']]\n",
    "display(df_lags[['MAE%','SESGO%','SCORE%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16f125-fb30-4708-90ad-dd3cfe55538a",
   "metadata": {},
   "source": [
    "# Script de prueba parte 2 - Novaventa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631630fc-da7d-4f52-aae9-1ef7fc86e0cc",
   "metadata": {},
   "source": [
    "# Ruta ubicacion de archivo fuente\n",
    "ruta_demanda_nv = r'dataset/Historico_Campañas_Novaventa.xlsx'\n",
    "df = cargar_data(ruta_demanda_nv)\n",
    "df_orig = preprocesar_datos_1_nv(df)\n",
    "df_vertical = llenar_nan(df_orig)\n",
    "df_resultado = eliminar_ceros_iniciales_nv(df_vertical)\n",
    "df_ceros = reemplazar_ceros_nv(df_resultado)\n",
    "graficar_demanda_codigo_nv(df_resultado)\n",
    "sup = 0.98\n",
    "inf = 0.02\n",
    "n = 6\n",
    "df_periodo, df_outliers, reporte_outliers = eliminar_outliers(df_ceros, sup, inf, n)\n",
    "graficar_outliers_subplots(df_ceros, df_outliers, sup, inf, n)\n",
    "lista_skus = crear_lista_skus(df_periodo) # Crear lista de skus\n",
    "meses_a_pronosticar_evaluacion = 6 # Numero de meses a pronosticar para evaluar y seleccionar el modelo\n",
    "periodo_max_evaluacion = 12 # Numero de periodos maximos de evaluacion de cada serie de tiempo\n",
    "porc_eval = 0.35 # Porcentaje de meses para evaluar el modelo\n",
    "barra_progreso = st.progress(0)\n",
    "status_text = st.text(\"Iniciando Evaluación...\")\n",
    "\n",
    "df_mejor_n, df_forecast_pms = evaluar_y_generar_pms_nv(df_periodo, df_ceros, lista_skus, \n",
    "                                                    periodo_max_evaluacion, \n",
    "                                                    porc_eval, \n",
    "                                                    meses_a_pronosticar_evaluacion,\n",
    "                                                   barra_progreso,\n",
    "                                                   status_text)\n",
    "grupo_mes_error_formato_pms, df_test_pms = kpi_error_lag(df_forecast_pms) # Reporte global\n",
    "grupo_sku_error_formato_pms, rmse_sku_lag_pms, rmse_sku_mes_pms = kpi_error_sku(df_forecast_pms) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con PMS\n",
    "meses_a_pronosticar_produccion = 12 # Numero de meses finales a pronosticar\n",
    "df_forecast_final_pms = construir_pronostico_pms_nv(df_mejor_n, df_periodo, meses_a_pronosticar_produccion, 'pms')\n",
    "\n",
    "df_mejor_se,  df_forecast_se = encontrar_mejor_se_nv(df_periodo, df_ceros, lista_skus, periodo_max_evaluacion, porc_eval, \n",
    "                        meses_a_pronosticar_evaluacion,\n",
    "                        barra_progreso,\n",
    "                        status_text)\n",
    "grupo_mes_error_formato_se, df_test_se = kpi_error_lag(df_forecast_se) # Reporte global\n",
    "grupo_sku_error_formato_se, rmse_sku_lag_se, rmse_sku_mes_se = kpi_error_sku(df_forecast_se)\n",
    "\n",
    "porc_eval_pronost = 0\n",
    "meses_a_pronosticar_produccion = 12\n",
    "df_mejor_se_final,  df_forecast_final_se = encontrar_mejor_se_nv(df_periodo, df_ceros, lista_skus, periodo_max_evaluacion, porc_eval_pronost, \n",
    "                        meses_a_pronosticar_produccion,\n",
    "                        barra_progreso,\n",
    "                        status_text)\n",
    "# Adicionar nombre a los pronosticos de SE\n",
    "df_forecast_final_se = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se, 'se')\n",
    "\n",
    "porc_eval = 0.35\n",
    "df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "\n",
    "grupo_mes_error_formato_rl_lineal, df_test_rl_lineal = kpi_error_lag(df_forecast_rl_lineal) # Reporte global\n",
    "grupo_sku_error_formato_rl_lineal, rmse_sku_lag_rl_lineal, rmse_sku_mes_rl_lineal = kpi_error_sku(df_forecast_rl_lineal)\n",
    "\n",
    "grupo_mes_error_formato_rl_estacional, df_test_rl_estacional = kpi_error_lag(df_forecast_rl_estacional) # Reporte global\n",
    "grupo_sku_error_formato_rl_estacional, rmse_sku_lag_rl_estacional, rmse_sku_mes_rl_estacional = kpi_error_sku(df_forecast_rl_estacional)\n",
    "\n",
    "\n",
    "df_final_mejor_rl_lineal, df_final_mejor_rl_estacional, df_forecast_final_rl_lineal, df_forecast_final_rl_estacional = aplicar_regresion_lineal_simple_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    "\n",
    "# Adicionar nombre a los pronosticos de RL\n",
    "df_forecast_final_rl_lineal = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal, 'rl_lineal')\n",
    "df_forecast_final_rl_estacional = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional, 'rl_estacional')\n",
    "\n",
    "# Modelo de descomposicion MSTL\n",
    "peso_ult_data = 0.08\n",
    "df_mejor_mstl, df_forecast_mstl = aplicar_mstl_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval, \n",
    "                                    meses_a_pronosticar_evaluacion, peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)\n",
    " # Reportes de error MSTL\n",
    "grupo_mes_error_formato_mstl, df_test_mstl = kpi_error_lag(df_forecast_mstl) # Reporte golbal\n",
    "grupo_sku_error_formato_mstl, rmse_sku_lag_mstl, rmse_sku_mes_mstl = kpi_error_sku(df_forecast_mstl) # Reporte por sku\n",
    "\n",
    "# Generar Pronosticos finales con MSTL\n",
    "tabla_final_pronost, df_forecast_final_mstl = aplicar_mstl_nv(lista_skus, df_periodo, df_ceros, \n",
    "                                    periodo_max_evaluacion, porc_eval_pronost, \n",
    "                                    meses_a_pronosticar_produccion, \n",
    "                                    peso_ult_data,\n",
    "                                    barra_progreso,\n",
    "                                    status_text)                      \n",
    "\n",
    "# Adicionar nombre a los pronosticos de MSTL                                                         \n",
    "df_forecast_final_mstl = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl, 'mstl')\n",
    "modelos = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "reporte_error_skus = generar_reporte_error_skus(modelos)\n",
    "df_todos_rmse = concatenar_rmse(modelos)\n",
    "df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales = comparar_y_graficar_modelos_nv(reporte_error_skus)\n",
    "fig1.show()\n",
    "n = 12\n",
    "periodo_max, futuros = generar_periodos_futuros(df_periodo, n)\n",
    "df_todos_pronosticos = concatenar_forecasts_pronosticos(modelos)\n",
    "df_todos_pronosticos_fecha = agregar_fecha_a_grupo(df_todos_pronosticos, futuros)\n",
    "df_pronosticos_mejor_modelo, df_pronosticos_12_meses = obtener_mejor_pronostico_nv(df_minimos, df_todos_pronosticos_fecha )\n",
    "fig = crear_grafica_pronostico_nv(df_periodo, df_todos_pronosticos_fecha, df_pronosticos_mejor_modelo)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff57394-0003-4ee2-93e3-66ad62dd6112",
   "metadata": {},
   "source": [
    "# Front end Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95a96842-a45f-4659-bd27-c9e640465b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 07:22:20.225 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# Configurar el layout de Streamlit\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Título de la aplicación\n",
    "st.title(\"Pronósticos de Series de Tiempo MILAGROS\")\n",
    "\n",
    "# Barra lateral\n",
    "st.sidebar.title('Flujo de Datos')\n",
    "\n",
    "# Secciones\n",
    "seccion = st.sidebar.radio('⬇️ Ir a:', ('📂 Carga de datos',\n",
    "                                        '📊 Demanda a pronosticar y outliers',\n",
    "                                        '🔮 Evaluar y Generar Pronosticos', \n",
    "                                        '🛠️ Herramientas de Análisis',\n",
    "                                        '📦 Pronosticos Novaventa por Campaña')\n",
    "                          )\n",
    "\n",
    "# Variables globales\n",
    "session_vars = ['df','df_vertical','df_mes_cliente','df_mes_orig', 'df_mes_ceros', 'df_mes', 'df_outliers',                            \n",
    "                'sup', 'inf', 'n',\n",
    "                'meses_a_pronosticar_evaluacion', 'meses_a_pronosticar_produccion', 'periodo_max_evaluacion',\n",
    "                'porc_eval', 'porc_eval_pronost','df_todos_pronosticos',                 \n",
    "                'codigo_seleccionado', 'modelo_seleccionado', 'mostrar_grafica_cliente', \n",
    "                'mostrar_grafica_codigo', 'df_pronosticos_12_meses', 'reporte_outliers', 'fig',\n",
    "                'sesgo_porc_formato', 'mae_porc_formato', 'score_formato',               \n",
    "                'df_periodo','mostrar_grafica_outliers','df_pronosticos_12_meses_nv','df_nv','df_ceros', 'df_orig_nv', 'df_vertical_nv', 'df_resultado_nv', 'mostrar_grafica', 'sup_nv', 'inf_nv', 'n_nv', 'reporte_outliers_nv',\n",
    "                'fig_nv','df_todos_pronosticos_nv', 'meses_a_pronosticar_evaluacion_nv', 'meses_a_pronosticar_produccion_nv', 'periodo_max_evaluacion_nv', 'porc_eval_nv','porc_eval_pronost_nv','pronosticos_generados_nv',\n",
    "                'codigo_seleccionado_nv','modelo_seleccionado_nv', 'df_outliers_nv', 'excel_data_nv'\n",
    "               ]\n",
    "\n",
    "# Inicializar session_state si no existe\n",
    "for var in session_vars:\n",
    "    if var not in st.session_state:\n",
    "        st.session_state[var] = None\n",
    "\n",
    "# Sección: Carga de Datos\n",
    "if seccion == '📂 Carga de datos':\n",
    "    # Resetear estados de gráficas para evitar mostrar gráficas automáticamente\n",
    "    st.session_state.mostrar_grafica_cliente = False\n",
    "    st.session_state.mostrar_grafica_codigo = False\n",
    "\n",
    "    st.header(\"Cargar Datos\")\n",
    "\n",
    "    # Comprobar si los datos ya están cargados\n",
    "    if \"df\" in st.session_state and st.session_state.df is not None:\n",
    "        st.success('Datos ya cargados previamente')\n",
    "        st.write(\"Datos cargados:\")\n",
    "        st.write(st.session_state.df.head())\n",
    "        st.write(\"Datos preprocesados:\")\n",
    "        st.write(st.session_state.df_mes_cliente.head())\n",
    "        if st.button('Cargar Nuevos Datos'):\n",
    "            # Resetear la session state para permitir cargue de nuevos datos\n",
    "            for var in session_vars:\n",
    "                st.session_state[var] = None\n",
    "            st.experimental_rerun()  # Recargar el script\n",
    "    else:\n",
    "        # Subida de datos\n",
    "        ruta_demanda = st.file_uploader(\"Sube el archivo de demanda en formato Excel\", type=['xlsx'])\n",
    "        if ruta_demanda is not None:\n",
    "            # Cargar y procesar datos\n",
    "            df = cargar_data(ruta_demanda)\n",
    "            st.write(\"Datos cargados:\")\n",
    "            st.write(df.head())\n",
    "            st.session_state.df = df\n",
    "            st.success(\"Archivo histórico cargado correctamente.\")\n",
    "\n",
    "            # Procesar datos\n",
    "            df_vertical = convertir_a_df_vertical(df)\n",
    "            df_vertical_fecha = convertir_texto_a_fecha(df_vertical, meses)\n",
    "            df_resultado = eliminar_ceros_iniciales(df_vertical_fecha)\n",
    "            df_mes_cliente = preprocesar_tabla_2(df_resultado)\n",
    "            st.session_state.df_mes_cliente = df_mes_cliente\n",
    "            st.write(df_mes_cliente.head())\n",
    "            st.success(\"Datos preprocesados correctamente.\")\n",
    "\n",
    "    # Opciones de gráficas\n",
    "    if \"df_mes_cliente\" in st.session_state and st.session_state.df_mes_cliente is not None:\n",
    "        st.header(\"Ver Gráficas de Demanda\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            if st.button(\"Graficar Demanda por Código - Cliente\"):\n",
    "                st.session_state.mostrar_grafica_cliente = True\n",
    "                st.session_state.mostrar_grafica_codigo = False\n",
    "        with col2:\n",
    "            if st.button(\"Graficar Demanda por Código Agregado\"):\n",
    "                st.session_state.mostrar_grafica_cliente = False\n",
    "                st.session_state.mostrar_grafica_codigo = True\n",
    "\n",
    "        # Mostrar las gráficas según la selección\n",
    "        if st.session_state.mostrar_grafica_cliente:\n",
    "            graficar_demanda_codigo_cliente(st.session_state.df_mes_cliente)\n",
    "        elif st.session_state.mostrar_grafica_codigo:\n",
    "            if st.session_state.df_mes_cliente is not None:\n",
    "                df_mes_orig, reporte_codigos = agrupar_demanda(st.session_state.df_mes_cliente)\n",
    "                st.session_state.df_mes_orig = df_mes_orig\n",
    "                graficar_demanda_codigo(df_mes_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3d495-1d8d-4855-a653-5a926712c9b0",
   "metadata": {},
   "source": [
    "### Seccion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c73cc6b2-03f6-4a3b-bbd8-9e55a7a2cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seccion == '📊 Demanda a pronosticar y outliers':\n",
    "      \n",
    "    # Seleccionar tipo de pronóstico\n",
    "    if \"df\" in st.session_state and \"df_mes_cliente\" in st.session_state:\n",
    "        st.header(\"Seleccionar Tipo de Pronóstico\")\n",
    "        opciones = ['POR_CODIGO_AGREGADO','POR_CODIGO_CLIENTE',] \n",
    "    \n",
    "        if 'opcion_seleccionada' not in st.session_state:\n",
    "            st.session_state['opcion_seleccionada'] = opciones[0]  # Selección por defecto\n",
    "\n",
    "        # Mostrar el menu desplegable y guardar la decision en session_state\n",
    "        st.session_state['opcion_seleccionada'] = st.selectbox(\n",
    "                \"Selecciona un modelo de pronóstico\", \n",
    "                opciones, \n",
    "                index=opciones.index(st.session_state['opcion_seleccionada'])\n",
    "                )\n",
    "        opcion = st.session_state['opcion_seleccionada']\n",
    "            \n",
    "            \n",
    "        df_mes_orig, reporte_codigos = seleccionar_tipo_pronostico(opcion, st.session_state.df_mes_cliente)\n",
    "        st.success(f\"Modelo seleccionado: {opcion}\")\n",
    "            \n",
    "        df_mes_ceros = reemplazar_ceros(df_mes_orig)    \n",
    "        st.session_state.df_mes_orig = df_mes_orig\n",
    "        st.session_state.df_mes_ceros = df_mes_ceros\n",
    "        st.write(\"Referencias con un solo dato, no seran pronosticadas:\")\n",
    "        st.write(reporte_codigos)\n",
    "\n",
    "    \n",
    "    # Parámetros de configuración\n",
    "    if \"df_mes_orig\" in st.session_state and \"df_mes_ceros\" in st.session_state:\n",
    "        st.header(\"Manejo de Outliers\")\n",
    "        sup = st.number_input(\"Límite Superior\", min_value=0.0, max_value=1.0, value=0.98, step=0.01)\n",
    "        inf = st.number_input(\"Límite Inferior\", min_value=0.0, max_value=1.0, value=0.02, step=0.01)\n",
    "        n = st.number_input(\"Número de Periodos para Pronóstico Ingenuo\", min_value=1, max_value=12, value=6, step=1)\n",
    "        \n",
    "        df_mes, df_outliers, reporte_outliers = eliminar_outliers(st.session_state.df_mes_ceros, sup, inf, n)\n",
    "        st.session_state.df_mes = df_mes\n",
    "        st.session_state.df_outliers = df_outliers\n",
    "        st.session_state.reporte_outliers = reporte_outliers\n",
    "        st.session_state.sup = sup\n",
    "        st.session_state.inf = inf\n",
    "        st.session_state.n = n  \n",
    "        st.success(\"Outliers Imputados correctamente.\")\n",
    "        \n",
    "    if \"df_mes\" in st.session_state and \"df_outliers\" in st.session_state:\n",
    "\n",
    "        # Exportar a excel outliers\n",
    "        output = io.BytesIO()\n",
    "        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
    "            st.session_state.reporte_outliers.to_excel(writer, index=False, sheet_name='Outliers')\n",
    "            \n",
    "        excel_data = output.getvalue()\n",
    "        \n",
    "        # Boton de descarga a excel\n",
    "        st.download_button(\n",
    "            label=\"📥 Descargar Outliers (Excel)\",\n",
    "            data=excel_data,\n",
    "            file_name=\"df_outliers.xlsx\",\n",
    "            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "        )\n",
    "        \n",
    "        st.header(\"Generar Gráfica Manejo Ouliers\")\n",
    "        if st.button(\"Grafica Imputacion de Outliers\"):\n",
    "            graficar_outliers_subplots(st.session_state.df_mes_ceros, \n",
    "                                       st.session_state.df_outliers, \n",
    "                                       sup=st.session_state.sup, \n",
    "                                       inf=st.session_state.inf, \n",
    "                                       n=st.session_state.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55682aa2-1751-49f6-af7d-2fbd2e763fc5",
   "metadata": {},
   "source": [
    "### Seccion 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "606a665a-7268-46d2-97be-e6da15343d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seccion == '🔮 Evaluar y Generar Pronosticos':\n",
    "     # Chequear si los pronosticos ya han sido generados\n",
    "    if st.session_state.df_pronosticos_12_meses is not None and st.session_state.fig is not None and st.session_state.df_todos_pronosticos is not None:\n",
    "        st.success(\"Pronósticos ya generados previamente.\")\n",
    "        # Boton para regenerar pronosticos\n",
    "        if st.button('Regenerar Pronósticos'):\n",
    "            # Limpiar los pronosticos previos y volver a correr script de la seccion\n",
    "            st.session_state.df_pronosticos_12_meses = None\n",
    "            st.session_state.fig = None\n",
    "            st.session_state.df_todos_pronosticos = None\n",
    "            st.experimental_rerun()  # Volver a correr el script\n",
    "        else: \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(label=\"Sesgo% Combinado\", value=st.session_state.sesgo_porc_formato)\n",
    "            with col2:\n",
    "                st.metric(label=\"Mae% Combinado\", value=st.session_state.mae_porc_formato)\n",
    "            with col3:\n",
    "                st.metric(label=\"Score% Combinado\", value=st.session_state.score_formato)\n",
    "                    \n",
    "            st.dataframe(st.session_state.df_pronosticos_12_meses)\n",
    "            st.plotly_chart(st.session_state.fig)\n",
    "\n",
    "    else:    \n",
    "        if \"df_mes\" in st.session_state and \"df_mes_ceros\" in st.session_state:\n",
    "            st.header(\"Parámetros de evaluación de los modelos\")\n",
    "            meses_a_pronosticar_evaluacion = st.number_input(\"Meses a Pronosticar para Evaluación\", \n",
    "                                                             min_value=1, max_value=24, value=6, step=1)\n",
    "            meses_a_pronosticar_produccion = st.number_input(\"Meses a Pronosticar para Produccion\", \n",
    "                                                             min_value=1, max_value=24, value=12, step=1)\n",
    "            periodo_max_evaluacion = 12\n",
    "            porc_eval = st.number_input(\"Porcentaje de Evaluación\", min_value=0.0, max_value=1.0, value=0.35, step=0.01)\n",
    "            porc_eval_pronost = 0\n",
    "        \n",
    "            st.session_state.meses_a_pronosticar_evaluacion = meses_a_pronosticar_evaluacion\n",
    "            st.session_state.meses_a_pronosticar_produccion = meses_a_pronosticar_produccion\n",
    "            st.session_state.periodo_max_evaluacion = periodo_max_evaluacion\n",
    "            st.session_state.porc_eval = porc_eval\n",
    "            st.session_state.porc_eval_pronost = porc_eval_pronost\n",
    "    \n",
    "        # Evaluar y generar pronósticos\n",
    "        if \"df_mes\" in st.session_state and \"df_mes_ceros\" in st.session_state:\n",
    "            st.header(\"Evaluar y Generar Pronósticos\")\n",
    "            \n",
    "            if st.button(\"Evaluar y Generar\"):\n",
    "                      \n",
    "                st.session_state.pronosticos_generados = True\n",
    "                lista_skus = crear_lista_skus(st.session_state.df_mes)\n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Iniciando Evaluación PMS...\")\n",
    "                with st.spinner('Evaluando Promedio Móvil Simple:'):\n",
    "                    df_mejor_n, df_forecast_pms = evaluar_y_generar_pms(st.session_state.df_mes,\n",
    "                                                                        st.session_state.df_mes_ceros, \n",
    "                                                                        lista_skus, \n",
    "                                                                        st.session_state.periodo_max_evaluacion, \n",
    "                                                                        st.session_state.porc_eval, \n",
    "                                                                        st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                       barra_progreso,\n",
    "                                                                       status_text)\n",
    "                    \n",
    "                    grupo_mes_error_formato_pms, df_test_pms = kpi_error_lag(df_forecast_pms) # Reporte global\n",
    "                    grupo_sku_error_formato_pms, rmse_sku_lag_pms, rmse_sku_mes_pms = kpi_error_sku(df_forecast_pms) \n",
    "                    \n",
    "                # Generar pronósticos finales\n",
    "                with st.spinner('Generando Promedio Móvil Simple:'):\n",
    "                    df_forecast_final_pms = construir_pronostico_pms(df_mejor_n, \n",
    "                                                                     st.session_state.df_mes,\n",
    "                                                                     st.session_state.meses_a_pronosticar_produccion, \n",
    "                                                                     'pms')\n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty()\n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Iniciando Evaluación SE...\") \n",
    "                with st.spinner('Evaluando Suavizacion Exponencial Simple:'):\n",
    "                    df_mejor_se,  df_forecast_se = encontrar_mejor_se(st.session_state.df_mes,\n",
    "                                                                      st.session_state.df_mes_ceros, \n",
    "                                                                      lista_skus, \n",
    "                                                                      st.session_state.periodo_max_evaluacion, \n",
    "                                                                      st.session_state.porc_eval, \n",
    "                                                                      st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                       barra_progreso,\n",
    "                                                                       status_text)\n",
    "                    \n",
    "                    grupo_mes_error_formato_se, df_test_se = kpi_error_lag(df_forecast_se) \n",
    "                    grupo_sku_error_formato_se, rmse_sku_lag_se, rmse_sku_mes_se = kpi_error_sku(df_forecast_se)\n",
    "                \n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty()                \n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Pronosticando con SE...\")     \n",
    "                with st.spinner('Generando Suavización Exponencial:'):\n",
    "                    \n",
    "                    df_mejor_se_final,  df_forecast_final_se = encontrar_mejor_se(st.session_state.df_mes, \n",
    "                                                                                  st.session_state.df_mes_ceros, \n",
    "                                                                                  lista_skus, \n",
    "                                                                                  st.session_state.periodo_max_evaluacion,\n",
    "                                                                                  st.session_state.porc_eval_pronost,                                                                           \n",
    "                                                                                  st.session_state.meses_a_pronosticar_produccion,\n",
    "                                                                                  barra_progreso,\n",
    "                                                                                  status_text)\n",
    "                    \n",
    "                    df_forecast_final_se = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se, 'se')\n",
    "                \n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty()   \n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Iniciando Evaluación RL...\") \n",
    "                with st.spinner('Evaluando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                    df_mejor_rl_lineal, df_mejor_rl_estacional, df_forecast_rl_lineal, df_forecast_rl_estacional = aplicar_regresion_lineal_simple(lista_skus, \n",
    "                                                                                                                                                   st.session_state.df_mes, \n",
    "                                                                                                                                                   st.session_state.df_mes_ceros,\n",
    "                                                                                                                                                   st.session_state.periodo_max_evaluacion,\n",
    "                                                                                                                                                   st.session_state.porc_eval, \n",
    "                                                                                                                                                   st.session_state.meses_a_pronosticar_evaluacion,\n",
    "                                                                                                                                                    barra_progreso,\n",
    "                                                                                                                                                   status_text)\n",
    "    \n",
    "                    grupo_mes_error_formato_rl_lineal, df_test_rl_lineal= kpi_error_lag(df_forecast_rl_lineal) # Reporte global RL simple\n",
    "                    grupo_sku_error_formato_rl_lineal, rmse_sku_lag_rl_lineal, rmse_sku_mes_rl_lineal = kpi_error_sku(df_forecast_rl_lineal) # Reporte por sku RL simple\n",
    "                    grupo_mes_error_formato_rl_estacional, df_test_rl_estacional= kpi_error_lag(df_forecast_rl_estacional) # Reporte global RL estacional\n",
    "                    grupo_sku_error_formato_rl_estacional, rmse_sku_lag_rl_estacional, rmse_sku_mes_rl_estacional = kpi_error_sku(df_forecast_rl_estacional) # Reporte por sku RL estaciona\n",
    "\n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty() \n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Pronosticando con RL...\") \n",
    "                with st.spinner('Generando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                    df_final_mejor_rl_lineal, df_final_mejor_rl_estacional, df_forecast_final_rl_lineal, df_forecast_final_rl_estacional = aplicar_regresion_lineal_simple(lista_skus, \n",
    "                                                                                                                                                                            st.session_state.df_mes, \n",
    "                                                                                                                                                                            st.session_state.df_mes_ceros,\n",
    "                                                                                                                                                                            st.session_state.periodo_max_evaluacion, \n",
    "                                                                                                                                                                            st.session_state.porc_eval_pronost, \n",
    "                                                                                                                                                                            st.session_state.meses_a_pronosticar_produccion,\n",
    "                                                                                                                                                                            barra_progreso,\n",
    "                                                                                                                                                                            status_text)\n",
    "                    \n",
    "                    df_forecast_final_rl_lineal = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal, 'rl_lineal')\n",
    "                    df_forecast_final_rl_estacional = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional, 'rl_estacional')\n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty() \n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Iniciando Evaluación MSTL...\") \n",
    "                with st.spinner('Evaluando MSTL:'):\n",
    "                    peso_ult_data = 0.08 \n",
    "                    df_mejor_mstl, df_forecast_mstl = aplicar_mstl(lista_skus, st.session_state.df_mes, \n",
    "                                                                   st.session_state.df_mes_ceros, \n",
    "                                                                   st.session_state.periodo_max_evaluacion, \n",
    "                                                                   st.session_state.porc_eval, \n",
    "                                                                   st.session_state.meses_a_pronosticar_evaluacion, \n",
    "                                                                   peso_ult_data, \n",
    "                                                                   barra_progreso, \n",
    "                                                                   status_text)\n",
    "                    \n",
    "                    grupo_mes_error_formato_mstl, df_test_mstl = kpi_error_lag(df_forecast_mstl) # Reporte golbal\n",
    "                    grupo_sku_error_formato_mstl, rmse_sku_lag_mstl, rmse_sku_mes_mstl = kpi_error_sku(df_forecast_mstl) # Reporte por sku\n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty() \n",
    "                barra_progreso = st.progress(0)\n",
    "                status_text = st.text(\"Pronosticando con MSTL...\") \n",
    "                with st.spinner('Generando MSTL:'):\n",
    "    \n",
    "                    tabla_final_pronost, df_forecast_final_mstl = aplicar_mstl(lista_skus, \n",
    "                                                                               st.session_state.df_mes, \n",
    "                                                                               st.session_state.df_mes_ceros, \n",
    "                                                                               st.session_state.periodo_max_evaluacion, \n",
    "                                                                               st.session_state.porc_eval_pronost, \n",
    "                                                                               st.session_state.meses_a_pronosticar_produccion, \n",
    "                                                                               peso_ult_data, \n",
    "                                                                               barra_progreso, \n",
    "                                                                               status_text)\n",
    "                    \n",
    "                    df_forecast_final_mstl = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl, 'mstl')\n",
    "                \n",
    "                barra_progreso = st.empty()\n",
    "                status_text = st.empty()  \n",
    "\n",
    "                st.success(\"✅✨ ¡Modelos Calculados Correctamente! 🎯🚀\")\n",
    "                st.balloons()\n",
    "                \n",
    "                modelos = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "                \n",
    "                reporte_error_skus = generar_reporte_error_skus(modelos)\n",
    "                df_todos_rmse = concatenar_rmse(modelos)\n",
    "                df_todos_df_test = concatenar_df_test(modelos)\n",
    "                df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales = comparar_y_graficar_modelos(reporte_error_skus)\n",
    "                with st.expander(\"Mostrar Estadisticas de Modelos de Pronosticos\"):\n",
    "                    st.plotly_chart(fig1)\n",
    "                \n",
    "                \n",
    "                df_todos_pronosticos = concatenar_forecasts_pronosticos(modelos)\n",
    "                st.session_state.df_todos_pronosticos = df_todos_pronosticos\n",
    "                \n",
    "                df_resultado_test = filtrar_y_concatenatar_df_test(df_minimos, df_todos_df_test)\n",
    "                st.subheader(\"Metricas de Error Combinadas\")\n",
    "                sesgo_porc, mae_porc, rmse, score = metricas_error(df_resultado_test, imprimir=0)\n",
    "                \n",
    "                # Convertir a formato porcentaje\n",
    "                sesgo_porc_formato = f\"{sesgo_porc * 100:.2f}%\"\n",
    "                mae_porc_formato = f\"{mae_porc * 100:.2f}%\"\n",
    "                score_formato = f\"{score * 100:.2f}%\"\n",
    "                st.session_state.sesgo_porc_formato = sesgo_porc_formato\n",
    "                st.session_state.mae_porc_formato = mae_porc_formato\n",
    "                st.session_state.score_formato = score_formato\n",
    "                \n",
    "                # Mostrar Metricas con streamlit\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                with col1:\n",
    "                    st.metric(label=\"Sesgo% Combinado\", value=st.session_state.sesgo_porc_formato)\n",
    "                with col2:\n",
    "                    st.metric(label=\"Mae% Combinado\", value=st.session_state.mae_porc_formato)\n",
    "                with col3:\n",
    "                    st.metric(label=\"Score% Combinado\", value=st.session_state.score_formato)\n",
    "\n",
    "                df_lags_metricas = evaluar_lags(df_resultado_test)[['MAE%','SESGO%','SCORE%']]\n",
    "                df_lags_metricas = df_lags_metricas.applymap(lambda x: f\"{x:.2%}\")                \n",
    "                st.dataframe(df_lags_metricas, \n",
    "                             #use_container_width=True\n",
    "                            )\n",
    "                df_pronosticos_mejor_modelo, df_pronosticos_12_meses = obtener_mejor_pronostico(df_minimos, \n",
    "                                                                                                st.session_state.df_todos_pronosticos, \n",
    "                                                                                                df_errores_totales, df_todos_rmse)\n",
    "                                                                                               \n",
    "                st.session_state.df_pronosticos_12_meses = df_pronosticos_12_meses\n",
    "                # Mostrar resultados\n",
    "                st.subheader(\"Pronósticos a 12 meses\")\n",
    "                st.write(df_pronosticos_12_meses)\n",
    "        \n",
    "                # Mostrar gráfica final\n",
    "                fig = crear_grafica_pronostico(st.session_state.df_mes, df_todos_pronosticos, df_pronosticos_mejor_modelo)\n",
    "                st.session_state.fig = fig\n",
    "                st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef02c4-d67a-408e-b1e6-91ce38a7aed2",
   "metadata": {},
   "source": [
    "### Seccion 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b0ad314-0ba3-4f96-b1f9-17e140fc3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seccion == '🛠️ Herramientas de Análisis':\n",
    "                \n",
    "    # Sección de filtrado (solo se muestra si df_todos_pronosticos existe)\n",
    "    if 'df_todos_pronosticos' in st.session_state and st.session_state.df_todos_pronosticos is not None:\n",
    "        st.header(\"Filtrar Pronósticos\")\n",
    "        st.text('Desea usar otro pronóstico diferente al sugerido estadísticamente?')\n",
    "        \n",
    "        # Menú desplegable para seleccionar el código\n",
    "        codigo_seleccionado = st.selectbox(\n",
    "            \"Seleccione el Código:\",\n",
    "            options=st.session_state.df_todos_pronosticos['CODIGO'].unique()\n",
    "        )\n",
    "        \n",
    "        # Menú desplegable para seleccionar el modelo\n",
    "        modelo_seleccionado = st.selectbox(\n",
    "            \"Seleccione el Modelo:\",\n",
    "            options=st.session_state.df_todos_pronosticos['MODELO'].unique()\n",
    "        )\n",
    "        if st.button('Validar Series de Tiempo'):\n",
    "            df_filtrado = validar_pronosticos(codigo_seleccionado, \n",
    "                                          modelo_seleccionado, \n",
    "                                          st.session_state.df_todos_pronosticos)\n",
    "            \n",
    "            st.write('Datos de pronostico para codigo y modelo seleccionado:')\n",
    "            st.dataframe(df_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abee9ab-dc46-432d-8f75-3c93a863f8bc",
   "metadata": {},
   "source": [
    "### Seccion 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c813b0b4-f33c-437c-8300-eb4507412cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seccion == '📦 Pronosticos Novaventa por Campaña': \n",
    "    tabs = st.tabs(['📂 Cargar datos Novaventa', \n",
    "                '📊 Outliers Novaventa',  \n",
    "                '🔮 Evaluar y generar pronósticos Novaventa',\n",
    "                '🛠️ Herramientas de Análisis Novaventa'\n",
    "               ])\n",
    "\n",
    "    with tabs[0]:\n",
    "        # Estado inicial de la variable de gráfica\n",
    "        if st.session_state.mostrar_grafica is None:\n",
    "            st.session_state.mostrar_grafica = \"ninguna\"\n",
    "        \n",
    "        # Subida y procesamiento de datos\n",
    "        st.header(\"Cargar Datos\")\n",
    "        \n",
    "        if st.session_state.df_nv is not None:\n",
    "            st.success('Datos ya cargados previamente')\n",
    "            st.write(\"Datos cargados:\")\n",
    "            st.write(st.session_state.df_nv.head())\n",
    "            if st.button('Cargar Nuevos Datos'):\n",
    "                for var in session_vars:\n",
    "                    st.session_state[var] = None\n",
    "                st.experimental_rerun()\n",
    "        else:\n",
    "            ruta_demanda_nv = st.file_uploader(\"Sube el archivo de demanda en formato Excel\", type=['xlsx'])\n",
    "            if ruta_demanda is not None:        \n",
    "                df_nv = cargar_data(ruta_demanda_nv)\n",
    "                st.success(\"Archivo histórico cargado correctamente.\")\n",
    "                st.session_state.df_nv = df_nv\n",
    "                st.write(\"Datos cargados:\")\n",
    "                st.write(st.session_state.df_nv.head())\n",
    "                df_orig_nv = preprocesar_datos_1_nv(df_nv)\n",
    "                df_vertical_nv = llenar_nan(df_orig_nv)\n",
    "                st.session_state.df_resultado_nv = eliminar_ceros_iniciales_nv(df_vertical_nv)\n",
    "                st.session_state.df_ceros = reemplazar_ceros_nv(st.session_state.df_resultado_nv)\n",
    "                st.success(\"Datos preprocesados correctamente.\")\n",
    "        \n",
    "        # Opciones de gráficas\n",
    "        if st.session_state.df_ceros is not None:\n",
    "            st.header(\"Ver Gráficas de Demanda por Campaña\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            \n",
    "            with col1:\n",
    "               if st.button(\"Graficar demanda original con ceros\"):\n",
    "                    st.session_state.mostrar_grafica = \"con_ceros\"\n",
    "            with col2:        \n",
    "                if st.button(\"Graficar demanda sin ceros\"):            \n",
    "                    st.session_state.mostrar_grafica = \"sin_ceros\"\n",
    "            with col3:\n",
    "                if st.button(\"Cerrar gráfica\"):\n",
    "                    st.session_state.mostrar_grafica = \"ninguna\"\n",
    "                    \n",
    "            # Mostrar las gráficas según la selección\n",
    "            if st.session_state.mostrar_grafica == \"con_ceros\":\n",
    "                st.subheader(\"Gráfica: Demanda Original con Ceros\")\n",
    "                graficar_demanda_codigo_nv(st.session_state.df_resultado_nv)\n",
    "            elif st.session_state.mostrar_grafica == \"sin_ceros\":\n",
    "                st.subheader(\"Gráfica: Demanda Sin Ceros\")\n",
    "                graficar_demanda_codigo_nv(st.session_state.df_ceros)\n",
    "\n",
    "    with tabs[1]:\n",
    "        # Parámetros de configuración\n",
    "        if \"df_ceros\" in st.session_state and st.session_state.df_ceros is not None:\n",
    "            st.header(\"Manejo de Outliers\")\n",
    "            sup_nv = st.number_input(\"Límite Superior\", min_value=0.0, max_value=1.0, value=0.98, step=0.01)\n",
    "            inf_nv = st.number_input(\"Límite Inferior\", min_value=0.0, max_value=1.0, value=0.02, step=0.01)\n",
    "            n_nv = st.number_input(\"Número de Periodos para Pronóstico Ingenuo\", min_value=1, max_value=12, value=6, step=1)\n",
    "            df_periodo, df_outliers_nv, reporte_outliers_nv = eliminar_outliers(st.session_state.df_ceros, sup_nv, inf_nv, n_nv)\n",
    "            st.session_state.df_periodo = df_periodo\n",
    "            st.session_state.df_outliers_nv = df_outliers_nv\n",
    "            st.session_state.reporte_outliers_nv = reporte_outliers_nv\n",
    "            st.session_state.sup_nv = sup_nv\n",
    "            st.session_state.inf_nv = inf_nv\n",
    "            st.session_state.n_nv = n_nv  \n",
    "            st.success(\"Outliers Imputados correctamente.\")\n",
    "                \n",
    "        #if \"df_periodo\" in st.session_state and \"df_outliers_nv\" in st.session_state:\n",
    "        if \"df_outliers_nv\" in st.session_state and st.session_state.df_outliers_nv is not None:\n",
    "            excel_data_env = None\n",
    "            # Exportar a excel outliers            \n",
    "            #if st.session_state.df_outliers_nv is not None:\n",
    "            output_nv = io.BytesIO()\n",
    "            with pd.ExcelWriter(output_nv, engine='openpyxl') as writer:\n",
    "                st.session_state.reporte_outliers_nv.to_excel(writer, index=False, sheet_name='Outliers')\n",
    "                    \n",
    "            excel_data_nv = output_nv.getvalue()\n",
    "                \n",
    "            #else:\n",
    "                #st.warning(\"No hay datos procesados aun para exportar.\")\n",
    "            # Boton de descarga a excel\n",
    "            if excel_data_nv is not None:\n",
    "                st.download_button(\n",
    "                        label=\"📥 Descargar Outliers (Excel)\",\n",
    "                        data=excel_data_nv,\n",
    "                        file_name=\"df_outliers_nv.xlsx\",\n",
    "                        mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "                    )\n",
    "            \n",
    "            st.header(\"Generar Gráfica Manejo Outliers\")\n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                if st.button(\"Mostrar gráfica de outliers\"):\n",
    "                    st.session_state.mostrar_grafica_outliers = \"mostrar\"\n",
    "            with col2:\n",
    "                if st.button(\"Cerrar gráfica de outliers\"):\n",
    "                    st.session_state.mostrar_grafica_outliers = \"cerrar\"\n",
    "        \n",
    "            # Mostrar o cerrar gráfica\n",
    "            if st.session_state.mostrar_grafica_outliers == \"mostrar\":\n",
    "                st.subheader(\"Gráfica: Imputación de Outliers\")\n",
    "                graficar_outliers_subplots(st.session_state.df_ceros, \n",
    "                                           st.session_state.df_outliers_nv, \n",
    "                                           sup=st.session_state.sup_nv, \n",
    "                                           inf=st.session_state.inf_nv, \n",
    "                                           n=st.session_state.n_nv)\n",
    "\n",
    "\n",
    "    with tabs[2]:\n",
    "         # Chequear si los pronosticos ya han sido generados\n",
    "        if st.session_state.df_pronosticos_12_meses_nv is not None and st.session_state.fig_nv is not None and st.session_state.df_todos_pronosticos_nv is not None:\n",
    "            st.success(\"Pronósticos ya generados previamente.\")\n",
    "            # Boton para regenerar pronosticos\n",
    "            if st.button('Regenerar Pronósticos'):\n",
    "                # Limpiar los pronosticos previos y volver a correr script de la seccion\n",
    "                st.session_state.df_pronosticos_12_meses_nv = None\n",
    "                st.session_state.fig_nv = None\n",
    "                st.session_state.df_todos_pronosticos_nv = None\n",
    "                st.experimental_rerun()  # Volver a correr el script\n",
    "            else: \n",
    "                st.dataframe(st.session_state.df_pronosticos_12_meses_nv)\n",
    "                st.plotly_chart(st.session_state.fig_nv)\n",
    "        \n",
    "        else:    \n",
    "            if \"df_periodo\" in st.session_state and \"df_ceros\" in st.session_state:\n",
    "                st.header(\"Parámetros de evaluación de los modelos\")\n",
    "                meses_a_pronosticar_evaluacion_nv = st.number_input(\"Meses a Pronosticar para Evaluación\", \n",
    "                                                                 min_value=1, max_value=24, value=6, step=1)\n",
    "                meses_a_pronosticar_produccion_nv = st.number_input(\"Meses a Pronosticar para Produccion\", \n",
    "                                                                 min_value=1, max_value=24, value=12, step=1)\n",
    "                periodo_max_evaluacion_nv = 12\n",
    "                porc_eval_nv = st.number_input(\"Porcentaje de Evaluación\", min_value=0.0, max_value=1.0, value=0.35, step=0.01)\n",
    "                porc_eval_pronost_nv = 0\n",
    "            \n",
    "                st.session_state.meses_a_pronosticar_evaluacion_nv = meses_a_pronosticar_evaluacion_nv\n",
    "                st.session_state.meses_a_pronosticar_produccion_nv = meses_a_pronosticar_produccion_nv\n",
    "                st.session_state.periodo_max_evaluacion_nv = periodo_max_evaluacion_nv\n",
    "                st.session_state.porc_eval_nv = porc_eval_nv\n",
    "                st.session_state.porc_eval_pronost_nv = porc_eval_pronost_nv\n",
    "        \n",
    "            # Evaluar y generar pronósticos\n",
    "            if \"df_periodo\" in st.session_state and \"df_ceros\" in st.session_state:\n",
    "                st.header(\"Evaluar y Generar Pronósticos\")\n",
    "                \n",
    "                if st.button(\"Evaluar y Generar\"):\n",
    "                          \n",
    "                    st.session_state.pronosticos_generados_nv = True\n",
    "                    lista_skus_nv = crear_lista_skus(st.session_state.df_periodo)\n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Iniciando Evaluación PMS...\")\n",
    "                    with st.spinner('Evaluando Promedio Móvil Simple:'):\n",
    "                        df_mejor_n_nv, df_forecast_pms_nv = evaluar_y_generar_pms_nv(st.session_state.df_periodo,\n",
    "                                                                            st.session_state.df_ceros, \n",
    "                                                                            lista_skus_nv, \n",
    "                                                                            st.session_state.periodo_max_evaluacion_nv, \n",
    "                                                                            st.session_state.porc_eval_nv, \n",
    "                                                                            st.session_state.meses_a_pronosticar_evaluacion_nv,\n",
    "                                                                           barra_progreso,\n",
    "                                                                           status_text)\n",
    "                        \n",
    "                        grupo_mes_error_formato_pms_nv, df_test_pms_nv = kpi_error_lag(df_forecast_pms_nv) # Reporte global\n",
    "                        grupo_sku_error_formato_pms_nv, rmse_sku_lag_pms_nv, rmse_sku_mes_pms_nv = kpi_error_sku(df_forecast_pms_nv) \n",
    "                        \n",
    "                    # Generar pronósticos finales\n",
    "                    with st.spinner('Generando Promedio Móvil Simple:'):\n",
    "                        df_forecast_final_pms_nv = construir_pronostico_pms_nv(df_mejor_n_nv, \n",
    "                                                                         st.session_state.df_periodo,\n",
    "                                                                         st.session_state.meses_a_pronosticar_produccion_nv, \n",
    "                                                                         'pms')\n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty()\n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Iniciando Evaluación SE...\") \n",
    "                    with st.spinner('Evaluando Suavizacion Exponencial Simple:'):\n",
    "                        df_mejor_se_nv,  df_forecast_se_nv = encontrar_mejor_se_nv(st.session_state.df_periodo,\n",
    "                                                                          st.session_state.df_ceros, \n",
    "                                                                          lista_skus_nv, \n",
    "                                                                          st.session_state.periodo_max_evaluacion_nv, \n",
    "                                                                          st.session_state.porc_eval_nv, \n",
    "                                                                          st.session_state.meses_a_pronosticar_evaluacion_nv,\n",
    "                                                                           barra_progreso,\n",
    "                                                                           status_text)\n",
    "                        \n",
    "                        grupo_mes_error_formato_se_nv, df_test_se_nv = kpi_error_lag(df_forecast_se_nv) \n",
    "                        grupo_sku_error_formato_se_nv, rmse_sku_lag_se_nv, rmse_sku_mes_se_nv = kpi_error_sku(df_forecast_se_nv)\n",
    "                    \n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty()                \n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Pronosticando con SE...\")     \n",
    "                    with st.spinner('Generando Suavización Exponencial:'):\n",
    "                        \n",
    "                        df_mejor_se_final_nv,  df_forecast_final_se_nv = encontrar_mejor_se_nv(st.session_state.df_periodo, \n",
    "                                                                                      st.session_state.df_ceros, \n",
    "                                                                                      lista_skus_nv, \n",
    "                                                                                      st.session_state.periodo_max_evaluacion_nv,\n",
    "                                                                                      st.session_state.porc_eval_pronost_nv,                                                                           \n",
    "                                                                                      st.session_state.meses_a_pronosticar_produccion_nv,\n",
    "                                                                                      barra_progreso,\n",
    "                                                                                      status_text)\n",
    "                        \n",
    "                        df_forecast_final_se_nv = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_se_nv, 'se')\n",
    "                    \n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty()   \n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Iniciando Evaluación RL...\") \n",
    "                    with st.spinner('Evaluando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                        df_mejor_rl_lineal_nv, df_mejor_rl_estacional_nv, df_forecast_rl_lineal_nv, df_forecast_rl_estacional_nv = aplicar_regresion_lineal_simple_nv(lista_skus_nv, \n",
    "                                                                                                                                                       st.session_state.df_periodo, \n",
    "                                                                                                                                                       st.session_state.df_ceros,\n",
    "                                                                                                                                                       st.session_state.periodo_max_evaluacion_nv,\n",
    "                                                                                                                                                       st.session_state.porc_eval_nv, \n",
    "                                                                                                                                                       st.session_state.meses_a_pronosticar_evaluacion_nv,\n",
    "                                                                                                                                                        barra_progreso,\n",
    "                                                                                                                                                       status_text)\n",
    "        \n",
    "                        grupo_mes_error_formato_rl_lineal_nv, df_test_rl_lineal_nv= kpi_error_lag(df_forecast_rl_lineal_nv) # Reporte global RL simple\n",
    "                        grupo_sku_error_formato_rl_lineal_nv, rmse_sku_lag_rl_lineal_nv, rmse_sku_mes_rl_lineal_nv = kpi_error_sku(df_forecast_rl_lineal_nv) # Reporte por sku RL simple\n",
    "                        grupo_mes_error_formato_rl_estacional_nv, df_test_rl_estacional_nv= kpi_error_lag(df_forecast_rl_estacional_nv) # Reporte global RL estacional\n",
    "                        grupo_sku_error_formato_rl_estacional_nv, rmse_sku_lag_rl_estacional_nv, rmse_sku_mes_rl_estacional_nv = kpi_error_sku(df_forecast_rl_estacional_nv) # Reporte por sku RL estacional\n",
    "        \n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty() \n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Pronosticando con RL...\") \n",
    "                    with st.spinner('Generando Regresion Lineal Simple y \"Estacional\":'):\n",
    "                        df_final_mejor_rl_lineal_nv, df_final_mejor_rl_estacional_nv, df_forecast_final_rl_lineal_nv, df_forecast_final_rl_estacional_nv = aplicar_regresion_lineal_simple_nv(lista_skus_nv, \n",
    "                                                                                                                                                                                st.session_state.df_periodo, \n",
    "                                                                                                                                                                                st.session_state.df_ceros,\n",
    "                                                                                                                                                                                st.session_state.periodo_max_evaluacion_nv, \n",
    "                                                                                                                                                                                st.session_state.porc_eval_pronost_nv, \n",
    "                                                                                                                                                                                st.session_state.meses_a_pronosticar_produccion_nv,\n",
    "                                                                                                                                                                                barra_progreso,\n",
    "                                                                                                                                                                                status_text)\n",
    "                        \n",
    "                        df_forecast_final_rl_lineal_nv = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_lineal_nv, 'rl_lineal')\n",
    "                        df_forecast_final_rl_estacional_nv = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_rl_estacional_nv, 'rl_estacional')\n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty() \n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Iniciando Evaluación MSTL...\") \n",
    "                    with st.spinner('Evaluando MSTL:'):\n",
    "                        peso_ult_data_nv = 0.08 \n",
    "                        df_mejor_mstl_nv, df_forecast_mstl_nv = aplicar_mstl_nv(lista_skus_nv, st.session_state.df_periodo, \n",
    "                                                                       st.session_state.df_ceros, \n",
    "                                                                       st.session_state.periodo_max_evaluacion_nv, \n",
    "                                                                       st.session_state.porc_eval_nv, \n",
    "                                                                       st.session_state.meses_a_pronosticar_evaluacion_nv, \n",
    "                                                                       peso_ult_data_nv, \n",
    "                                                                       barra_progreso, \n",
    "                                                                       status_text)\n",
    "                        \n",
    "                        grupo_mes_error_formato_mstl_nv, df_test_mstl_nv = kpi_error_lag(df_forecast_mstl_nv) # Reporte golbal\n",
    "                        grupo_sku_error_formato_mstl_nv, rmse_sku_lag_mstl_nv, rmse_sku_mes_mstl_nv = kpi_error_sku(df_forecast_mstl_nv) # Reporte por sku\n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty() \n",
    "                    barra_progreso = st.progress(0)\n",
    "                    status_text = st.text(\"Pronosticando con MSTL...\") \n",
    "                    with st.spinner('Generando MSTL:'):\n",
    "        \n",
    "                        tabla_final_pronost_nv, df_forecast_final_mstl_nv = aplicar_mstl_nv(lista_skus_nv, \n",
    "                                                                                   st.session_state.df_periodo, \n",
    "                                                                                   st.session_state.df_ceros, \n",
    "                                                                                   st.session_state.periodo_max_evaluacion_nv, \n",
    "                                                                                   st.session_state.porc_eval_pronost_nv, \n",
    "                                                                                   st.session_state.meses_a_pronosticar_produccion_nv, \n",
    "                                                                                   peso_ult_data_nv, \n",
    "                                                                                   barra_progreso, \n",
    "                                                                                   status_text)\n",
    "                        \n",
    "                        df_forecast_final_mstl_nv = adicionar_nombre_modelo_serie_tiempo(df_forecast_final_mstl_nv, 'mstl')\n",
    "                    \n",
    "                    barra_progreso = st.empty()\n",
    "                    status_text = st.empty()  \n",
    "        \n",
    "                    st.success(\"✅✨ ¡Modelos Calculados Correctamente! 🎯🚀\")\n",
    "                    #st.balloons()\n",
    "                    \n",
    "                    modelos_nv = ['pms', 'se', 'rl_lineal', 'rl_estacional', 'mstl']\n",
    "                    \n",
    "                    reporte_error_skus_nv = generar_reporte_error_skus_nv(modelos_nv)\n",
    "                    df_todos_rmse_nv = concatenar_rmse_nv(modelos_nv)\n",
    "                    df_minimos_nv, df_final_nv, reporte_error_skus_nv, fig1_nv, df_errores_totales_nv = comparar_y_graficar_modelos_nv(reporte_error_skus_nv)\n",
    "                    with st.expander(\"Mostrar Estadisticas de Modelos de Pronosticos\"):\n",
    "                        st.plotly_chart(fig1_nv)\n",
    "                    periodo_max, futuros = generar_periodos_futuros(df_periodo, st.session_state.meses_a_pronosticar_produccion_nv)            \n",
    "                    df_todos_pronosticos_nv = concatenar_forecasts_pronosticos_nv(modelos_nv)\n",
    "                    df_todos_pronosticos_fecha = agregar_fecha_a_grupo(df_todos_pronosticos_nv, futuros)\n",
    "                    st.session_state.df_todos_pronosticos_nv = df_todos_pronosticos_nv\n",
    "                    st.session_state.df_todos_pronosticos_fecha  = df_todos_pronosticos_fecha \n",
    "                    \n",
    "                    df_pronosticos_mejor_modelo_nv, df_pronosticos_12_meses_nv = obtener_mejor_pronostico_nv(df_minimos_nv, \n",
    "                                                                                                    st.session_state.df_todos_pronosticos_fecha, \n",
    "                                                                                                    #df_errores_totales, \n",
    "                                                                                                    #df_todos_rmse\n",
    "                                                                                                   )\n",
    "                                                                                                   \n",
    "                    st.session_state.df_pronosticos_12_meses_nv = df_pronosticos_12_meses_nv\n",
    "                    # Mostrar resultados\n",
    "                    st.subheader(\"Pronósticos proximas campañas\")\n",
    "                    st.write(df_pronosticos_12_meses_nv)\n",
    "            \n",
    "                    # Mostrar gráfica final\n",
    "                    fig_nv = crear_grafica_pronostico_nv(st.session_state.df_periodo, st.session_state.df_todos_pronosticos_fecha, df_pronosticos_mejor_modelo_nv)\n",
    "                    st.session_state.fig = fig_nv\n",
    "                    st.plotly_chart(fig_nv)\n",
    "\n",
    "    with tabs[3]:\n",
    "        # Sección de filtrado (solo se muestra si df_todos_pronosticos existe)\n",
    "        if 'df_todos_pronosticos_fecha' in st.session_state and st.session_state.df_todos_pronosticos_fecha is not None:\n",
    "            st.header(\"Filtrar Pronósticos\")\n",
    "            st.text('Desea usar otro pronóstico diferente al sugerido estadísticamente?')\n",
    "            \n",
    "            # Menú desplegable para seleccionar el código\n",
    "            codigo_seleccionado_nv = st.selectbox(\n",
    "                \"Seleccione el Código:\",\n",
    "                options=st.session_state.df_todos_pronosticos_fecha['CODIGO'].unique()\n",
    "            )\n",
    "            \n",
    "            # Menú desplegable para seleccionar el modelo\n",
    "            modelo_seleccionado_nv = st.selectbox(\n",
    "                \"Seleccione el Modelo:\",\n",
    "                options=st.session_state.df_todos_pronosticos_fecha['MODELO'].unique()\n",
    "            )\n",
    "            if st.button('Validar Series de Tiempo'):\n",
    "                df_filtrado_nv = validar_pronosticos(codigo_seleccionado_nv, \n",
    "                                              modelo_seleccionado_nv, \n",
    "                                              st.session_state.df_todos_pronosticos_fecha)\n",
    "                \n",
    "                st.write('Datos de pronostico para codigo y modelo seleccionado:')\n",
    "                st.dataframe(df_filtrado_nv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361e4a8-c714-4238-a331-8a0e7970de6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
